{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktkc/ai-science-training-series/blob/main/Copy_of_02_keras_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXMy-G9R8oWh"
      },
      "source": [
        "# CIFAR-10 dataset classification with CNNs\n",
        "\n",
        "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
        "\n",
        "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
        "\n",
        "First, the needed imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TN4uDgPV8oWp"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZlv2PAd8oWu"
      },
      "source": [
        "## CIFAR-10 data set\n",
        "\n",
        "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb6lPPH28oWy",
        "outputId": "a9c7e17c-aab3-4ee7-ae49-15766be4d171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zss2_bq8oW2"
      },
      "source": [
        "This time we won't flatten the images. \n",
        "\n",
        "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 28x28 pixels. \n",
        "\n",
        "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JFYNl5f8oW5"
      },
      "source": [
        "## Convolutional neural network (CNN)\n",
        "\n",
        "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
        "\n",
        "Let's use a small model that includes convolutional layers\n",
        "\n",
        "- The Conv2D layers operate on 2D matrices so we input the digit images directly to the model.\n",
        "    - The two Conv2D layers belows learn 32 and 64 filters respectively. \n",
        "    - They are learning filters for 3x3 windows.\n",
        "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
        "    - It downsamples by taking the maximum value in the window \n",
        "    - The pool size of (2, 2) below means the windows are 2x2. \n",
        "    - Helps in extracting important features and reduce computation\n",
        "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
        "\n",
        "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJQLGLCz8oW8"
      },
      "source": [
        "![conv layer](https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv_layer.png?raw=1)\n",
        "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Ud-hG08oW-"
      },
      "source": [
        "![conv layer](https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv.png?raw=1)\n",
        "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xDbR1qK8oXB"
      },
      "source": [
        "\n",
        "<img src=\"https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/MaxpoolSample2.png?raw=1\" width=\"600\" hight=\"600\" align=\"left\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsY0Oey18oXH"
      },
      "outputs": [],
      "source": [
        "class CIFAR10Classifier(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, activation=tf.nn.tanh):\n",
        "        tf.keras.models.Model.__init__(self)\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
        "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.drop_6 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.pool_3(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.dense_5(x)\n",
        "        x = self.drop_6(x)\n",
        "        x = self.dense_7(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvnetdTs8oXJ"
      },
      "source": [
        "### Simple training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSzgHibq8oXK"
      },
      "source": [
        "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4J-XiXJ8oXL"
      },
      "outputs": [],
      "source": [
        "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cnn_model = CIFAR10Classifier()\n",
        "\n",
        "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJG4sW3M8oXM",
        "outputId": "851bb01d-da36-4d83-8670-816c9cd31f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "98/98 [==============================] - 11s 35ms/step - loss: 1.9292 - accuracy: 0.2876\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 3s 32ms/step - loss: 1.5865 - accuracy: 0.4223\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 4s 38ms/step - loss: 1.4625 - accuracy: 0.4728\n"
          ]
        }
      ],
      "source": [
        "# This took 55 seconds per epoch on my laptop\n",
        "batch_size = 512\n",
        "epochs = 3\n",
        "lr = .01\n",
        "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr9bXKuu8oXN"
      },
      "source": [
        "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxCLi9u28oXO",
        "outputId": "62403e2d-bb00-4a16-f7bf-d71be850eb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'])\n",
        "plt.title('accuracy');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgmKpw4J8oXO"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRrkYuXB8oXP"
      },
      "source": [
        "With enough training epochs, the test accuracy should exceed 99%.\n",
        "\n",
        "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwm50VSt8oXQ",
        "outputId": "c7f3bdfa-737a-48a2-d095-30bfa0f8d8a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 1.2500 - accuracy: 0.5566 - 1s/epoch - 4ms/step\n",
            "accuracy: 55.66%\n",
            "CPU times: user 1.4 s, sys: 163 ms, total: 1.56 s\n",
            "Wall time: 1.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfUDwucV8oXR"
      },
      "source": [
        "We can also again check the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-IhFa4L8oXS",
        "outputId": "d92045b3-110c-42a4-c39f-29033b13c88a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (rows: true classes; columns: predicted classes):\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[556  50  82  14  12  13  27  10 199  37]\n",
            " [ 20 755   3   9   3   4  26   7  64 109]\n",
            " [ 88  11 385  46 157 109 139  21  31  13]\n",
            " [ 11  19  99 276  70 228 221  30  21  25]\n",
            " [ 39  14 152  57 428  37 194  66  11   2]\n",
            " [ 12   6 113 133  63 494 103  53  18   5]\n",
            " [  4  13  46  36  56  16 802   7   7  13]\n",
            " [ 23   7  32  45  89 124  71 561   5  43]\n",
            " [104  76  22  10   2   7  20   4 713  42]\n",
            " [ 26 190   9  12   5   7  42  25  88 596]]\n",
            "\n",
            "Classification accuracy for each class:\n",
            "\n",
            "0: 0.5560\n",
            "1: 0.7550\n",
            "2: 0.3850\n",
            "3: 0.2760\n",
            "4: 0.4280\n",
            "5: 0.4940\n",
            "6: 0.8020\n",
            "7: 0.5610\n",
            "8: 0.7130\n",
            "9: 0.5960\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
        "predictions = cnn_model.predict(x_test)\n",
        "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
        "print(cm); print()\n",
        "\n",
        "print('Classification accuracy for each class:'); print()\n",
        "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dalYJKP18oXU"
      },
      "source": [
        "### More verbose training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0ddLOnM8oXV"
      },
      "source": [
        "This approach explicitly handles the looping over data. It will be helpful this afternoon for diving in and optimizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUV5D1dd8oXX"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y_true, y_pred):\n",
        "    # if labels are integers, use sparse categorical crossentropy\n",
        "    # network's final layer is softmax, so from_logtis=False\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    # if labels are one-hot encoded, use standard crossentropy\n",
        "\n",
        "    return scce(y_true, y_pred)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P9ju8mY8oXZ"
      },
      "outputs": [],
      "source": [
        "def forward_pass(model, batch_data, y_true):\n",
        "    y_pred = model(batch_data)\n",
        "    loss = compute_loss(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z4EGxSE8oXb"
      },
      "outputs": [],
      "source": [
        "# Here is a function that will manage the training loop for us:\n",
        "\n",
        "def train_loop(batch_size, n_training_epochs, model, opt):\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_iteration(data, y_true, model, opt):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = forward_pass(model, data, y_true)\n",
        "\n",
        "        trainable_vars = model.trainable_variables\n",
        "\n",
        "        # Apply the update to the network (one at a time):\n",
        "        grads = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        opt.apply_gradients(zip(grads, trainable_vars))\n",
        "        return loss\n",
        "\n",
        "    for i_epoch in range(n_training_epochs):\n",
        "        print(\"beginning epoch %d\" % i_epoch)\n",
        "        start = time.time()\n",
        "\n",
        "        epoch_steps = int(50000/batch_size)\n",
        "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
        "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "        \n",
        "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
        "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
        "            loss = train_iteration(batch_data, y_true, model, opt)\n",
        "            \n",
        "        end = time.time()\n",
        "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh6Xr6Nv8oXd"
      },
      "outputs": [],
      "source": [
        "def train_network(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    mnist_model = CIFAR10Classifier()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(_lr)\n",
        "\n",
        "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDSN2osF8oXf",
        "outputId": "0706f166-5e19-49b3-b3b0-91ab08e636e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beginning epoch 0\n",
            "took 3.5 seconds for epoch #0\n",
            "beginning epoch 1\n",
            "took 2.8 seconds for epoch #1\n",
            "beginning epoch 2\n",
            "took 2.8 seconds for epoch #2\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset.shuffle(50000)\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 3\n",
        "lr = .01\n",
        "train_network(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GCfkxx38oXg"
      },
      "source": [
        "# Homework: improve the accuracy of this model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtNuUVwa8oXj"
      },
      "source": [
        "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning weight, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting with modifying the Simple Version first. "
      ],
      "metadata": {
        "id": "7GV00-Ul1mdA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weA7gAva8oXo"
      },
      "outputs": [],
      "source": [
        "class CIFAR10Classifier(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, activation=tf.nn.tanh):\n",
        "        tf.keras.models.Model.__init__(self)\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
        "        #self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dense_5 = tf.keras.layers.Dense(10)\n",
        "        self.dense_6 = tf.keras.layers.LeakyReLU()\n",
        "        self.drop_7 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense_8 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.pool_3(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.dense_5(x)\n",
        "        x = self.dense_6(x)\n",
        "        x = self.drop_7(x)\n",
        "        x = self.dense_8(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cnn_model = CIFAR10Classifier()\n",
        "\n",
        "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ],
      "metadata": {
        "id": "_LnCK05Rz7En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 50\n",
        "epochs = 1000 #3000 not really worth the time; only got to 67.68% on the test set\n",
        "#I need to be able to shuffle the data...\n",
        "lr = .1\n",
        "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gThFo0_2z8NW",
        "outputId": "e9b627b6-424c-46d3-c089-ed9c363c538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7348 - accuracy: 0.6985\n",
            "Epoch 502/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7419 - accuracy: 0.6962\n",
            "Epoch 503/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7369 - accuracy: 0.6976\n",
            "Epoch 504/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7445 - accuracy: 0.6948\n",
            "Epoch 505/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7408 - accuracy: 0.6990\n",
            "Epoch 506/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7382 - accuracy: 0.7007\n",
            "Epoch 507/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7410 - accuracy: 0.6960\n",
            "Epoch 508/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7415 - accuracy: 0.6981\n",
            "Epoch 509/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7428 - accuracy: 0.6961\n",
            "Epoch 510/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7472 - accuracy: 0.6968\n",
            "Epoch 511/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7366 - accuracy: 0.6971\n",
            "Epoch 512/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7437 - accuracy: 0.6941\n",
            "Epoch 513/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7433 - accuracy: 0.6958\n",
            "Epoch 514/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7455 - accuracy: 0.6950\n",
            "Epoch 515/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7428 - accuracy: 0.6970\n",
            "Epoch 516/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7377 - accuracy: 0.6987\n",
            "Epoch 517/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7396 - accuracy: 0.6966\n",
            "Epoch 518/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7365 - accuracy: 0.7010\n",
            "Epoch 519/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7391 - accuracy: 0.6970\n",
            "Epoch 520/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7338 - accuracy: 0.6983\n",
            "Epoch 521/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7408 - accuracy: 0.6955\n",
            "Epoch 522/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7410 - accuracy: 0.6966\n",
            "Epoch 523/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7366 - accuracy: 0.6981\n",
            "Epoch 524/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7445 - accuracy: 0.6963\n",
            "Epoch 525/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7475 - accuracy: 0.6942\n",
            "Epoch 526/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7382 - accuracy: 0.6960\n",
            "Epoch 527/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7376 - accuracy: 0.6984\n",
            "Epoch 528/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7310 - accuracy: 0.7015\n",
            "Epoch 529/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7417 - accuracy: 0.6975\n",
            "Epoch 530/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7376 - accuracy: 0.6996\n",
            "Epoch 531/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7334 - accuracy: 0.7022\n",
            "Epoch 532/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7352 - accuracy: 0.6991\n",
            "Epoch 533/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7379 - accuracy: 0.6969\n",
            "Epoch 534/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7405 - accuracy: 0.6973\n",
            "Epoch 535/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7403 - accuracy: 0.6959\n",
            "Epoch 536/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7344 - accuracy: 0.6987\n",
            "Epoch 537/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7383 - accuracy: 0.6974\n",
            "Epoch 538/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7400 - accuracy: 0.6991\n",
            "Epoch 539/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7350 - accuracy: 0.6980\n",
            "Epoch 540/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7372 - accuracy: 0.6997\n",
            "Epoch 541/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7333 - accuracy: 0.6994\n",
            "Epoch 542/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7363 - accuracy: 0.6978\n",
            "Epoch 543/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7371 - accuracy: 0.6971\n",
            "Epoch 544/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7340 - accuracy: 0.7005\n",
            "Epoch 545/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7326 - accuracy: 0.7007\n",
            "Epoch 546/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7403 - accuracy: 0.6963\n",
            "Epoch 547/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7446 - accuracy: 0.6947\n",
            "Epoch 548/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7469 - accuracy: 0.6928\n",
            "Epoch 549/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7335 - accuracy: 0.6999\n",
            "Epoch 550/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7332 - accuracy: 0.6997\n",
            "Epoch 551/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7364 - accuracy: 0.6995\n",
            "Epoch 552/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7321 - accuracy: 0.6993\n",
            "Epoch 553/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7373 - accuracy: 0.6990\n",
            "Epoch 554/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7408 - accuracy: 0.6959\n",
            "Epoch 555/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7380 - accuracy: 0.7020\n",
            "Epoch 556/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7285 - accuracy: 0.6998\n",
            "Epoch 557/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7348 - accuracy: 0.6983\n",
            "Epoch 558/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7330 - accuracy: 0.6997\n",
            "Epoch 559/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7356 - accuracy: 0.7001\n",
            "Epoch 560/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7356 - accuracy: 0.6976\n",
            "Epoch 561/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7310 - accuracy: 0.7025\n",
            "Epoch 562/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7355 - accuracy: 0.7003\n",
            "Epoch 563/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7356 - accuracy: 0.6974\n",
            "Epoch 564/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7324 - accuracy: 0.6992\n",
            "Epoch 565/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7366 - accuracy: 0.6981\n",
            "Epoch 566/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7302 - accuracy: 0.7007\n",
            "Epoch 567/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7437 - accuracy: 0.6949\n",
            "Epoch 568/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7396 - accuracy: 0.6987\n",
            "Epoch 569/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7370 - accuracy: 0.6981\n",
            "Epoch 570/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7264 - accuracy: 0.7028\n",
            "Epoch 571/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7365 - accuracy: 0.6990\n",
            "Epoch 572/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7318 - accuracy: 0.6999\n",
            "Epoch 573/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7391 - accuracy: 0.6991\n",
            "Epoch 574/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7392 - accuracy: 0.6943\n",
            "Epoch 575/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7365 - accuracy: 0.6978\n",
            "Epoch 576/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7361 - accuracy: 0.6972\n",
            "Epoch 577/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7344 - accuracy: 0.6986\n",
            "Epoch 578/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7331 - accuracy: 0.7026\n",
            "Epoch 579/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7319 - accuracy: 0.7008\n",
            "Epoch 580/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7300 - accuracy: 0.7015\n",
            "Epoch 581/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7258 - accuracy: 0.7038\n",
            "Epoch 582/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7297 - accuracy: 0.6990\n",
            "Epoch 583/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7373 - accuracy: 0.6983\n",
            "Epoch 584/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7334 - accuracy: 0.7007\n",
            "Epoch 585/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7290 - accuracy: 0.7034\n",
            "Epoch 586/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7283 - accuracy: 0.7020\n",
            "Epoch 587/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7296 - accuracy: 0.7016\n",
            "Epoch 588/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7335 - accuracy: 0.7003\n",
            "Epoch 589/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7331 - accuracy: 0.7015\n",
            "Epoch 590/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7288 - accuracy: 0.7003\n",
            "Epoch 591/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7314 - accuracy: 0.7004\n",
            "Epoch 592/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7290 - accuracy: 0.7034\n",
            "Epoch 593/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7349 - accuracy: 0.6993\n",
            "Epoch 594/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7294 - accuracy: 0.7002\n",
            "Epoch 595/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7285 - accuracy: 0.6986\n",
            "Epoch 596/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7312 - accuracy: 0.7015\n",
            "Epoch 597/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7310 - accuracy: 0.7014\n",
            "Epoch 598/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7261 - accuracy: 0.7029\n",
            "Epoch 599/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7263 - accuracy: 0.7014\n",
            "Epoch 600/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7400 - accuracy: 0.6984\n",
            "Epoch 601/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7300 - accuracy: 0.7020\n",
            "Epoch 602/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7284 - accuracy: 0.7022\n",
            "Epoch 603/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7271 - accuracy: 0.7026\n",
            "Epoch 604/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7313 - accuracy: 0.7008\n",
            "Epoch 605/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7312 - accuracy: 0.6997\n",
            "Epoch 606/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7248 - accuracy: 0.7031\n",
            "Epoch 607/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7292 - accuracy: 0.7044\n",
            "Epoch 608/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7280 - accuracy: 0.6996\n",
            "Epoch 609/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7244 - accuracy: 0.7013\n",
            "Epoch 610/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7266 - accuracy: 0.7009\n",
            "Epoch 611/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7355 - accuracy: 0.6989\n",
            "Epoch 612/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7304 - accuracy: 0.7004\n",
            "Epoch 613/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7267 - accuracy: 0.7009\n",
            "Epoch 614/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7331 - accuracy: 0.7013\n",
            "Epoch 615/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7209 - accuracy: 0.7044\n",
            "Epoch 616/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7230 - accuracy: 0.7044\n",
            "Epoch 617/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7300 - accuracy: 0.7009\n",
            "Epoch 618/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7297 - accuracy: 0.7006\n",
            "Epoch 619/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7293 - accuracy: 0.6999\n",
            "Epoch 620/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7325 - accuracy: 0.6996\n",
            "Epoch 621/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7292 - accuracy: 0.7010\n",
            "Epoch 622/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7250 - accuracy: 0.7027\n",
            "Epoch 623/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7327 - accuracy: 0.6983\n",
            "Epoch 624/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7335 - accuracy: 0.7005\n",
            "Epoch 625/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7270 - accuracy: 0.7013\n",
            "Epoch 626/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7255 - accuracy: 0.7016\n",
            "Epoch 627/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7285 - accuracy: 0.7006\n",
            "Epoch 628/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7289 - accuracy: 0.7013\n",
            "Epoch 629/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7252 - accuracy: 0.7023\n",
            "Epoch 630/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7189 - accuracy: 0.7068\n",
            "Epoch 631/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7283 - accuracy: 0.6978\n",
            "Epoch 632/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7235 - accuracy: 0.7030\n",
            "Epoch 633/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7339 - accuracy: 0.7015\n",
            "Epoch 634/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7283 - accuracy: 0.7028\n",
            "Epoch 635/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7285 - accuracy: 0.6983\n",
            "Epoch 636/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7241 - accuracy: 0.7041\n",
            "Epoch 637/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7246 - accuracy: 0.7059\n",
            "Epoch 638/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7291 - accuracy: 0.7009\n",
            "Epoch 639/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7247 - accuracy: 0.7016\n",
            "Epoch 640/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7283 - accuracy: 0.7032\n",
            "Epoch 641/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7329 - accuracy: 0.6996\n",
            "Epoch 642/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7257 - accuracy: 0.7024\n",
            "Epoch 643/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7268 - accuracy: 0.7028\n",
            "Epoch 644/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7239 - accuracy: 0.7041\n",
            "Epoch 645/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7288 - accuracy: 0.7014\n",
            "Epoch 646/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7292 - accuracy: 0.6986\n",
            "Epoch 647/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7266 - accuracy: 0.7036\n",
            "Epoch 648/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7253 - accuracy: 0.7019\n",
            "Epoch 649/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7271 - accuracy: 0.7013\n",
            "Epoch 650/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7218 - accuracy: 0.7040\n",
            "Epoch 651/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7204 - accuracy: 0.7056\n",
            "Epoch 652/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7243 - accuracy: 0.7022\n",
            "Epoch 653/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7326 - accuracy: 0.7001\n",
            "Epoch 654/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7233 - accuracy: 0.7017\n",
            "Epoch 655/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7310 - accuracy: 0.6995\n",
            "Epoch 656/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7170 - accuracy: 0.7048\n",
            "Epoch 657/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7259 - accuracy: 0.7036\n",
            "Epoch 658/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7236 - accuracy: 0.7019\n",
            "Epoch 659/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7234 - accuracy: 0.7027\n",
            "Epoch 660/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7208 - accuracy: 0.7019\n",
            "Epoch 661/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7298 - accuracy: 0.7027\n",
            "Epoch 662/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7267 - accuracy: 0.7002\n",
            "Epoch 663/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7255 - accuracy: 0.7034\n",
            "Epoch 664/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7241 - accuracy: 0.7030\n",
            "Epoch 665/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7259 - accuracy: 0.7016\n",
            "Epoch 666/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7236 - accuracy: 0.7029\n",
            "Epoch 667/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7255 - accuracy: 0.7001\n",
            "Epoch 668/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7211 - accuracy: 0.7033\n",
            "Epoch 669/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7221 - accuracy: 0.7045\n",
            "Epoch 670/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7317 - accuracy: 0.6992\n",
            "Epoch 671/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7242 - accuracy: 0.7045\n",
            "Epoch 672/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7238 - accuracy: 0.7027\n",
            "Epoch 673/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7255 - accuracy: 0.7017\n",
            "Epoch 674/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7198 - accuracy: 0.7041\n",
            "Epoch 675/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7266 - accuracy: 0.7009\n",
            "Epoch 676/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7223 - accuracy: 0.7080\n",
            "Epoch 677/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7262 - accuracy: 0.7032\n",
            "Epoch 678/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7187 - accuracy: 0.7048\n",
            "Epoch 679/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7272 - accuracy: 0.7036\n",
            "Epoch 680/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7208 - accuracy: 0.7063\n",
            "Epoch 681/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7228 - accuracy: 0.7048\n",
            "Epoch 682/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7267 - accuracy: 0.7011\n",
            "Epoch 683/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7243 - accuracy: 0.7018\n",
            "Epoch 684/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7200 - accuracy: 0.7023\n",
            "Epoch 685/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7272 - accuracy: 0.7011\n",
            "Epoch 686/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7218 - accuracy: 0.7037\n",
            "Epoch 687/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7239 - accuracy: 0.7010\n",
            "Epoch 688/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7212 - accuracy: 0.7041\n",
            "Epoch 689/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7221 - accuracy: 0.7035\n",
            "Epoch 690/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7225 - accuracy: 0.7042\n",
            "Epoch 691/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7219 - accuracy: 0.7031\n",
            "Epoch 692/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7279 - accuracy: 0.6998\n",
            "Epoch 693/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7243 - accuracy: 0.7033\n",
            "Epoch 694/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7204 - accuracy: 0.7036\n",
            "Epoch 695/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7170 - accuracy: 0.7063\n",
            "Epoch 696/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7215 - accuracy: 0.7039\n",
            "Epoch 697/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7261 - accuracy: 0.7027\n",
            "Epoch 698/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7250 - accuracy: 0.7017\n",
            "Epoch 699/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7181 - accuracy: 0.7035\n",
            "Epoch 700/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7240 - accuracy: 0.7031\n",
            "Epoch 701/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7253 - accuracy: 0.7017\n",
            "Epoch 702/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7187 - accuracy: 0.7041\n",
            "Epoch 703/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7274 - accuracy: 0.7011\n",
            "Epoch 704/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7305 - accuracy: 0.7026\n",
            "Epoch 705/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7229 - accuracy: 0.7018\n",
            "Epoch 706/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7248 - accuracy: 0.7012\n",
            "Epoch 707/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7233 - accuracy: 0.7025\n",
            "Epoch 708/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7184 - accuracy: 0.7054\n",
            "Epoch 709/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7243 - accuracy: 0.7013\n",
            "Epoch 710/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7162 - accuracy: 0.7065\n",
            "Epoch 711/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7190 - accuracy: 0.7072\n",
            "Epoch 712/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7179 - accuracy: 0.7058\n",
            "Epoch 713/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7267 - accuracy: 0.7000\n",
            "Epoch 714/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7160 - accuracy: 0.7070\n",
            "Epoch 715/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7249 - accuracy: 0.7002\n",
            "Epoch 716/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7148 - accuracy: 0.7046\n",
            "Epoch 717/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7246 - accuracy: 0.7007\n",
            "Epoch 718/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7195 - accuracy: 0.7047\n",
            "Epoch 719/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7212 - accuracy: 0.7045\n",
            "Epoch 720/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7214 - accuracy: 0.7032\n",
            "Epoch 721/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7239 - accuracy: 0.7018\n",
            "Epoch 722/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7201 - accuracy: 0.7032\n",
            "Epoch 723/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7158 - accuracy: 0.7073\n",
            "Epoch 724/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7172 - accuracy: 0.7056\n",
            "Epoch 725/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7172 - accuracy: 0.7043\n",
            "Epoch 726/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7255 - accuracy: 0.7037\n",
            "Epoch 727/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7169 - accuracy: 0.7047\n",
            "Epoch 728/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7225 - accuracy: 0.7008\n",
            "Epoch 729/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7169 - accuracy: 0.7029\n",
            "Epoch 730/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7187 - accuracy: 0.7069\n",
            "Epoch 731/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7209 - accuracy: 0.7022\n",
            "Epoch 732/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7254 - accuracy: 0.7012\n",
            "Epoch 733/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7177 - accuracy: 0.7071\n",
            "Epoch 734/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7229 - accuracy: 0.7035\n",
            "Epoch 735/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7167 - accuracy: 0.7028\n",
            "Epoch 736/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7200 - accuracy: 0.7037\n",
            "Epoch 737/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7241 - accuracy: 0.7006\n",
            "Epoch 738/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7176 - accuracy: 0.7036\n",
            "Epoch 739/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7215 - accuracy: 0.7043\n",
            "Epoch 740/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7180 - accuracy: 0.7040\n",
            "Epoch 741/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7243 - accuracy: 0.7018\n",
            "Epoch 742/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7219 - accuracy: 0.7042\n",
            "Epoch 743/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7164 - accuracy: 0.7035\n",
            "Epoch 744/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7190 - accuracy: 0.7050\n",
            "Epoch 745/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7199 - accuracy: 0.7056\n",
            "Epoch 746/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7222 - accuracy: 0.7044\n",
            "Epoch 747/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7188 - accuracy: 0.7034\n",
            "Epoch 748/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7187 - accuracy: 0.7055\n",
            "Epoch 749/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7206 - accuracy: 0.7042\n",
            "Epoch 750/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7199 - accuracy: 0.7037\n",
            "Epoch 751/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7175 - accuracy: 0.7053\n",
            "Epoch 752/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7170 - accuracy: 0.7054\n",
            "Epoch 753/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7196 - accuracy: 0.7035\n",
            "Epoch 754/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7198 - accuracy: 0.7018\n",
            "Epoch 755/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7090 - accuracy: 0.7088\n",
            "Epoch 756/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7176 - accuracy: 0.7043\n",
            "Epoch 757/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7230 - accuracy: 0.7048\n",
            "Epoch 758/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7217 - accuracy: 0.7038\n",
            "Epoch 759/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7236 - accuracy: 0.7006\n",
            "Epoch 760/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7186 - accuracy: 0.7050\n",
            "Epoch 761/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7191 - accuracy: 0.7050\n",
            "Epoch 762/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7133 - accuracy: 0.7068\n",
            "Epoch 763/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7172 - accuracy: 0.7080\n",
            "Epoch 764/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7277 - accuracy: 0.7001\n",
            "Epoch 765/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7153 - accuracy: 0.7056\n",
            "Epoch 766/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7180 - accuracy: 0.7033\n",
            "Epoch 767/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7221 - accuracy: 0.7021\n",
            "Epoch 768/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7242 - accuracy: 0.7041\n",
            "Epoch 769/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7110 - accuracy: 0.7075\n",
            "Epoch 770/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7200 - accuracy: 0.7037\n",
            "Epoch 771/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7160 - accuracy: 0.7053\n",
            "Epoch 772/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7203 - accuracy: 0.7033\n",
            "Epoch 773/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7166 - accuracy: 0.7051\n",
            "Epoch 774/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7079 - accuracy: 0.7091\n",
            "Epoch 775/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7107 - accuracy: 0.7094\n",
            "Epoch 776/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7221 - accuracy: 0.7024\n",
            "Epoch 777/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7123 - accuracy: 0.7070\n",
            "Epoch 778/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7173 - accuracy: 0.7057\n",
            "Epoch 779/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7062 - accuracy: 0.7089\n",
            "Epoch 780/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7145 - accuracy: 0.7042\n",
            "Epoch 781/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7206 - accuracy: 0.7044\n",
            "Epoch 782/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7130 - accuracy: 0.7044\n",
            "Epoch 783/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7141 - accuracy: 0.7056\n",
            "Epoch 784/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7162 - accuracy: 0.7064\n",
            "Epoch 785/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7192 - accuracy: 0.7042\n",
            "Epoch 786/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7144 - accuracy: 0.7068\n",
            "Epoch 787/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7196 - accuracy: 0.7061\n",
            "Epoch 788/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7059 - accuracy: 0.7078\n",
            "Epoch 789/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7194 - accuracy: 0.7044\n",
            "Epoch 790/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7126 - accuracy: 0.7047\n",
            "Epoch 791/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7170 - accuracy: 0.7057\n",
            "Epoch 792/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7128 - accuracy: 0.7052\n",
            "Epoch 793/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7108 - accuracy: 0.7092\n",
            "Epoch 794/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7151 - accuracy: 0.7090\n",
            "Epoch 795/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7143 - accuracy: 0.7052\n",
            "Epoch 796/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7131 - accuracy: 0.7072\n",
            "Epoch 797/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7192 - accuracy: 0.7044\n",
            "Epoch 798/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7159 - accuracy: 0.7041\n",
            "Epoch 799/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7142 - accuracy: 0.7073\n",
            "Epoch 800/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7124 - accuracy: 0.7048\n",
            "Epoch 801/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7070 - accuracy: 0.7073\n",
            "Epoch 802/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7155 - accuracy: 0.7107\n",
            "Epoch 803/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7170 - accuracy: 0.7072\n",
            "Epoch 804/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7218 - accuracy: 0.7043\n",
            "Epoch 805/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7197 - accuracy: 0.7063\n",
            "Epoch 806/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7076 - accuracy: 0.7094\n",
            "Epoch 807/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7103 - accuracy: 0.7091\n",
            "Epoch 808/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7162 - accuracy: 0.7043\n",
            "Epoch 809/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7153 - accuracy: 0.7054\n",
            "Epoch 810/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7205 - accuracy: 0.7030\n",
            "Epoch 811/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7194 - accuracy: 0.7042\n",
            "Epoch 812/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7097 - accuracy: 0.7067\n",
            "Epoch 813/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7088 - accuracy: 0.7082\n",
            "Epoch 814/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7135 - accuracy: 0.7043\n",
            "Epoch 815/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7091 - accuracy: 0.7083\n",
            "Epoch 816/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7141 - accuracy: 0.7076\n",
            "Epoch 817/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7087 - accuracy: 0.7108\n",
            "Epoch 818/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7077 - accuracy: 0.7075\n",
            "Epoch 819/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7106 - accuracy: 0.7091\n",
            "Epoch 820/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7188 - accuracy: 0.7038\n",
            "Epoch 821/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7143 - accuracy: 0.7053\n",
            "Epoch 822/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7142 - accuracy: 0.7066\n",
            "Epoch 823/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7193 - accuracy: 0.7052\n",
            "Epoch 824/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7184 - accuracy: 0.7010\n",
            "Epoch 825/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7106 - accuracy: 0.7073\n",
            "Epoch 826/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7132 - accuracy: 0.7090\n",
            "Epoch 827/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7116 - accuracy: 0.7067\n",
            "Epoch 828/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7105 - accuracy: 0.7075\n",
            "Epoch 829/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7185 - accuracy: 0.7035\n",
            "Epoch 830/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7185 - accuracy: 0.7042\n",
            "Epoch 831/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7171 - accuracy: 0.7056\n",
            "Epoch 832/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7147 - accuracy: 0.7048\n",
            "Epoch 833/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7174 - accuracy: 0.7040\n",
            "Epoch 834/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7145 - accuracy: 0.7069\n",
            "Epoch 835/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7143 - accuracy: 0.7059\n",
            "Epoch 836/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7092\n",
            "Epoch 837/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7135 - accuracy: 0.7069\n",
            "Epoch 838/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7077 - accuracy: 0.7070\n",
            "Epoch 839/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7107 - accuracy: 0.7058\n",
            "Epoch 840/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7203 - accuracy: 0.7046\n",
            "Epoch 841/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7128 - accuracy: 0.7069\n",
            "Epoch 842/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7090 - accuracy: 0.7108\n",
            "Epoch 843/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7165 - accuracy: 0.7074\n",
            "Epoch 844/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7119 - accuracy: 0.7075\n",
            "Epoch 845/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7147 - accuracy: 0.7057\n",
            "Epoch 846/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7162 - accuracy: 0.7064\n",
            "Epoch 847/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7136 - accuracy: 0.7075\n",
            "Epoch 848/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7122 - accuracy: 0.7080\n",
            "Epoch 849/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7028 - accuracy: 0.7112\n",
            "Epoch 850/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7087 - accuracy: 0.7106\n",
            "Epoch 851/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7118 - accuracy: 0.7072\n",
            "Epoch 852/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7130 - accuracy: 0.7070\n",
            "Epoch 853/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7163 - accuracy: 0.7045\n",
            "Epoch 854/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7074 - accuracy: 0.7092\n",
            "Epoch 855/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7101 - accuracy: 0.7076\n",
            "Epoch 856/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7132 - accuracy: 0.7081\n",
            "Epoch 857/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7134 - accuracy: 0.7079\n",
            "Epoch 858/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7069 - accuracy: 0.7086\n",
            "Epoch 859/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7163 - accuracy: 0.7078\n",
            "Epoch 860/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7127 - accuracy: 0.7067\n",
            "Epoch 861/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7087 - accuracy: 0.7063\n",
            "Epoch 862/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7126 - accuracy: 0.7088\n",
            "Epoch 863/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7169 - accuracy: 0.7050\n",
            "Epoch 864/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7097\n",
            "Epoch 865/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7143 - accuracy: 0.7052\n",
            "Epoch 866/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7090 - accuracy: 0.7106\n",
            "Epoch 867/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7075 - accuracy: 0.7084\n",
            "Epoch 868/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7105 - accuracy: 0.7118\n",
            "Epoch 869/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7118 - accuracy: 0.7043\n",
            "Epoch 870/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7107 - accuracy: 0.7057\n",
            "Epoch 871/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7095\n",
            "Epoch 872/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7127 - accuracy: 0.7072\n",
            "Epoch 873/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7184 - accuracy: 0.7077\n",
            "Epoch 874/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7118 - accuracy: 0.7047\n",
            "Epoch 875/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7139 - accuracy: 0.7051\n",
            "Epoch 876/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7072\n",
            "Epoch 877/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7073 - accuracy: 0.7084\n",
            "Epoch 878/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7137 - accuracy: 0.7052\n",
            "Epoch 879/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7150 - accuracy: 0.7073\n",
            "Epoch 880/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7116 - accuracy: 0.7078\n",
            "Epoch 881/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7126 - accuracy: 0.7056\n",
            "Epoch 882/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7122 - accuracy: 0.7073\n",
            "Epoch 883/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7197 - accuracy: 0.7053\n",
            "Epoch 884/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7072 - accuracy: 0.7110\n",
            "Epoch 885/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7126 - accuracy: 0.7074\n",
            "Epoch 886/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7152 - accuracy: 0.7035\n",
            "Epoch 887/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7117 - accuracy: 0.7066\n",
            "Epoch 888/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7150 - accuracy: 0.7048\n",
            "Epoch 889/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7070 - accuracy: 0.7076\n",
            "Epoch 890/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7110 - accuracy: 0.7078\n",
            "Epoch 891/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7095 - accuracy: 0.7061\n",
            "Epoch 892/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7181 - accuracy: 0.7040\n",
            "Epoch 893/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7086 - accuracy: 0.7085\n",
            "Epoch 894/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7115 - accuracy: 0.7069\n",
            "Epoch 895/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7103 - accuracy: 0.7069\n",
            "Epoch 896/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7128 - accuracy: 0.7059\n",
            "Epoch 897/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7084 - accuracy: 0.7091\n",
            "Epoch 898/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7054 - accuracy: 0.7092\n",
            "Epoch 899/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7121 - accuracy: 0.7086\n",
            "Epoch 900/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7110 - accuracy: 0.7070\n",
            "Epoch 901/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7073 - accuracy: 0.7091\n",
            "Epoch 902/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7093 - accuracy: 0.7079\n",
            "Epoch 903/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7116 - accuracy: 0.7055\n",
            "Epoch 904/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7138 - accuracy: 0.7061\n",
            "Epoch 905/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7037 - accuracy: 0.7114\n",
            "Epoch 906/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7085 - accuracy: 0.7062\n",
            "Epoch 907/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7141 - accuracy: 0.7062\n",
            "Epoch 908/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7076 - accuracy: 0.7087\n",
            "Epoch 909/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7151 - accuracy: 0.7045\n",
            "Epoch 910/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7094 - accuracy: 0.7093\n",
            "Epoch 911/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7050 - accuracy: 0.7104\n",
            "Epoch 912/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7101 - accuracy: 0.7056\n",
            "Epoch 913/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7068 - accuracy: 0.7080\n",
            "Epoch 914/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7137 - accuracy: 0.7051\n",
            "Epoch 915/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7102 - accuracy: 0.7069\n",
            "Epoch 916/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7085 - accuracy: 0.7068\n",
            "Epoch 917/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7116 - accuracy: 0.7061\n",
            "Epoch 918/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7087\n",
            "Epoch 919/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7136 - accuracy: 0.7069\n",
            "Epoch 920/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7055 - accuracy: 0.7103\n",
            "Epoch 921/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7105\n",
            "Epoch 922/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7116 - accuracy: 0.7063\n",
            "Epoch 923/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7051 - accuracy: 0.7062\n",
            "Epoch 924/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7067 - accuracy: 0.7088\n",
            "Epoch 925/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7117 - accuracy: 0.7098\n",
            "Epoch 926/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7087 - accuracy: 0.7082\n",
            "Epoch 927/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7069 - accuracy: 0.7086\n",
            "Epoch 928/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7080 - accuracy: 0.7074\n",
            "Epoch 929/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7092 - accuracy: 0.7086\n",
            "Epoch 930/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7095 - accuracy: 0.7047\n",
            "Epoch 931/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7082 - accuracy: 0.7084\n",
            "Epoch 932/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7062 - accuracy: 0.7102\n",
            "Epoch 933/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7084 - accuracy: 0.7105\n",
            "Epoch 934/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7086 - accuracy: 0.7084\n",
            "Epoch 935/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7042 - accuracy: 0.7094\n",
            "Epoch 936/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7091 - accuracy: 0.7083\n",
            "Epoch 937/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7081 - accuracy: 0.7086\n",
            "Epoch 938/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7098 - accuracy: 0.7058\n",
            "Epoch 939/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7084\n",
            "Epoch 940/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7032 - accuracy: 0.7097\n",
            "Epoch 941/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7079 - accuracy: 0.7078\n",
            "Epoch 942/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6989 - accuracy: 0.7101\n",
            "Epoch 943/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7088 - accuracy: 0.7087\n",
            "Epoch 944/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7124 - accuracy: 0.7059\n",
            "Epoch 945/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7060 - accuracy: 0.7083\n",
            "Epoch 946/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7114 - accuracy: 0.7071\n",
            "Epoch 947/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7088 - accuracy: 0.7076\n",
            "Epoch 948/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7082 - accuracy: 0.7105\n",
            "Epoch 949/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7054 - accuracy: 0.7076\n",
            "Epoch 950/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7085\n",
            "Epoch 951/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7063 - accuracy: 0.7111\n",
            "Epoch 952/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7122 - accuracy: 0.7051\n",
            "Epoch 953/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7039 - accuracy: 0.7109\n",
            "Epoch 954/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7041 - accuracy: 0.7070\n",
            "Epoch 955/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7093 - accuracy: 0.7089\n",
            "Epoch 956/3000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.7114 - accuracy: 0.7055\n",
            "Epoch 957/3000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.7025 - accuracy: 0.7101\n",
            "Epoch 958/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7063 - accuracy: 0.7092\n",
            "Epoch 959/3000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.7054 - accuracy: 0.7075\n",
            "Epoch 960/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7020 - accuracy: 0.7113\n",
            "Epoch 961/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7102 - accuracy: 0.7062\n",
            "Epoch 962/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7063 - accuracy: 0.7080\n",
            "Epoch 963/3000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7166 - accuracy: 0.7036\n",
            "Epoch 964/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6988 - accuracy: 0.7120\n",
            "Epoch 965/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6983 - accuracy: 0.7130\n",
            "Epoch 966/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7101\n",
            "Epoch 967/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7067 - accuracy: 0.7076\n",
            "Epoch 968/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7142 - accuracy: 0.7065\n",
            "Epoch 969/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7094 - accuracy: 0.7069\n",
            "Epoch 970/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7014 - accuracy: 0.7120\n",
            "Epoch 971/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7152 - accuracy: 0.7043\n",
            "Epoch 972/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7065 - accuracy: 0.7099\n",
            "Epoch 973/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7076 - accuracy: 0.7078\n",
            "Epoch 974/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7074 - accuracy: 0.7082\n",
            "Epoch 975/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7151 - accuracy: 0.7051\n",
            "Epoch 976/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7112 - accuracy: 0.7072\n",
            "Epoch 977/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7032 - accuracy: 0.7104\n",
            "Epoch 978/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7111 - accuracy: 0.7060\n",
            "Epoch 979/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7084\n",
            "Epoch 980/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7071 - accuracy: 0.7101\n",
            "Epoch 981/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7087 - accuracy: 0.7077\n",
            "Epoch 982/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7076 - accuracy: 0.7083\n",
            "Epoch 983/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6999 - accuracy: 0.7114\n",
            "Epoch 984/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7114 - accuracy: 0.7056\n",
            "Epoch 985/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7067\n",
            "Epoch 986/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7099 - accuracy: 0.7087\n",
            "Epoch 987/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7113 - accuracy: 0.7075\n",
            "Epoch 988/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7037 - accuracy: 0.7071\n",
            "Epoch 989/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7029 - accuracy: 0.7111\n",
            "Epoch 990/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7089 - accuracy: 0.7073\n",
            "Epoch 991/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7061 - accuracy: 0.7072\n",
            "Epoch 992/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7094\n",
            "Epoch 993/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7013 - accuracy: 0.7125\n",
            "Epoch 994/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7064 - accuracy: 0.7104\n",
            "Epoch 995/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7003 - accuracy: 0.7103\n",
            "Epoch 996/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7104 - accuracy: 0.7090\n",
            "Epoch 997/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7039 - accuracy: 0.7065\n",
            "Epoch 998/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7106 - accuracy: 0.7084\n",
            "Epoch 999/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7083\n",
            "Epoch 1000/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6975 - accuracy: 0.7134\n",
            "Epoch 1001/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7035 - accuracy: 0.7085\n",
            "Epoch 1002/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7067 - accuracy: 0.7094\n",
            "Epoch 1003/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7025 - accuracy: 0.7094\n",
            "Epoch 1004/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7057 - accuracy: 0.7096\n",
            "Epoch 1005/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7059 - accuracy: 0.7079\n",
            "Epoch 1006/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7046 - accuracy: 0.7088\n",
            "Epoch 1007/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7068 - accuracy: 0.7093\n",
            "Epoch 1008/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7037 - accuracy: 0.7110\n",
            "Epoch 1009/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7110\n",
            "Epoch 1010/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7084 - accuracy: 0.7071\n",
            "Epoch 1011/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7030 - accuracy: 0.7104\n",
            "Epoch 1012/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7105\n",
            "Epoch 1013/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7064 - accuracy: 0.7085\n",
            "Epoch 1014/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7038 - accuracy: 0.7070\n",
            "Epoch 1015/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7062 - accuracy: 0.7088\n",
            "Epoch 1016/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7048 - accuracy: 0.7084\n",
            "Epoch 1017/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7108\n",
            "Epoch 1018/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7030 - accuracy: 0.7089\n",
            "Epoch 1019/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7098 - accuracy: 0.7100\n",
            "Epoch 1020/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7113 - accuracy: 0.7064\n",
            "Epoch 1021/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7077 - accuracy: 0.7093\n",
            "Epoch 1022/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7075 - accuracy: 0.7087\n",
            "Epoch 1023/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7065 - accuracy: 0.7104\n",
            "Epoch 1024/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7091 - accuracy: 0.7067\n",
            "Epoch 1025/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7125\n",
            "Epoch 1026/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6965 - accuracy: 0.7142\n",
            "Epoch 1027/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7119 - accuracy: 0.7052\n",
            "Epoch 1028/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7062 - accuracy: 0.7080\n",
            "Epoch 1029/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7056 - accuracy: 0.7088\n",
            "Epoch 1030/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7115\n",
            "Epoch 1031/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6976 - accuracy: 0.7140\n",
            "Epoch 1032/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7100 - accuracy: 0.7095\n",
            "Epoch 1033/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7039 - accuracy: 0.7105\n",
            "Epoch 1034/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6994 - accuracy: 0.7120\n",
            "Epoch 1035/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6920 - accuracy: 0.7153\n",
            "Epoch 1036/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.7103 - accuracy: 0.7052\n",
            "Epoch 1037/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7039 - accuracy: 0.7063\n",
            "Epoch 1038/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7055\n",
            "Epoch 1039/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7083 - accuracy: 0.7057\n",
            "Epoch 1040/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7040 - accuracy: 0.7100\n",
            "Epoch 1041/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7067 - accuracy: 0.7090\n",
            "Epoch 1042/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7086 - accuracy: 0.7072\n",
            "Epoch 1043/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7104\n",
            "Epoch 1044/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6969 - accuracy: 0.7131\n",
            "Epoch 1045/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7052 - accuracy: 0.7100\n",
            "Epoch 1046/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6986 - accuracy: 0.7128\n",
            "Epoch 1047/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6998 - accuracy: 0.7095\n",
            "Epoch 1048/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7032 - accuracy: 0.7081\n",
            "Epoch 1049/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7014 - accuracy: 0.7137\n",
            "Epoch 1050/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7070 - accuracy: 0.7093\n",
            "Epoch 1051/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7021 - accuracy: 0.7094\n",
            "Epoch 1052/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7074 - accuracy: 0.7084\n",
            "Epoch 1053/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7091 - accuracy: 0.7098\n",
            "Epoch 1054/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6977 - accuracy: 0.7118\n",
            "Epoch 1055/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7069 - accuracy: 0.7099\n",
            "Epoch 1056/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7057 - accuracy: 0.7104\n",
            "Epoch 1057/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6966 - accuracy: 0.7122\n",
            "Epoch 1058/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7044 - accuracy: 0.7095\n",
            "Epoch 1059/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7048 - accuracy: 0.7081\n",
            "Epoch 1060/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7036 - accuracy: 0.7094\n",
            "Epoch 1061/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7040 - accuracy: 0.7085\n",
            "Epoch 1062/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7083 - accuracy: 0.7077\n",
            "Epoch 1063/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7048 - accuracy: 0.7069\n",
            "Epoch 1064/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7056 - accuracy: 0.7095\n",
            "Epoch 1065/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6966 - accuracy: 0.7095\n",
            "Epoch 1066/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6975 - accuracy: 0.7114\n",
            "Epoch 1067/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7049 - accuracy: 0.7114\n",
            "Epoch 1068/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7020 - accuracy: 0.7103\n",
            "Epoch 1069/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7096 - accuracy: 0.7060\n",
            "Epoch 1070/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7046 - accuracy: 0.7111\n",
            "Epoch 1071/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7028 - accuracy: 0.7097\n",
            "Epoch 1072/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7044 - accuracy: 0.7099\n",
            "Epoch 1073/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7071 - accuracy: 0.7090\n",
            "Epoch 1074/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7024 - accuracy: 0.7114\n",
            "Epoch 1075/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6995 - accuracy: 0.7089\n",
            "Epoch 1076/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7121\n",
            "Epoch 1077/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6989 - accuracy: 0.7099\n",
            "Epoch 1078/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7012 - accuracy: 0.7108\n",
            "Epoch 1079/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7069 - accuracy: 0.7097\n",
            "Epoch 1080/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7145\n",
            "Epoch 1081/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7041 - accuracy: 0.7108\n",
            "Epoch 1082/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7007 - accuracy: 0.7107\n",
            "Epoch 1083/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6996 - accuracy: 0.7122\n",
            "Epoch 1084/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7114\n",
            "Epoch 1085/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7162\n",
            "Epoch 1086/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7028 - accuracy: 0.7092\n",
            "Epoch 1087/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7098 - accuracy: 0.7084\n",
            "Epoch 1088/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7092 - accuracy: 0.7052\n",
            "Epoch 1089/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7076 - accuracy: 0.7084\n",
            "Epoch 1090/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6990 - accuracy: 0.7109\n",
            "Epoch 1091/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6977 - accuracy: 0.7108\n",
            "Epoch 1092/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6959 - accuracy: 0.7133\n",
            "Epoch 1093/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6979 - accuracy: 0.7122\n",
            "Epoch 1094/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7002 - accuracy: 0.7128\n",
            "Epoch 1095/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6980 - accuracy: 0.7140\n",
            "Epoch 1096/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7031 - accuracy: 0.7136\n",
            "Epoch 1097/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7072 - accuracy: 0.7085\n",
            "Epoch 1098/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7035 - accuracy: 0.7111\n",
            "Epoch 1099/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7075 - accuracy: 0.7090\n",
            "Epoch 1100/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7121\n",
            "Epoch 1101/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6989 - accuracy: 0.7100\n",
            "Epoch 1102/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7001 - accuracy: 0.7114\n",
            "Epoch 1103/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6951 - accuracy: 0.7144\n",
            "Epoch 1104/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7015 - accuracy: 0.7098\n",
            "Epoch 1105/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7150\n",
            "Epoch 1106/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6995 - accuracy: 0.7113\n",
            "Epoch 1107/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6965 - accuracy: 0.7119\n",
            "Epoch 1108/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7037 - accuracy: 0.7091\n",
            "Epoch 1109/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7007 - accuracy: 0.7106\n",
            "Epoch 1110/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7030 - accuracy: 0.7097\n",
            "Epoch 1111/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6978 - accuracy: 0.7117\n",
            "Epoch 1112/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6976 - accuracy: 0.7136\n",
            "Epoch 1113/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7062 - accuracy: 0.7129\n",
            "Epoch 1114/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7010 - accuracy: 0.7101\n",
            "Epoch 1115/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6972 - accuracy: 0.7129\n",
            "Epoch 1116/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7073 - accuracy: 0.7107\n",
            "Epoch 1117/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7005 - accuracy: 0.7109\n",
            "Epoch 1118/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7113\n",
            "Epoch 1119/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7024 - accuracy: 0.7113\n",
            "Epoch 1120/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7010 - accuracy: 0.7122\n",
            "Epoch 1121/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7070 - accuracy: 0.7087\n",
            "Epoch 1122/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7039 - accuracy: 0.7100\n",
            "Epoch 1123/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7054 - accuracy: 0.7093\n",
            "Epoch 1124/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6956 - accuracy: 0.7132\n",
            "Epoch 1125/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7041 - accuracy: 0.7072\n",
            "Epoch 1126/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7094\n",
            "Epoch 1127/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7018 - accuracy: 0.7107\n",
            "Epoch 1128/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6963 - accuracy: 0.7103\n",
            "Epoch 1129/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7108\n",
            "Epoch 1130/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7126\n",
            "Epoch 1131/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6960 - accuracy: 0.7126\n",
            "Epoch 1132/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7023 - accuracy: 0.7108\n",
            "Epoch 1133/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7008 - accuracy: 0.7118\n",
            "Epoch 1134/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6996 - accuracy: 0.7121\n",
            "Epoch 1135/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7095 - accuracy: 0.7077\n",
            "Epoch 1136/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7003 - accuracy: 0.7092\n",
            "Epoch 1137/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6930 - accuracy: 0.7127\n",
            "Epoch 1138/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7124\n",
            "Epoch 1139/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7000 - accuracy: 0.7088\n",
            "Epoch 1140/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7130\n",
            "Epoch 1141/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7056 - accuracy: 0.7110\n",
            "Epoch 1142/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7034 - accuracy: 0.7097\n",
            "Epoch 1143/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7027 - accuracy: 0.7116\n",
            "Epoch 1144/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6966 - accuracy: 0.7133\n",
            "Epoch 1145/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7001 - accuracy: 0.7098\n",
            "Epoch 1146/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6931 - accuracy: 0.7146\n",
            "Epoch 1147/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7120\n",
            "Epoch 1148/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7134\n",
            "Epoch 1149/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7000 - accuracy: 0.7118\n",
            "Epoch 1150/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7109\n",
            "Epoch 1151/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7020 - accuracy: 0.7102\n",
            "Epoch 1152/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6997 - accuracy: 0.7134\n",
            "Epoch 1153/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7119\n",
            "Epoch 1154/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7053 - accuracy: 0.7076\n",
            "Epoch 1155/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7145\n",
            "Epoch 1156/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7102\n",
            "Epoch 1157/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6994 - accuracy: 0.7125\n",
            "Epoch 1158/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7033 - accuracy: 0.7086\n",
            "Epoch 1159/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6976 - accuracy: 0.7122\n",
            "Epoch 1160/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6965 - accuracy: 0.7114\n",
            "Epoch 1161/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7147\n",
            "Epoch 1162/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7139\n",
            "Epoch 1163/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7113\n",
            "Epoch 1164/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6988 - accuracy: 0.7113\n",
            "Epoch 1165/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7020 - accuracy: 0.7095\n",
            "Epoch 1166/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6951 - accuracy: 0.7125\n",
            "Epoch 1167/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6992 - accuracy: 0.7113\n",
            "Epoch 1168/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7025 - accuracy: 0.7092\n",
            "Epoch 1169/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7147\n",
            "Epoch 1170/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7008 - accuracy: 0.7110\n",
            "Epoch 1171/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7140\n",
            "Epoch 1172/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7031 - accuracy: 0.7094\n",
            "Epoch 1173/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6977 - accuracy: 0.7123\n",
            "Epoch 1174/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7039 - accuracy: 0.7112\n",
            "Epoch 1175/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7090\n",
            "Epoch 1176/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7040 - accuracy: 0.7087\n",
            "Epoch 1177/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7010 - accuracy: 0.7075\n",
            "Epoch 1178/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6942 - accuracy: 0.7159\n",
            "Epoch 1179/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6917 - accuracy: 0.7155\n",
            "Epoch 1180/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7015 - accuracy: 0.7084\n",
            "Epoch 1181/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6968 - accuracy: 0.7121\n",
            "Epoch 1182/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6993 - accuracy: 0.7109\n",
            "Epoch 1183/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7031 - accuracy: 0.7112\n",
            "Epoch 1184/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6933 - accuracy: 0.7134\n",
            "Epoch 1185/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7103\n",
            "Epoch 1186/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6987 - accuracy: 0.7094\n",
            "Epoch 1187/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6982 - accuracy: 0.7109\n",
            "Epoch 1188/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6963 - accuracy: 0.7154\n",
            "Epoch 1189/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6969 - accuracy: 0.7117\n",
            "Epoch 1190/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7043 - accuracy: 0.7072\n",
            "Epoch 1191/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7037 - accuracy: 0.7071\n",
            "Epoch 1192/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6948 - accuracy: 0.7143\n",
            "Epoch 1193/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7057 - accuracy: 0.7096\n",
            "Epoch 1194/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6999 - accuracy: 0.7105\n",
            "Epoch 1195/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7001 - accuracy: 0.7103\n",
            "Epoch 1196/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6998 - accuracy: 0.7117\n",
            "Epoch 1197/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7000 - accuracy: 0.7110\n",
            "Epoch 1198/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7148\n",
            "Epoch 1199/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6963 - accuracy: 0.7124\n",
            "Epoch 1200/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6999 - accuracy: 0.7104\n",
            "Epoch 1201/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7030 - accuracy: 0.7096\n",
            "Epoch 1202/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6947 - accuracy: 0.7107\n",
            "Epoch 1203/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7138\n",
            "Epoch 1204/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6946 - accuracy: 0.7127\n",
            "Epoch 1205/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6936 - accuracy: 0.7135\n",
            "Epoch 1206/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6935 - accuracy: 0.7130\n",
            "Epoch 1207/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6988 - accuracy: 0.7135\n",
            "Epoch 1208/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7123\n",
            "Epoch 1209/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6974 - accuracy: 0.7130\n",
            "Epoch 1210/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7005 - accuracy: 0.7095\n",
            "Epoch 1211/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7004 - accuracy: 0.7130\n",
            "Epoch 1212/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6929 - accuracy: 0.7115\n",
            "Epoch 1213/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7167\n",
            "Epoch 1214/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7115\n",
            "Epoch 1215/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6953 - accuracy: 0.7124\n",
            "Epoch 1216/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7146\n",
            "Epoch 1217/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7105\n",
            "Epoch 1218/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6984 - accuracy: 0.7146\n",
            "Epoch 1219/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6964 - accuracy: 0.7140\n",
            "Epoch 1220/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7102\n",
            "Epoch 1221/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6944 - accuracy: 0.7129\n",
            "Epoch 1222/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7150\n",
            "Epoch 1223/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6969 - accuracy: 0.7125\n",
            "Epoch 1224/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7080 - accuracy: 0.7095\n",
            "Epoch 1225/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6981 - accuracy: 0.7142\n",
            "Epoch 1226/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7147\n",
            "Epoch 1227/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7103\n",
            "Epoch 1228/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6935 - accuracy: 0.7140\n",
            "Epoch 1229/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7011 - accuracy: 0.7105\n",
            "Epoch 1230/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6951 - accuracy: 0.7125\n",
            "Epoch 1231/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7148\n",
            "Epoch 1232/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6994 - accuracy: 0.7128\n",
            "Epoch 1233/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7108\n",
            "Epoch 1234/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6993 - accuracy: 0.7127\n",
            "Epoch 1235/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6939 - accuracy: 0.7138\n",
            "Epoch 1236/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6981 - accuracy: 0.7115\n",
            "Epoch 1237/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6952 - accuracy: 0.7148\n",
            "Epoch 1238/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6976 - accuracy: 0.7142\n",
            "Epoch 1239/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7124\n",
            "Epoch 1240/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6930 - accuracy: 0.7148\n",
            "Epoch 1241/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6975 - accuracy: 0.7111\n",
            "Epoch 1242/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6927 - accuracy: 0.7122\n",
            "Epoch 1243/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7005 - accuracy: 0.7112\n",
            "Epoch 1244/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7135\n",
            "Epoch 1245/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6939 - accuracy: 0.7140\n",
            "Epoch 1246/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7131\n",
            "Epoch 1247/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7122\n",
            "Epoch 1248/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6916 - accuracy: 0.7137\n",
            "Epoch 1249/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7034 - accuracy: 0.7132\n",
            "Epoch 1250/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6980 - accuracy: 0.7114\n",
            "Epoch 1251/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6948 - accuracy: 0.7141\n",
            "Epoch 1252/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6968 - accuracy: 0.7117\n",
            "Epoch 1253/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7005 - accuracy: 0.7119\n",
            "Epoch 1254/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7137\n",
            "Epoch 1255/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7124\n",
            "Epoch 1256/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6927 - accuracy: 0.7141\n",
            "Epoch 1257/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7004 - accuracy: 0.7100\n",
            "Epoch 1258/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7027 - accuracy: 0.7107\n",
            "Epoch 1259/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6978 - accuracy: 0.7131\n",
            "Epoch 1260/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6973 - accuracy: 0.7118\n",
            "Epoch 1261/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7040 - accuracy: 0.7117\n",
            "Epoch 1262/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7132\n",
            "Epoch 1263/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6930 - accuracy: 0.7137\n",
            "Epoch 1264/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6949 - accuracy: 0.7115\n",
            "Epoch 1265/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7031 - accuracy: 0.7105\n",
            "Epoch 1266/3000\n",
            "1000/1000 [==============================] - 7s 6ms/step - loss: 0.6888 - accuracy: 0.7164\n",
            "Epoch 1267/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6891 - accuracy: 0.7173\n",
            "Epoch 1268/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7121\n",
            "Epoch 1269/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6943 - accuracy: 0.7125\n",
            "Epoch 1270/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7156\n",
            "Epoch 1271/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6931 - accuracy: 0.7138\n",
            "Epoch 1272/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7110\n",
            "Epoch 1273/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7122\n",
            "Epoch 1274/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6975 - accuracy: 0.7144\n",
            "Epoch 1275/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7016 - accuracy: 0.7120\n",
            "Epoch 1276/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6895 - accuracy: 0.7166\n",
            "Epoch 1277/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6966 - accuracy: 0.7137\n",
            "Epoch 1278/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6898 - accuracy: 0.7120\n",
            "Epoch 1279/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6969 - accuracy: 0.7111\n",
            "Epoch 1280/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6990 - accuracy: 0.7122\n",
            "Epoch 1281/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6958 - accuracy: 0.7142\n",
            "Epoch 1282/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6957 - accuracy: 0.7109\n",
            "Epoch 1283/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6924 - accuracy: 0.7138\n",
            "Epoch 1284/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7099\n",
            "Epoch 1285/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7001 - accuracy: 0.7104\n",
            "Epoch 1286/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6879 - accuracy: 0.7146\n",
            "Epoch 1287/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6959 - accuracy: 0.7142\n",
            "Epoch 1288/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6953 - accuracy: 0.7134\n",
            "Epoch 1289/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7006 - accuracy: 0.7116\n",
            "Epoch 1290/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7001 - accuracy: 0.7121\n",
            "Epoch 1291/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7151\n",
            "Epoch 1292/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6933 - accuracy: 0.7136\n",
            "Epoch 1293/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6913 - accuracy: 0.7157\n",
            "Epoch 1294/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6983 - accuracy: 0.7101\n",
            "Epoch 1295/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6986 - accuracy: 0.7095\n",
            "Epoch 1296/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6956 - accuracy: 0.7117\n",
            "Epoch 1297/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7137\n",
            "Epoch 1298/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6963 - accuracy: 0.7108\n",
            "Epoch 1299/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6939 - accuracy: 0.7166\n",
            "Epoch 1300/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6943 - accuracy: 0.7143\n",
            "Epoch 1301/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6953 - accuracy: 0.7115\n",
            "Epoch 1302/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7133\n",
            "Epoch 1303/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6940 - accuracy: 0.7137\n",
            "Epoch 1304/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6951 - accuracy: 0.7099\n",
            "Epoch 1305/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7115\n",
            "Epoch 1306/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6924 - accuracy: 0.7151\n",
            "Epoch 1307/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7139\n",
            "Epoch 1308/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7020 - accuracy: 0.7099\n",
            "Epoch 1309/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7170\n",
            "Epoch 1310/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7109\n",
            "Epoch 1311/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6944 - accuracy: 0.7129\n",
            "Epoch 1312/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7162\n",
            "Epoch 1313/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6940 - accuracy: 0.7163\n",
            "Epoch 1314/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6939 - accuracy: 0.7114\n",
            "Epoch 1315/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6958 - accuracy: 0.7141\n",
            "Epoch 1316/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7160\n",
            "Epoch 1317/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6878 - accuracy: 0.7155\n",
            "Epoch 1318/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6943 - accuracy: 0.7144\n",
            "Epoch 1319/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6890 - accuracy: 0.7140\n",
            "Epoch 1320/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7136\n",
            "Epoch 1321/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6982 - accuracy: 0.7124\n",
            "Epoch 1322/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6946 - accuracy: 0.7111\n",
            "Epoch 1323/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6916 - accuracy: 0.7131\n",
            "Epoch 1324/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6946 - accuracy: 0.7127\n",
            "Epoch 1325/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6900 - accuracy: 0.7157\n",
            "Epoch 1326/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7119\n",
            "Epoch 1327/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7118\n",
            "Epoch 1328/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7114\n",
            "Epoch 1329/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7103\n",
            "Epoch 1330/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7136\n",
            "Epoch 1331/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6921 - accuracy: 0.7161\n",
            "Epoch 1332/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7115\n",
            "Epoch 1333/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6986 - accuracy: 0.7115\n",
            "Epoch 1334/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6849 - accuracy: 0.7158\n",
            "Epoch 1335/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7141\n",
            "Epoch 1336/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6922 - accuracy: 0.7144\n",
            "Epoch 1337/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6957 - accuracy: 0.7092\n",
            "Epoch 1338/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7169\n",
            "Epoch 1339/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6951 - accuracy: 0.7111\n",
            "Epoch 1340/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6899 - accuracy: 0.7131\n",
            "Epoch 1341/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6978 - accuracy: 0.7097\n",
            "Epoch 1342/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7157\n",
            "Epoch 1343/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7010 - accuracy: 0.7102\n",
            "Epoch 1344/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7131\n",
            "Epoch 1345/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7158\n",
            "Epoch 1346/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6893 - accuracy: 0.7138\n",
            "Epoch 1347/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6927 - accuracy: 0.7133\n",
            "Epoch 1348/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7136\n",
            "Epoch 1349/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7165\n",
            "Epoch 1350/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7132\n",
            "Epoch 1351/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6918 - accuracy: 0.7147\n",
            "Epoch 1352/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6958 - accuracy: 0.7139\n",
            "Epoch 1353/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6904 - accuracy: 0.7168\n",
            "Epoch 1354/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7142\n",
            "Epoch 1355/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7125\n",
            "Epoch 1356/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6981 - accuracy: 0.7130\n",
            "Epoch 1357/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7142\n",
            "Epoch 1358/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6899 - accuracy: 0.7143\n",
            "Epoch 1359/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6882 - accuracy: 0.7128\n",
            "Epoch 1360/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6979 - accuracy: 0.7131\n",
            "Epoch 1361/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7129\n",
            "Epoch 1362/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6942 - accuracy: 0.7139\n",
            "Epoch 1363/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6978 - accuracy: 0.7088\n",
            "Epoch 1364/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6974 - accuracy: 0.7117\n",
            "Epoch 1365/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6976 - accuracy: 0.7126\n",
            "Epoch 1366/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6947 - accuracy: 0.7128\n",
            "Epoch 1367/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7123\n",
            "Epoch 1368/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6990 - accuracy: 0.7122\n",
            "Epoch 1369/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6948 - accuracy: 0.7139\n",
            "Epoch 1370/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6949 - accuracy: 0.7150\n",
            "Epoch 1371/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7123\n",
            "Epoch 1372/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6979 - accuracy: 0.7118\n",
            "Epoch 1373/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6988 - accuracy: 0.7108\n",
            "Epoch 1374/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7159\n",
            "Epoch 1375/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7117\n",
            "Epoch 1376/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6978 - accuracy: 0.7123\n",
            "Epoch 1377/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6910 - accuracy: 0.7145\n",
            "Epoch 1378/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6917 - accuracy: 0.7145\n",
            "Epoch 1379/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6887 - accuracy: 0.7144\n",
            "Epoch 1380/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6956 - accuracy: 0.7127\n",
            "Epoch 1381/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7113\n",
            "Epoch 1382/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7132\n",
            "Epoch 1383/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7181\n",
            "Epoch 1384/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7131\n",
            "Epoch 1385/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7191\n",
            "Epoch 1386/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7154\n",
            "Epoch 1387/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6904 - accuracy: 0.7144\n",
            "Epoch 1388/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7164\n",
            "Epoch 1389/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6921 - accuracy: 0.7124\n",
            "Epoch 1390/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6882 - accuracy: 0.7156\n",
            "Epoch 1391/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6884 - accuracy: 0.7154\n",
            "Epoch 1392/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7114\n",
            "Epoch 1393/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6895 - accuracy: 0.7157\n",
            "Epoch 1394/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7147\n",
            "Epoch 1395/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7126\n",
            "Epoch 1396/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6942 - accuracy: 0.7136\n",
            "Epoch 1397/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6906 - accuracy: 0.7160\n",
            "Epoch 1398/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7136\n",
            "Epoch 1399/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.7132\n",
            "Epoch 1400/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6985 - accuracy: 0.7120\n",
            "Epoch 1401/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7133\n",
            "Epoch 1402/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6883 - accuracy: 0.7144\n",
            "Epoch 1403/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6880 - accuracy: 0.7165\n",
            "Epoch 1404/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7147\n",
            "Epoch 1405/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6941 - accuracy: 0.7144\n",
            "Epoch 1406/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6883 - accuracy: 0.7132\n",
            "Epoch 1407/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6785 - accuracy: 0.7186\n",
            "Epoch 1408/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6877 - accuracy: 0.7166\n",
            "Epoch 1409/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7117\n",
            "Epoch 1410/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7152\n",
            "Epoch 1411/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6963 - accuracy: 0.7136\n",
            "Epoch 1412/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7146\n",
            "Epoch 1413/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7137\n",
            "Epoch 1414/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7171\n",
            "Epoch 1415/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6938 - accuracy: 0.7131\n",
            "Epoch 1416/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7137\n",
            "Epoch 1417/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7134\n",
            "Epoch 1418/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6944 - accuracy: 0.7134\n",
            "Epoch 1419/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7115\n",
            "Epoch 1420/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6893 - accuracy: 0.7144\n",
            "Epoch 1421/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6987 - accuracy: 0.7109\n",
            "Epoch 1422/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6862 - accuracy: 0.7163\n",
            "Epoch 1423/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6956 - accuracy: 0.7101\n",
            "Epoch 1424/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6866 - accuracy: 0.7153\n",
            "Epoch 1425/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7130\n",
            "Epoch 1426/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7145\n",
            "Epoch 1427/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6907 - accuracy: 0.7129\n",
            "Epoch 1428/3000\n",
            "1000/1000 [==============================] - 7s 6ms/step - loss: 0.6912 - accuracy: 0.7140\n",
            "Epoch 1429/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6901 - accuracy: 0.7158\n",
            "Epoch 1430/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6829 - accuracy: 0.7140\n",
            "Epoch 1431/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7164\n",
            "Epoch 1432/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7137\n",
            "Epoch 1433/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6924 - accuracy: 0.7143\n",
            "Epoch 1434/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6920 - accuracy: 0.7123\n",
            "Epoch 1435/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6959 - accuracy: 0.7133\n",
            "Epoch 1436/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7148\n",
            "Epoch 1437/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7126\n",
            "Epoch 1438/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6920 - accuracy: 0.7153\n",
            "Epoch 1439/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6873 - accuracy: 0.7144\n",
            "Epoch 1440/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6920 - accuracy: 0.7177\n",
            "Epoch 1441/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7137\n",
            "Epoch 1442/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7131\n",
            "Epoch 1443/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6884 - accuracy: 0.7131\n",
            "Epoch 1444/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7113\n",
            "Epoch 1445/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7103\n",
            "Epoch 1446/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6916 - accuracy: 0.7133\n",
            "Epoch 1447/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6844 - accuracy: 0.7187\n",
            "Epoch 1448/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6916 - accuracy: 0.7141\n",
            "Epoch 1449/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7139\n",
            "Epoch 1450/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7133\n",
            "Epoch 1451/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6924 - accuracy: 0.7142\n",
            "Epoch 1452/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6912 - accuracy: 0.7147\n",
            "Epoch 1453/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7155\n",
            "Epoch 1454/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7152\n",
            "Epoch 1455/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6949 - accuracy: 0.7126\n",
            "Epoch 1456/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6868 - accuracy: 0.7144\n",
            "Epoch 1457/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6908 - accuracy: 0.7144\n",
            "Epoch 1458/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6939 - accuracy: 0.7150\n",
            "Epoch 1459/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7130\n",
            "Epoch 1460/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6950 - accuracy: 0.7133\n",
            "Epoch 1461/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6891 - accuracy: 0.7155\n",
            "Epoch 1462/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6889 - accuracy: 0.7169\n",
            "Epoch 1463/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6887 - accuracy: 0.7152\n",
            "Epoch 1464/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6962 - accuracy: 0.7114\n",
            "Epoch 1465/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7160\n",
            "Epoch 1466/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7137\n",
            "Epoch 1467/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6877 - accuracy: 0.7163\n",
            "Epoch 1468/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7120\n",
            "Epoch 1469/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7155\n",
            "Epoch 1470/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6943 - accuracy: 0.7137\n",
            "Epoch 1471/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6865 - accuracy: 0.7163\n",
            "Epoch 1472/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6878 - accuracy: 0.7145\n",
            "Epoch 1473/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6879 - accuracy: 0.7166\n",
            "Epoch 1474/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6981 - accuracy: 0.7118\n",
            "Epoch 1475/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7166\n",
            "Epoch 1476/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7139\n",
            "Epoch 1477/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7127\n",
            "Epoch 1478/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6847 - accuracy: 0.7168\n",
            "Epoch 1479/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6874 - accuracy: 0.7184\n",
            "Epoch 1480/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6955 - accuracy: 0.7133\n",
            "Epoch 1481/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7126\n",
            "Epoch 1482/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7140\n",
            "Epoch 1483/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7146\n",
            "Epoch 1484/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6848 - accuracy: 0.7160\n",
            "Epoch 1485/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6947 - accuracy: 0.7158\n",
            "Epoch 1486/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6953 - accuracy: 0.7118\n",
            "Epoch 1487/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7173\n",
            "Epoch 1488/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7132\n",
            "Epoch 1489/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6970 - accuracy: 0.7131\n",
            "Epoch 1490/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7103\n",
            "Epoch 1491/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6901 - accuracy: 0.7167\n",
            "Epoch 1492/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6851 - accuracy: 0.7167\n",
            "Epoch 1493/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7179\n",
            "Epoch 1494/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7138\n",
            "Epoch 1495/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6955 - accuracy: 0.7145\n",
            "Epoch 1496/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7148\n",
            "Epoch 1497/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6890 - accuracy: 0.7164\n",
            "Epoch 1498/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6866 - accuracy: 0.7164\n",
            "Epoch 1499/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6883 - accuracy: 0.7156\n",
            "Epoch 1500/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6898 - accuracy: 0.7133\n",
            "Epoch 1501/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6890 - accuracy: 0.7131\n",
            "Epoch 1502/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7167\n",
            "Epoch 1503/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6977 - accuracy: 0.7114\n",
            "Epoch 1504/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6904 - accuracy: 0.7141\n",
            "Epoch 1505/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6867 - accuracy: 0.7145\n",
            "Epoch 1506/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7168\n",
            "Epoch 1507/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7138\n",
            "Epoch 1508/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6903 - accuracy: 0.7152\n",
            "Epoch 1509/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6931 - accuracy: 0.7122\n",
            "Epoch 1510/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6973 - accuracy: 0.7118\n",
            "Epoch 1511/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6954 - accuracy: 0.7123\n",
            "Epoch 1512/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7124\n",
            "Epoch 1513/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6869 - accuracy: 0.7179\n",
            "Epoch 1514/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6961 - accuracy: 0.7140\n",
            "Epoch 1515/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6846 - accuracy: 0.7195\n",
            "Epoch 1516/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6874 - accuracy: 0.7169\n",
            "Epoch 1517/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6916 - accuracy: 0.7126\n",
            "Epoch 1518/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6867 - accuracy: 0.7146\n",
            "Epoch 1519/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6897 - accuracy: 0.7121\n",
            "Epoch 1520/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7173\n",
            "Epoch 1521/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6869 - accuracy: 0.7146\n",
            "Epoch 1522/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6901 - accuracy: 0.7126\n",
            "Epoch 1523/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6934 - accuracy: 0.7138\n",
            "Epoch 1524/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7155\n",
            "Epoch 1525/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7144\n",
            "Epoch 1526/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6818 - accuracy: 0.7150\n",
            "Epoch 1527/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6852 - accuracy: 0.7141\n",
            "Epoch 1528/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6920 - accuracy: 0.7150\n",
            "Epoch 1529/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6926 - accuracy: 0.7143\n",
            "Epoch 1530/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7127\n",
            "Epoch 1531/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7169\n",
            "Epoch 1532/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7159\n",
            "Epoch 1533/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7146\n",
            "Epoch 1534/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6907 - accuracy: 0.7161\n",
            "Epoch 1535/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7119\n",
            "Epoch 1536/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6927 - accuracy: 0.7136\n",
            "Epoch 1537/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6862 - accuracy: 0.7143\n",
            "Epoch 1538/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6940 - accuracy: 0.7142\n",
            "Epoch 1539/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6909 - accuracy: 0.7131\n",
            "Epoch 1540/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6981 - accuracy: 0.7111\n",
            "Epoch 1541/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7142\n",
            "Epoch 1542/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6938 - accuracy: 0.7115\n",
            "Epoch 1543/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7127\n",
            "Epoch 1544/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6887 - accuracy: 0.7153\n",
            "Epoch 1545/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7165\n",
            "Epoch 1546/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6919 - accuracy: 0.7144\n",
            "Epoch 1547/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7165\n",
            "Epoch 1548/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6894 - accuracy: 0.7135\n",
            "Epoch 1549/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6938 - accuracy: 0.7119\n",
            "Epoch 1550/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6845 - accuracy: 0.7139\n",
            "Epoch 1551/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6910 - accuracy: 0.7136\n",
            "Epoch 1552/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7157\n",
            "Epoch 1553/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6847 - accuracy: 0.7180\n",
            "Epoch 1554/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7149\n",
            "Epoch 1555/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6908 - accuracy: 0.7144\n",
            "Epoch 1556/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6851 - accuracy: 0.7161\n",
            "Epoch 1557/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.7015 - accuracy: 0.7119\n",
            "Epoch 1558/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6888 - accuracy: 0.7165\n",
            "Epoch 1559/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6933 - accuracy: 0.7130\n",
            "Epoch 1560/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7151\n",
            "Epoch 1561/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7138\n",
            "Epoch 1562/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7167\n",
            "Epoch 1563/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6883 - accuracy: 0.7148\n",
            "Epoch 1564/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6870 - accuracy: 0.7145\n",
            "Epoch 1565/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7163\n",
            "Epoch 1566/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7148\n",
            "Epoch 1567/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6859 - accuracy: 0.7148\n",
            "Epoch 1568/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6893 - accuracy: 0.7134\n",
            "Epoch 1569/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6918 - accuracy: 0.7135\n",
            "Epoch 1570/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7151\n",
            "Epoch 1571/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7160\n",
            "Epoch 1572/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7166\n",
            "Epoch 1573/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7190\n",
            "Epoch 1574/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6920 - accuracy: 0.7131\n",
            "Epoch 1575/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7141\n",
            "Epoch 1576/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7125\n",
            "Epoch 1577/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6903 - accuracy: 0.7138\n",
            "Epoch 1578/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7170\n",
            "Epoch 1579/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7148\n",
            "Epoch 1580/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6917 - accuracy: 0.7133\n",
            "Epoch 1581/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6883 - accuracy: 0.7152\n",
            "Epoch 1582/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7159\n",
            "Epoch 1583/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6830 - accuracy: 0.7162\n",
            "Epoch 1584/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6937 - accuracy: 0.7140\n",
            "Epoch 1585/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6840 - accuracy: 0.7141\n",
            "Epoch 1586/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6923 - accuracy: 0.7127\n",
            "Epoch 1587/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7136\n",
            "Epoch 1588/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6813 - accuracy: 0.7172\n",
            "Epoch 1589/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6936 - accuracy: 0.7150\n",
            "Epoch 1590/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7158\n",
            "Epoch 1591/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6877 - accuracy: 0.7152\n",
            "Epoch 1592/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6868 - accuracy: 0.7166\n",
            "Epoch 1593/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6849 - accuracy: 0.7145\n",
            "Epoch 1594/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6873 - accuracy: 0.7169\n",
            "Epoch 1595/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6948 - accuracy: 0.7144\n",
            "Epoch 1596/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7148\n",
            "Epoch 1597/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7137\n",
            "Epoch 1598/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7124\n",
            "Epoch 1599/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7179\n",
            "Epoch 1600/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7151\n",
            "Epoch 1601/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6907 - accuracy: 0.7152\n",
            "Epoch 1602/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6871 - accuracy: 0.7174\n",
            "Epoch 1603/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6967 - accuracy: 0.7135\n",
            "Epoch 1604/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6859 - accuracy: 0.7140\n",
            "Epoch 1605/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6890 - accuracy: 0.7129\n",
            "Epoch 1606/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7119\n",
            "Epoch 1607/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6900 - accuracy: 0.7168\n",
            "Epoch 1608/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6881 - accuracy: 0.7146\n",
            "Epoch 1609/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6887 - accuracy: 0.7158\n",
            "Epoch 1610/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7152\n",
            "Epoch 1611/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7152\n",
            "Epoch 1612/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6824 - accuracy: 0.7189\n",
            "Epoch 1613/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6860 - accuracy: 0.7150\n",
            "Epoch 1614/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6880 - accuracy: 0.7160\n",
            "Epoch 1615/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7129\n",
            "Epoch 1616/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6860 - accuracy: 0.7154\n",
            "Epoch 1617/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6874 - accuracy: 0.7151\n",
            "Epoch 1618/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6866 - accuracy: 0.7159\n",
            "Epoch 1619/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7139\n",
            "Epoch 1620/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6809 - accuracy: 0.7184\n",
            "Epoch 1621/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6947 - accuracy: 0.7144\n",
            "Epoch 1622/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7187\n",
            "Epoch 1623/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6928 - accuracy: 0.7147\n",
            "Epoch 1624/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6878 - accuracy: 0.7168\n",
            "Epoch 1625/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6866 - accuracy: 0.7158\n",
            "Epoch 1626/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7185\n",
            "Epoch 1627/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6940 - accuracy: 0.7140\n",
            "Epoch 1628/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6891 - accuracy: 0.7170\n",
            "Epoch 1629/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6911 - accuracy: 0.7131\n",
            "Epoch 1630/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7156\n",
            "Epoch 1631/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7163\n",
            "Epoch 1632/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7175\n",
            "Epoch 1633/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6919 - accuracy: 0.7153\n",
            "Epoch 1634/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6907 - accuracy: 0.7136\n",
            "Epoch 1635/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6925 - accuracy: 0.7104\n",
            "Epoch 1636/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7171\n",
            "Epoch 1637/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7171\n",
            "Epoch 1638/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7156\n",
            "Epoch 1639/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6860 - accuracy: 0.7151\n",
            "Epoch 1640/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6894 - accuracy: 0.7144\n",
            "Epoch 1641/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7128\n",
            "Epoch 1642/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7133\n",
            "Epoch 1643/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7142\n",
            "Epoch 1644/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7168\n",
            "Epoch 1645/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7146\n",
            "Epoch 1646/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6912 - accuracy: 0.7154\n",
            "Epoch 1647/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6859 - accuracy: 0.7167\n",
            "Epoch 1648/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7177\n",
            "Epoch 1649/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6874 - accuracy: 0.7146\n",
            "Epoch 1650/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7173\n",
            "Epoch 1651/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7133\n",
            "Epoch 1652/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7179\n",
            "Epoch 1653/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6909 - accuracy: 0.7148\n",
            "Epoch 1654/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7187\n",
            "Epoch 1655/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7150\n",
            "Epoch 1656/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7163\n",
            "Epoch 1657/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7184\n",
            "Epoch 1658/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7174\n",
            "Epoch 1659/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6811 - accuracy: 0.7184\n",
            "Epoch 1660/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6865 - accuracy: 0.7170\n",
            "Epoch 1661/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7166\n",
            "Epoch 1662/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7153\n",
            "Epoch 1663/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6838 - accuracy: 0.7163\n",
            "Epoch 1664/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7194\n",
            "Epoch 1665/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7183\n",
            "Epoch 1666/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6908 - accuracy: 0.7131\n",
            "Epoch 1667/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6904 - accuracy: 0.7163\n",
            "Epoch 1668/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7198\n",
            "Epoch 1669/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7138\n",
            "Epoch 1670/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7178\n",
            "Epoch 1671/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7169\n",
            "Epoch 1672/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6893 - accuracy: 0.7143\n",
            "Epoch 1673/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7186\n",
            "Epoch 1674/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7169\n",
            "Epoch 1675/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6914 - accuracy: 0.7148\n",
            "Epoch 1676/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6882 - accuracy: 0.7149\n",
            "Epoch 1677/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7177\n",
            "Epoch 1678/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6872 - accuracy: 0.7164\n",
            "Epoch 1679/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7164\n",
            "Epoch 1680/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6867 - accuracy: 0.7159\n",
            "Epoch 1681/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6893 - accuracy: 0.7183\n",
            "Epoch 1682/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6917 - accuracy: 0.7127\n",
            "Epoch 1683/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6851 - accuracy: 0.7168\n",
            "Epoch 1684/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6860 - accuracy: 0.7161\n",
            "Epoch 1685/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6874 - accuracy: 0.7137\n",
            "Epoch 1686/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7151\n",
            "Epoch 1687/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7182\n",
            "Epoch 1688/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6871 - accuracy: 0.7146\n",
            "Epoch 1689/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7176\n",
            "Epoch 1690/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7170\n",
            "Epoch 1691/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7180\n",
            "Epoch 1692/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7149\n",
            "Epoch 1693/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7147\n",
            "Epoch 1694/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6848 - accuracy: 0.7151\n",
            "Epoch 1695/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6854 - accuracy: 0.7130\n",
            "Epoch 1696/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6908 - accuracy: 0.7131\n",
            "Epoch 1697/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7161\n",
            "Epoch 1698/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6803 - accuracy: 0.7176\n",
            "Epoch 1699/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7156\n",
            "Epoch 1700/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7143\n",
            "Epoch 1701/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7187\n",
            "Epoch 1702/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7179\n",
            "Epoch 1703/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6881 - accuracy: 0.7156\n",
            "Epoch 1704/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7146\n",
            "Epoch 1705/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7184\n",
            "Epoch 1706/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6864 - accuracy: 0.7174\n",
            "Epoch 1707/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7175\n",
            "Epoch 1708/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6891 - accuracy: 0.7171\n",
            "Epoch 1709/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6793 - accuracy: 0.7182\n",
            "Epoch 1710/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7156\n",
            "Epoch 1711/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7165\n",
            "Epoch 1712/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7170\n",
            "Epoch 1713/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6827 - accuracy: 0.7171\n",
            "Epoch 1714/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6838 - accuracy: 0.7162\n",
            "Epoch 1715/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7166\n",
            "Epoch 1716/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6859 - accuracy: 0.7165\n",
            "Epoch 1717/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6865 - accuracy: 0.7168\n",
            "Epoch 1718/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7170\n",
            "Epoch 1719/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6898 - accuracy: 0.7161\n",
            "Epoch 1720/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6866 - accuracy: 0.7140\n",
            "Epoch 1721/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6929 - accuracy: 0.7122\n",
            "Epoch 1722/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6831 - accuracy: 0.7170\n",
            "Epoch 1723/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6880 - accuracy: 0.7169\n",
            "Epoch 1724/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7176\n",
            "Epoch 1725/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6910 - accuracy: 0.7133\n",
            "Epoch 1726/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6820 - accuracy: 0.7173\n",
            "Epoch 1727/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7165\n",
            "Epoch 1728/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7140\n",
            "Epoch 1729/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6901 - accuracy: 0.7153\n",
            "Epoch 1730/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6924 - accuracy: 0.7150\n",
            "Epoch 1731/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7191\n",
            "Epoch 1732/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7165\n",
            "Epoch 1733/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7159\n",
            "Epoch 1734/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7157\n",
            "Epoch 1735/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6885 - accuracy: 0.7136\n",
            "Epoch 1736/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7168\n",
            "Epoch 1737/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7179\n",
            "Epoch 1738/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6907 - accuracy: 0.7132\n",
            "Epoch 1739/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7170\n",
            "Epoch 1740/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7197\n",
            "Epoch 1741/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6873 - accuracy: 0.7164\n",
            "Epoch 1742/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7162\n",
            "Epoch 1743/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7203\n",
            "Epoch 1744/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7166\n",
            "Epoch 1745/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7169\n",
            "Epoch 1746/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6813 - accuracy: 0.7205\n",
            "Epoch 1747/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7174\n",
            "Epoch 1748/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6854 - accuracy: 0.7171\n",
            "Epoch 1749/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6813 - accuracy: 0.7190\n",
            "Epoch 1750/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6827 - accuracy: 0.7164\n",
            "Epoch 1751/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7184\n",
            "Epoch 1752/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7167\n",
            "Epoch 1753/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7169\n",
            "Epoch 1754/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7189\n",
            "Epoch 1755/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6820 - accuracy: 0.7167\n",
            "Epoch 1756/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6865 - accuracy: 0.7164\n",
            "Epoch 1757/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6818 - accuracy: 0.7201\n",
            "Epoch 1758/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6845 - accuracy: 0.7165\n",
            "Epoch 1759/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6867 - accuracy: 0.7172\n",
            "Epoch 1760/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7161\n",
            "Epoch 1761/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6865 - accuracy: 0.7157\n",
            "Epoch 1762/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7166\n",
            "Epoch 1763/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6777 - accuracy: 0.7185\n",
            "Epoch 1764/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6852 - accuracy: 0.7176\n",
            "Epoch 1765/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7180\n",
            "Epoch 1766/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7164\n",
            "Epoch 1767/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6820 - accuracy: 0.7162\n",
            "Epoch 1768/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7150\n",
            "Epoch 1769/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6803 - accuracy: 0.7167\n",
            "Epoch 1770/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6846 - accuracy: 0.7174\n",
            "Epoch 1771/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7166\n",
            "Epoch 1772/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6905 - accuracy: 0.7153\n",
            "Epoch 1773/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7180\n",
            "Epoch 1774/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7155\n",
            "Epoch 1775/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6907 - accuracy: 0.7153\n",
            "Epoch 1776/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7183\n",
            "Epoch 1777/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7137\n",
            "Epoch 1778/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7184\n",
            "Epoch 1779/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6915 - accuracy: 0.7145\n",
            "Epoch 1780/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7149\n",
            "Epoch 1781/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7155\n",
            "Epoch 1782/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7175\n",
            "Epoch 1783/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7183\n",
            "Epoch 1784/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6829 - accuracy: 0.7180\n",
            "Epoch 1785/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6871 - accuracy: 0.7152\n",
            "Epoch 1786/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6834 - accuracy: 0.7148\n",
            "Epoch 1787/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7194\n",
            "Epoch 1788/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7155\n",
            "Epoch 1789/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6906 - accuracy: 0.7149\n",
            "Epoch 1790/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7171\n",
            "Epoch 1791/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6805 - accuracy: 0.7201\n",
            "Epoch 1792/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7193\n",
            "Epoch 1793/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6868 - accuracy: 0.7155\n",
            "Epoch 1794/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6889 - accuracy: 0.7137\n",
            "Epoch 1795/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7192\n",
            "Epoch 1796/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6854 - accuracy: 0.7134\n",
            "Epoch 1797/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6885 - accuracy: 0.7163\n",
            "Epoch 1798/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7155\n",
            "Epoch 1799/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7183\n",
            "Epoch 1800/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6929 - accuracy: 0.7136\n",
            "Epoch 1801/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6827 - accuracy: 0.7177\n",
            "Epoch 1802/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7184\n",
            "Epoch 1803/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6897 - accuracy: 0.7152\n",
            "Epoch 1804/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6793 - accuracy: 0.7190\n",
            "Epoch 1805/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6840 - accuracy: 0.7147\n",
            "Epoch 1806/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7164\n",
            "Epoch 1807/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6867 - accuracy: 0.7157\n",
            "Epoch 1808/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7162\n",
            "Epoch 1809/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6862 - accuracy: 0.7159\n",
            "Epoch 1810/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7198\n",
            "Epoch 1811/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7183\n",
            "Epoch 1812/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6888 - accuracy: 0.7159\n",
            "Epoch 1813/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7160\n",
            "Epoch 1814/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6829 - accuracy: 0.7204\n",
            "Epoch 1815/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7154\n",
            "Epoch 1816/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7163\n",
            "Epoch 1817/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7181\n",
            "Epoch 1818/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7198\n",
            "Epoch 1819/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7186\n",
            "Epoch 1820/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7168\n",
            "Epoch 1821/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6824 - accuracy: 0.7192\n",
            "Epoch 1822/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6940 - accuracy: 0.7133\n",
            "Epoch 1823/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6831 - accuracy: 0.7168\n",
            "Epoch 1824/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7193\n",
            "Epoch 1825/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6868 - accuracy: 0.7157\n",
            "Epoch 1826/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7164\n",
            "Epoch 1827/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7177\n",
            "Epoch 1828/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7147\n",
            "Epoch 1829/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7152\n",
            "Epoch 1830/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6899 - accuracy: 0.7147\n",
            "Epoch 1831/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6781 - accuracy: 0.7181\n",
            "Epoch 1832/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6904 - accuracy: 0.7154\n",
            "Epoch 1833/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6832 - accuracy: 0.7162\n",
            "Epoch 1834/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6769 - accuracy: 0.7195\n",
            "Epoch 1835/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6901 - accuracy: 0.7187\n",
            "Epoch 1836/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7190\n",
            "Epoch 1837/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6847 - accuracy: 0.7160\n",
            "Epoch 1838/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6854 - accuracy: 0.7190\n",
            "Epoch 1839/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7158\n",
            "Epoch 1840/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6786 - accuracy: 0.7183\n",
            "Epoch 1841/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7162\n",
            "Epoch 1842/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6828 - accuracy: 0.7193\n",
            "Epoch 1843/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7207\n",
            "Epoch 1844/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6874 - accuracy: 0.7176\n",
            "Epoch 1845/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6889 - accuracy: 0.7135\n",
            "Epoch 1846/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7177\n",
            "Epoch 1847/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7169\n",
            "Epoch 1848/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7174\n",
            "Epoch 1849/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7158\n",
            "Epoch 1850/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6808 - accuracy: 0.7190\n",
            "Epoch 1851/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7196\n",
            "Epoch 1852/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7175\n",
            "Epoch 1853/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7173\n",
            "Epoch 1854/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7188\n",
            "Epoch 1855/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7162\n",
            "Epoch 1856/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7146\n",
            "Epoch 1857/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6862 - accuracy: 0.7163\n",
            "Epoch 1858/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6763 - accuracy: 0.7192\n",
            "Epoch 1859/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6914 - accuracy: 0.7140\n",
            "Epoch 1860/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6895 - accuracy: 0.7152\n",
            "Epoch 1861/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7157\n",
            "Epoch 1862/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7187\n",
            "Epoch 1863/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6877 - accuracy: 0.7169\n",
            "Epoch 1864/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6896 - accuracy: 0.7155\n",
            "Epoch 1865/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6866 - accuracy: 0.7165\n",
            "Epoch 1866/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7197\n",
            "Epoch 1867/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7212\n",
            "Epoch 1868/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7188\n",
            "Epoch 1869/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7172\n",
            "Epoch 1870/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7180\n",
            "Epoch 1871/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7179\n",
            "Epoch 1872/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7165\n",
            "Epoch 1873/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6786 - accuracy: 0.7158\n",
            "Epoch 1874/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7141\n",
            "Epoch 1875/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6892 - accuracy: 0.7134\n",
            "Epoch 1876/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6862 - accuracy: 0.7145\n",
            "Epoch 1877/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7193\n",
            "Epoch 1878/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7191\n",
            "Epoch 1879/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7191\n",
            "Epoch 1880/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7190\n",
            "Epoch 1881/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7184\n",
            "Epoch 1882/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7195\n",
            "Epoch 1883/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7197\n",
            "Epoch 1884/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6786 - accuracy: 0.7204\n",
            "Epoch 1885/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7195\n",
            "Epoch 1886/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7182\n",
            "Epoch 1887/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7174\n",
            "Epoch 1888/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7160\n",
            "Epoch 1889/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7183\n",
            "Epoch 1890/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6861 - accuracy: 0.7151\n",
            "Epoch 1891/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7182\n",
            "Epoch 1892/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6849 - accuracy: 0.7143\n",
            "Epoch 1893/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7160\n",
            "Epoch 1894/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7144\n",
            "Epoch 1895/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7156\n",
            "Epoch 1896/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6854 - accuracy: 0.7158\n",
            "Epoch 1897/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6821 - accuracy: 0.7175\n",
            "Epoch 1898/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7182\n",
            "Epoch 1899/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7186\n",
            "Epoch 1900/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7187\n",
            "Epoch 1901/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7186\n",
            "Epoch 1902/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7160\n",
            "Epoch 1903/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7215\n",
            "Epoch 1904/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7179\n",
            "Epoch 1905/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7163\n",
            "Epoch 1906/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7175\n",
            "Epoch 1907/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7170\n",
            "Epoch 1908/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7171\n",
            "Epoch 1909/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6863 - accuracy: 0.7165\n",
            "Epoch 1910/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7178\n",
            "Epoch 1911/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7181\n",
            "Epoch 1912/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7150\n",
            "Epoch 1913/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7158\n",
            "Epoch 1914/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6875 - accuracy: 0.7176\n",
            "Epoch 1915/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7202\n",
            "Epoch 1916/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7166\n",
            "Epoch 1917/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7209\n",
            "Epoch 1918/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7174\n",
            "Epoch 1919/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7185\n",
            "Epoch 1920/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7189\n",
            "Epoch 1921/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7182\n",
            "Epoch 1922/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6840 - accuracy: 0.7182\n",
            "Epoch 1923/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7179\n",
            "Epoch 1924/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7174\n",
            "Epoch 1925/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7176\n",
            "Epoch 1926/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7220\n",
            "Epoch 1927/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7185\n",
            "Epoch 1928/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7168\n",
            "Epoch 1929/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7188\n",
            "Epoch 1930/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6880 - accuracy: 0.7143\n",
            "Epoch 1931/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7189\n",
            "Epoch 1932/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6834 - accuracy: 0.7165\n",
            "Epoch 1933/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7166\n",
            "Epoch 1934/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7170\n",
            "Epoch 1935/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7176\n",
            "Epoch 1936/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7189\n",
            "Epoch 1937/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6913 - accuracy: 0.7139\n",
            "Epoch 1938/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7197\n",
            "Epoch 1939/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7182\n",
            "Epoch 1940/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6815 - accuracy: 0.7186\n",
            "Epoch 1941/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7178\n",
            "Epoch 1942/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7181\n",
            "Epoch 1943/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7172\n",
            "Epoch 1944/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7214\n",
            "Epoch 1945/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7194\n",
            "Epoch 1946/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7210\n",
            "Epoch 1947/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6846 - accuracy: 0.7173\n",
            "Epoch 1948/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6852 - accuracy: 0.7178\n",
            "Epoch 1949/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7174\n",
            "Epoch 1950/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7182\n",
            "Epoch 1951/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6850 - accuracy: 0.7167\n",
            "Epoch 1952/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6851 - accuracy: 0.7187\n",
            "Epoch 1953/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7158\n",
            "Epoch 1954/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6786 - accuracy: 0.7199\n",
            "Epoch 1955/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6852 - accuracy: 0.7183\n",
            "Epoch 1956/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7160\n",
            "Epoch 1957/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7203\n",
            "Epoch 1958/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7197\n",
            "Epoch 1959/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7178\n",
            "Epoch 1960/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6826 - accuracy: 0.7162\n",
            "Epoch 1961/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7151\n",
            "Epoch 1962/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7202\n",
            "Epoch 1963/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7204\n",
            "Epoch 1964/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6902 - accuracy: 0.7158\n",
            "Epoch 1965/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6815 - accuracy: 0.7165\n",
            "Epoch 1966/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6829 - accuracy: 0.7167\n",
            "Epoch 1967/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7186\n",
            "Epoch 1968/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6831 - accuracy: 0.7181\n",
            "Epoch 1969/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6877 - accuracy: 0.7149\n",
            "Epoch 1970/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6828 - accuracy: 0.7179\n",
            "Epoch 1971/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7167\n",
            "Epoch 1972/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6839 - accuracy: 0.7161\n",
            "Epoch 1973/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7181\n",
            "Epoch 1974/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7172\n",
            "Epoch 1975/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7196\n",
            "Epoch 1976/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7161\n",
            "Epoch 1977/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7169\n",
            "Epoch 1978/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7176\n",
            "Epoch 1979/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6713 - accuracy: 0.7199\n",
            "Epoch 1980/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7142\n",
            "Epoch 1981/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7235\n",
            "Epoch 1982/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7219\n",
            "Epoch 1983/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7176\n",
            "Epoch 1984/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7181\n",
            "Epoch 1985/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7190\n",
            "Epoch 1986/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7178\n",
            "Epoch 1987/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7162\n",
            "Epoch 1988/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7197\n",
            "Epoch 1989/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7184\n",
            "Epoch 1990/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7186\n",
            "Epoch 1991/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6763 - accuracy: 0.7178\n",
            "Epoch 1992/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7191\n",
            "Epoch 1993/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7189\n",
            "Epoch 1994/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6818 - accuracy: 0.7176\n",
            "Epoch 1995/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7177\n",
            "Epoch 1996/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7194\n",
            "Epoch 1997/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7195\n",
            "Epoch 1998/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7210\n",
            "Epoch 1999/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7158\n",
            "Epoch 2000/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7163\n",
            "Epoch 2001/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6815 - accuracy: 0.7170\n",
            "Epoch 2002/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7178\n",
            "Epoch 2003/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7181\n",
            "Epoch 2004/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7168\n",
            "Epoch 2005/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7187\n",
            "Epoch 2006/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7201\n",
            "Epoch 2007/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7188\n",
            "Epoch 2008/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6805 - accuracy: 0.7171\n",
            "Epoch 2009/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7210\n",
            "Epoch 2010/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7192\n",
            "Epoch 2011/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6848 - accuracy: 0.7172\n",
            "Epoch 2012/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7202\n",
            "Epoch 2013/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7163\n",
            "Epoch 2014/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6845 - accuracy: 0.7163\n",
            "Epoch 2015/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7175\n",
            "Epoch 2016/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6761 - accuracy: 0.7211\n",
            "Epoch 2017/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7200\n",
            "Epoch 2018/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7219\n",
            "Epoch 2019/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6884 - accuracy: 0.7141\n",
            "Epoch 2020/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7215\n",
            "Epoch 2021/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6886 - accuracy: 0.7173\n",
            "Epoch 2022/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7208\n",
            "Epoch 2023/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7175\n",
            "Epoch 2024/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6828 - accuracy: 0.7165\n",
            "Epoch 2025/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6820 - accuracy: 0.7200\n",
            "Epoch 2026/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7148\n",
            "Epoch 2027/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7179\n",
            "Epoch 2028/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6785 - accuracy: 0.7165\n",
            "Epoch 2029/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6820 - accuracy: 0.7163\n",
            "Epoch 2030/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7151\n",
            "Epoch 2031/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7204\n",
            "Epoch 2032/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6761 - accuracy: 0.7192\n",
            "Epoch 2033/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7180\n",
            "Epoch 2034/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6828 - accuracy: 0.7195\n",
            "Epoch 2035/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6856 - accuracy: 0.7181\n",
            "Epoch 2036/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7180\n",
            "Epoch 2037/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6824 - accuracy: 0.7175\n",
            "Epoch 2038/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7186\n",
            "Epoch 2039/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7205\n",
            "Epoch 2040/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7163\n",
            "Epoch 2041/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6847 - accuracy: 0.7179\n",
            "Epoch 2042/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7198\n",
            "Epoch 2043/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7149\n",
            "Epoch 2044/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6843 - accuracy: 0.7147\n",
            "Epoch 2045/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7184\n",
            "Epoch 2046/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7184\n",
            "Epoch 2047/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7194\n",
            "Epoch 2048/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6837 - accuracy: 0.7176\n",
            "Epoch 2049/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6774 - accuracy: 0.7203\n",
            "Epoch 2050/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6848 - accuracy: 0.7144\n",
            "Epoch 2051/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7189\n",
            "Epoch 2052/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7198\n",
            "Epoch 2053/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7201\n",
            "Epoch 2054/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7173\n",
            "Epoch 2055/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7193\n",
            "Epoch 2056/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6847 - accuracy: 0.7165\n",
            "Epoch 2057/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6808 - accuracy: 0.7187\n",
            "Epoch 2058/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7192\n",
            "Epoch 2059/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6808 - accuracy: 0.7179\n",
            "Epoch 2060/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7171\n",
            "Epoch 2061/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6764 - accuracy: 0.7182\n",
            "Epoch 2062/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7190\n",
            "Epoch 2063/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6803 - accuracy: 0.7187\n",
            "Epoch 2064/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7237\n",
            "Epoch 2065/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6815 - accuracy: 0.7175\n",
            "Epoch 2066/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7204\n",
            "Epoch 2067/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7194\n",
            "Epoch 2068/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7177\n",
            "Epoch 2069/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7208\n",
            "Epoch 2070/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7209\n",
            "Epoch 2071/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6876 - accuracy: 0.7195\n",
            "Epoch 2072/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7146\n",
            "Epoch 2073/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6842 - accuracy: 0.7173\n",
            "Epoch 2074/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7201\n",
            "Epoch 2075/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7182\n",
            "Epoch 2076/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6774 - accuracy: 0.7189\n",
            "Epoch 2077/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7169\n",
            "Epoch 2078/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7186\n",
            "Epoch 2079/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7193\n",
            "Epoch 2080/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6844 - accuracy: 0.7180\n",
            "Epoch 2081/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7151\n",
            "Epoch 2082/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7200\n",
            "Epoch 2083/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7192\n",
            "Epoch 2084/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7174\n",
            "Epoch 2085/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7198\n",
            "Epoch 2086/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6744 - accuracy: 0.7200\n",
            "Epoch 2087/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7190\n",
            "Epoch 2088/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7196\n",
            "Epoch 2089/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7192\n",
            "Epoch 2090/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7158\n",
            "Epoch 2091/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7204\n",
            "Epoch 2092/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6856 - accuracy: 0.7149\n",
            "Epoch 2093/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7148\n",
            "Epoch 2094/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7178\n",
            "Epoch 2095/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7210\n",
            "Epoch 2096/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6726 - accuracy: 0.7211\n",
            "Epoch 2097/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7175\n",
            "Epoch 2098/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7219\n",
            "Epoch 2099/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7181\n",
            "Epoch 2100/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7148\n",
            "Epoch 2101/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7193\n",
            "Epoch 2102/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7203\n",
            "Epoch 2103/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7170\n",
            "Epoch 2104/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6822 - accuracy: 0.7164\n",
            "Epoch 2105/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7190\n",
            "Epoch 2106/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7177\n",
            "Epoch 2107/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7176\n",
            "Epoch 2108/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7215\n",
            "Epoch 2109/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7181\n",
            "Epoch 2110/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7199\n",
            "Epoch 2111/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6785 - accuracy: 0.7228\n",
            "Epoch 2112/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7193\n",
            "Epoch 2113/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6777 - accuracy: 0.7190\n",
            "Epoch 2114/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7172\n",
            "Epoch 2115/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7194\n",
            "Epoch 2116/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7155\n",
            "Epoch 2117/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7198\n",
            "Epoch 2118/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6781 - accuracy: 0.7175\n",
            "Epoch 2119/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7181\n",
            "Epoch 2120/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6849 - accuracy: 0.7154\n",
            "Epoch 2121/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7181\n",
            "Epoch 2122/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6761 - accuracy: 0.7185\n",
            "Epoch 2123/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7177\n",
            "Epoch 2124/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7179\n",
            "Epoch 2125/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7194\n",
            "Epoch 2126/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6870 - accuracy: 0.7168\n",
            "Epoch 2127/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7202\n",
            "Epoch 2128/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6761 - accuracy: 0.7207\n",
            "Epoch 2129/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7165\n",
            "Epoch 2130/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7221\n",
            "Epoch 2131/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7178\n",
            "Epoch 2132/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6719 - accuracy: 0.7198\n",
            "Epoch 2133/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7198\n",
            "Epoch 2134/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7185\n",
            "Epoch 2135/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6828 - accuracy: 0.7156\n",
            "Epoch 2136/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6815 - accuracy: 0.7173\n",
            "Epoch 2137/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7177\n",
            "Epoch 2138/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7167\n",
            "Epoch 2139/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7200\n",
            "Epoch 2140/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6808 - accuracy: 0.7170\n",
            "Epoch 2141/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7203\n",
            "Epoch 2142/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7192\n",
            "Epoch 2143/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7217\n",
            "Epoch 2144/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7217\n",
            "Epoch 2145/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6840 - accuracy: 0.7176\n",
            "Epoch 2146/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7195\n",
            "Epoch 2147/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7188\n",
            "Epoch 2148/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6857 - accuracy: 0.7179\n",
            "Epoch 2149/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7232\n",
            "Epoch 2150/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7194\n",
            "Epoch 2151/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7183\n",
            "Epoch 2152/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6858 - accuracy: 0.7161\n",
            "Epoch 2153/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7195\n",
            "Epoch 2154/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6855 - accuracy: 0.7157\n",
            "Epoch 2155/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6686 - accuracy: 0.7215\n",
            "Epoch 2156/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7215\n",
            "Epoch 2157/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7182\n",
            "Epoch 2158/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7203\n",
            "Epoch 2159/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6764 - accuracy: 0.7183\n",
            "Epoch 2160/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7168\n",
            "Epoch 2161/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7183\n",
            "Epoch 2162/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6805 - accuracy: 0.7145\n",
            "Epoch 2163/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7203\n",
            "Epoch 2164/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7188\n",
            "Epoch 2165/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6810 - accuracy: 0.7187\n",
            "Epoch 2166/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7183\n",
            "Epoch 2167/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7173\n",
            "Epoch 2168/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7171\n",
            "Epoch 2169/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7189\n",
            "Epoch 2170/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7233\n",
            "Epoch 2171/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7195\n",
            "Epoch 2172/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7198\n",
            "Epoch 2173/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7220\n",
            "Epoch 2174/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7174\n",
            "Epoch 2175/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7186\n",
            "Epoch 2176/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7201\n",
            "Epoch 2177/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7196\n",
            "Epoch 2178/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7178\n",
            "Epoch 2179/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7181\n",
            "Epoch 2180/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7189\n",
            "Epoch 2181/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6777 - accuracy: 0.7180\n",
            "Epoch 2182/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6850 - accuracy: 0.7142\n",
            "Epoch 2183/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7190\n",
            "Epoch 2184/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6845 - accuracy: 0.7151\n",
            "Epoch 2185/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7204\n",
            "Epoch 2186/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7214\n",
            "Epoch 2187/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6785 - accuracy: 0.7193\n",
            "Epoch 2188/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7178\n",
            "Epoch 2189/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7182\n",
            "Epoch 2190/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7211\n",
            "Epoch 2191/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7191\n",
            "Epoch 2192/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6831 - accuracy: 0.7178\n",
            "Epoch 2193/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6830 - accuracy: 0.7169\n",
            "Epoch 2194/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7192\n",
            "Epoch 2195/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7155\n",
            "Epoch 2196/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7165\n",
            "Epoch 2197/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7185\n",
            "Epoch 2198/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7207\n",
            "Epoch 2199/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7196\n",
            "Epoch 2200/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7176\n",
            "Epoch 2201/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7211\n",
            "Epoch 2202/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7161\n",
            "Epoch 2203/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6761 - accuracy: 0.7198\n",
            "Epoch 2204/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7208\n",
            "Epoch 2205/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7174\n",
            "Epoch 2206/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7172\n",
            "Epoch 2207/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7193\n",
            "Epoch 2208/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7196\n",
            "Epoch 2209/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7198\n",
            "Epoch 2210/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7202\n",
            "Epoch 2211/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7180\n",
            "Epoch 2212/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6900 - accuracy: 0.7151\n",
            "Epoch 2213/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7199\n",
            "Epoch 2214/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6716 - accuracy: 0.7231\n",
            "Epoch 2215/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7211\n",
            "Epoch 2216/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7182\n",
            "Epoch 2217/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7202\n",
            "Epoch 2218/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6831 - accuracy: 0.7205\n",
            "Epoch 2219/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7184\n",
            "Epoch 2220/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6838 - accuracy: 0.7182\n",
            "Epoch 2221/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6742 - accuracy: 0.7216\n",
            "Epoch 2222/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7201\n",
            "Epoch 2223/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6726 - accuracy: 0.7220\n",
            "Epoch 2224/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7172\n",
            "Epoch 2225/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7167\n",
            "Epoch 2226/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6731 - accuracy: 0.7205\n",
            "Epoch 2227/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7183\n",
            "Epoch 2228/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7188\n",
            "Epoch 2229/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7219\n",
            "Epoch 2230/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7189\n",
            "Epoch 2231/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7207\n",
            "Epoch 2232/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6816 - accuracy: 0.7195\n",
            "Epoch 2233/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6786 - accuracy: 0.7196\n",
            "Epoch 2234/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6797 - accuracy: 0.7168\n",
            "Epoch 2235/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7195\n",
            "Epoch 2236/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7181\n",
            "Epoch 2237/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7209\n",
            "Epoch 2238/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7203\n",
            "Epoch 2239/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7182\n",
            "Epoch 2240/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7200\n",
            "Epoch 2241/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7211\n",
            "Epoch 2242/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7182\n",
            "Epoch 2243/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7152\n",
            "Epoch 2244/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7162\n",
            "Epoch 2245/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6827 - accuracy: 0.7184\n",
            "Epoch 2246/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7187\n",
            "Epoch 2247/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7216\n",
            "Epoch 2248/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7172\n",
            "Epoch 2249/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7211\n",
            "Epoch 2250/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7172\n",
            "Epoch 2251/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7194\n",
            "Epoch 2252/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7193\n",
            "Epoch 2253/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7196\n",
            "Epoch 2254/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7171\n",
            "Epoch 2255/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7185\n",
            "Epoch 2256/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7159\n",
            "Epoch 2257/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6796 - accuracy: 0.7217\n",
            "Epoch 2258/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7207\n",
            "Epoch 2259/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7185\n",
            "Epoch 2260/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6833 - accuracy: 0.7200\n",
            "Epoch 2261/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7175\n",
            "Epoch 2262/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7188\n",
            "Epoch 2263/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7225\n",
            "Epoch 2264/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6814 - accuracy: 0.7168\n",
            "Epoch 2265/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7213\n",
            "Epoch 2266/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7219\n",
            "Epoch 2267/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7195\n",
            "Epoch 2268/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7199\n",
            "Epoch 2269/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6818 - accuracy: 0.7169\n",
            "Epoch 2270/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7210\n",
            "Epoch 2271/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7215\n",
            "Epoch 2272/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7185\n",
            "Epoch 2273/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7181\n",
            "Epoch 2274/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7204\n",
            "Epoch 2275/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7200\n",
            "Epoch 2276/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7177\n",
            "Epoch 2277/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7178\n",
            "Epoch 2278/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7202\n",
            "Epoch 2279/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6853 - accuracy: 0.7155\n",
            "Epoch 2280/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6737 - accuracy: 0.7191\n",
            "Epoch 2281/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7204\n",
            "Epoch 2282/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6845 - accuracy: 0.7159\n",
            "Epoch 2283/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7185\n",
            "Epoch 2284/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6828 - accuracy: 0.7164\n",
            "Epoch 2285/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7193\n",
            "Epoch 2286/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6705 - accuracy: 0.7223\n",
            "Epoch 2287/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7202\n",
            "Epoch 2288/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6819 - accuracy: 0.7173\n",
            "Epoch 2289/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6802 - accuracy: 0.7177\n",
            "Epoch 2290/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7202\n",
            "Epoch 2291/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7202\n",
            "Epoch 2292/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6687 - accuracy: 0.7207\n",
            "Epoch 2293/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7210\n",
            "Epoch 2294/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7202\n",
            "Epoch 2295/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6835 - accuracy: 0.7167\n",
            "Epoch 2296/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6783 - accuracy: 0.7208\n",
            "Epoch 2297/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7173\n",
            "Epoch 2298/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6864 - accuracy: 0.7168\n",
            "Epoch 2299/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7209\n",
            "Epoch 2300/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7178\n",
            "Epoch 2301/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7216\n",
            "Epoch 2302/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7180\n",
            "Epoch 2303/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7182\n",
            "Epoch 2304/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7177\n",
            "Epoch 2305/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7187\n",
            "Epoch 2306/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7212\n",
            "Epoch 2307/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7182\n",
            "Epoch 2308/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7190\n",
            "Epoch 2309/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7210\n",
            "Epoch 2310/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7191\n",
            "Epoch 2311/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7190\n",
            "Epoch 2312/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6832 - accuracy: 0.7179\n",
            "Epoch 2313/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7186\n",
            "Epoch 2314/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7194\n",
            "Epoch 2315/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7212\n",
            "Epoch 2316/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7225\n",
            "Epoch 2317/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6727 - accuracy: 0.7205\n",
            "Epoch 2318/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7197\n",
            "Epoch 2319/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7211\n",
            "Epoch 2320/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7191\n",
            "Epoch 2321/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7181\n",
            "Epoch 2322/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7200\n",
            "Epoch 2323/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6779 - accuracy: 0.7203\n",
            "Epoch 2324/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7184\n",
            "Epoch 2325/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7211\n",
            "Epoch 2326/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6823 - accuracy: 0.7186\n",
            "Epoch 2327/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6809 - accuracy: 0.7175\n",
            "Epoch 2328/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6781 - accuracy: 0.7204\n",
            "Epoch 2329/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6836 - accuracy: 0.7193\n",
            "Epoch 2330/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7245\n",
            "Epoch 2331/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7228\n",
            "Epoch 2332/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7219\n",
            "Epoch 2333/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7233\n",
            "Epoch 2334/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7214\n",
            "Epoch 2335/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7178\n",
            "Epoch 2336/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7197\n",
            "Epoch 2337/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6663 - accuracy: 0.7258\n",
            "Epoch 2338/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6841 - accuracy: 0.7156\n",
            "Epoch 2339/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7202\n",
            "Epoch 2340/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7203\n",
            "Epoch 2341/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6824 - accuracy: 0.7191\n",
            "Epoch 2342/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6764 - accuracy: 0.7180\n",
            "Epoch 2343/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7214\n",
            "Epoch 2344/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7214\n",
            "Epoch 2345/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7223\n",
            "Epoch 2346/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7213\n",
            "Epoch 2347/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7201\n",
            "Epoch 2348/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6793 - accuracy: 0.7212\n",
            "Epoch 2349/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7196\n",
            "Epoch 2350/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6812 - accuracy: 0.7189\n",
            "Epoch 2351/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7197\n",
            "Epoch 2352/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7177\n",
            "Epoch 2353/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7207\n",
            "Epoch 2354/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7193\n",
            "Epoch 2355/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7189\n",
            "Epoch 2356/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7175\n",
            "Epoch 2357/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6782 - accuracy: 0.7171\n",
            "Epoch 2358/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7205\n",
            "Epoch 2359/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7205\n",
            "Epoch 2360/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7196\n",
            "Epoch 2361/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7186\n",
            "Epoch 2362/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7190\n",
            "Epoch 2363/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6686 - accuracy: 0.7222\n",
            "Epoch 2364/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7193\n",
            "Epoch 2365/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7223\n",
            "Epoch 2366/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6777 - accuracy: 0.7182\n",
            "Epoch 2367/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7199\n",
            "Epoch 2368/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6808 - accuracy: 0.7185\n",
            "Epoch 2369/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7239\n",
            "Epoch 2370/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7174\n",
            "Epoch 2371/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7197\n",
            "Epoch 2372/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7199\n",
            "Epoch 2373/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6745 - accuracy: 0.7200\n",
            "Epoch 2374/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7220\n",
            "Epoch 2375/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7183\n",
            "Epoch 2376/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7178\n",
            "Epoch 2377/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6815 - accuracy: 0.7183\n",
            "Epoch 2378/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6781 - accuracy: 0.7190\n",
            "Epoch 2379/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7180\n",
            "Epoch 2380/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7187\n",
            "Epoch 2381/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7185\n",
            "Epoch 2382/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7204\n",
            "Epoch 2383/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7178\n",
            "Epoch 2384/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7189\n",
            "Epoch 2385/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6787 - accuracy: 0.7175\n",
            "Epoch 2386/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7193\n",
            "Epoch 2387/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7245\n",
            "Epoch 2388/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7216\n",
            "Epoch 2389/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7173\n",
            "Epoch 2390/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7200\n",
            "Epoch 2391/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6744 - accuracy: 0.7184\n",
            "Epoch 2392/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7193\n",
            "Epoch 2393/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7189\n",
            "Epoch 2394/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7186\n",
            "Epoch 2395/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7192\n",
            "Epoch 2396/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7189\n",
            "Epoch 2397/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6811 - accuracy: 0.7189\n",
            "Epoch 2398/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7180\n",
            "Epoch 2399/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7218\n",
            "Epoch 2400/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7198\n",
            "Epoch 2401/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7186\n",
            "Epoch 2402/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6799 - accuracy: 0.7209\n",
            "Epoch 2403/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6745 - accuracy: 0.7177\n",
            "Epoch 2404/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7168\n",
            "Epoch 2405/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7198\n",
            "Epoch 2406/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6731 - accuracy: 0.7179\n",
            "Epoch 2407/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7200\n",
            "Epoch 2408/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7223\n",
            "Epoch 2409/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6798 - accuracy: 0.7178\n",
            "Epoch 2410/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7204\n",
            "Epoch 2411/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7227\n",
            "Epoch 2412/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6691 - accuracy: 0.7214\n",
            "Epoch 2413/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7232\n",
            "Epoch 2414/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7225\n",
            "Epoch 2415/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7203\n",
            "Epoch 2416/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7202\n",
            "Epoch 2417/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7207\n",
            "Epoch 2418/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7157\n",
            "Epoch 2419/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7199\n",
            "Epoch 2420/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6704 - accuracy: 0.7213\n",
            "Epoch 2421/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6785 - accuracy: 0.7186\n",
            "Epoch 2422/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7202\n",
            "Epoch 2423/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7181\n",
            "Epoch 2424/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7210\n",
            "Epoch 2425/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7188\n",
            "Epoch 2426/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7187\n",
            "Epoch 2427/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7225\n",
            "Epoch 2428/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7233\n",
            "Epoch 2429/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7200\n",
            "Epoch 2430/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6727 - accuracy: 0.7188\n",
            "Epoch 2431/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7219\n",
            "Epoch 2432/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7177\n",
            "Epoch 2433/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7199\n",
            "Epoch 2434/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7203\n",
            "Epoch 2435/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7211\n",
            "Epoch 2436/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7194\n",
            "Epoch 2437/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7214\n",
            "Epoch 2438/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7211\n",
            "Epoch 2439/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7189\n",
            "Epoch 2440/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6737 - accuracy: 0.7197\n",
            "Epoch 2441/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7182\n",
            "Epoch 2442/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7194\n",
            "Epoch 2443/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7184\n",
            "Epoch 2444/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6800 - accuracy: 0.7169\n",
            "Epoch 2445/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7209\n",
            "Epoch 2446/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7204\n",
            "Epoch 2447/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7190\n",
            "Epoch 2448/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6774 - accuracy: 0.7169\n",
            "Epoch 2449/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6774 - accuracy: 0.7193\n",
            "Epoch 2450/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6680 - accuracy: 0.7213\n",
            "Epoch 2451/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6701 - accuracy: 0.7212\n",
            "Epoch 2452/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6717 - accuracy: 0.7212\n",
            "Epoch 2453/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7218\n",
            "Epoch 2454/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6715 - accuracy: 0.7222\n",
            "Epoch 2455/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7202\n",
            "Epoch 2456/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7199\n",
            "Epoch 2457/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6679 - accuracy: 0.7220\n",
            "Epoch 2458/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7174\n",
            "Epoch 2459/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7178\n",
            "Epoch 2460/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7193\n",
            "Epoch 2461/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7186\n",
            "Epoch 2462/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6671 - accuracy: 0.7268\n",
            "Epoch 2463/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6817 - accuracy: 0.7173\n",
            "Epoch 2464/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6719 - accuracy: 0.7209\n",
            "Epoch 2465/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7181\n",
            "Epoch 2466/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7186\n",
            "Epoch 2467/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7186\n",
            "Epoch 2468/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6701 - accuracy: 0.7226\n",
            "Epoch 2469/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7219\n",
            "Epoch 2470/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7207\n",
            "Epoch 2471/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7225\n",
            "Epoch 2472/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7232\n",
            "Epoch 2473/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7208\n",
            "Epoch 2474/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7198\n",
            "Epoch 2475/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7203\n",
            "Epoch 2476/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7177\n",
            "Epoch 2477/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7216\n",
            "Epoch 2478/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6636 - accuracy: 0.7232\n",
            "Epoch 2479/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7184\n",
            "Epoch 2480/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6794 - accuracy: 0.7162\n",
            "Epoch 2481/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6727 - accuracy: 0.7206\n",
            "Epoch 2482/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7216\n",
            "Epoch 2483/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7219\n",
            "Epoch 2484/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7215\n",
            "Epoch 2485/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7229\n",
            "Epoch 2486/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7213\n",
            "Epoch 2487/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7208\n",
            "Epoch 2488/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7167\n",
            "Epoch 2489/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7224\n",
            "Epoch 2490/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7201\n",
            "Epoch 2491/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7219\n",
            "Epoch 2492/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7185\n",
            "Epoch 2493/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7229\n",
            "Epoch 2494/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7207\n",
            "Epoch 2495/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6706 - accuracy: 0.7234\n",
            "Epoch 2496/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6759 - accuracy: 0.7211\n",
            "Epoch 2497/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7207\n",
            "Epoch 2498/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7219\n",
            "Epoch 2499/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6801 - accuracy: 0.7187\n",
            "Epoch 2500/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6825 - accuracy: 0.7161\n",
            "Epoch 2501/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7179\n",
            "Epoch 2502/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6655 - accuracy: 0.7228\n",
            "Epoch 2503/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7214\n",
            "Epoch 2504/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7215\n",
            "Epoch 2505/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7222\n",
            "Epoch 2506/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6654 - accuracy: 0.7234\n",
            "Epoch 2507/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6792 - accuracy: 0.7193\n",
            "Epoch 2508/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6706 - accuracy: 0.7213\n",
            "Epoch 2509/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6742 - accuracy: 0.7217\n",
            "Epoch 2510/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7212\n",
            "Epoch 2511/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7213\n",
            "Epoch 2512/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6790 - accuracy: 0.7195\n",
            "Epoch 2513/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7213\n",
            "Epoch 2514/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7186\n",
            "Epoch 2515/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6716 - accuracy: 0.7192\n",
            "Epoch 2516/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7205\n",
            "Epoch 2517/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7253\n",
            "Epoch 2518/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6680 - accuracy: 0.7220\n",
            "Epoch 2519/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7202\n",
            "Epoch 2520/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7198\n",
            "Epoch 2521/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6807 - accuracy: 0.7186\n",
            "Epoch 2522/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7231\n",
            "Epoch 2523/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6704 - accuracy: 0.7209\n",
            "Epoch 2524/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7200\n",
            "Epoch 2525/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7175\n",
            "Epoch 2526/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6685 - accuracy: 0.7228\n",
            "Epoch 2527/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6655 - accuracy: 0.7219\n",
            "Epoch 2528/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6677 - accuracy: 0.7205\n",
            "Epoch 2529/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7207\n",
            "Epoch 2530/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6666 - accuracy: 0.7218\n",
            "Epoch 2531/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7221\n",
            "Epoch 2532/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7197\n",
            "Epoch 2533/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6767 - accuracy: 0.7201\n",
            "Epoch 2534/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7204\n",
            "Epoch 2535/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6830 - accuracy: 0.7168\n",
            "Epoch 2536/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7205\n",
            "Epoch 2537/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6773 - accuracy: 0.7186\n",
            "Epoch 2538/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7208\n",
            "Epoch 2539/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6780 - accuracy: 0.7203\n",
            "Epoch 2540/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7234\n",
            "Epoch 2541/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7211\n",
            "Epoch 2542/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6737 - accuracy: 0.7217\n",
            "Epoch 2543/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7209\n",
            "Epoch 2544/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7176\n",
            "Epoch 2545/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6763 - accuracy: 0.7194\n",
            "Epoch 2546/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7144\n",
            "Epoch 2547/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7191\n",
            "Epoch 2548/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7199\n",
            "Epoch 2549/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7200\n",
            "Epoch 2550/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7192\n",
            "Epoch 2551/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6651 - accuracy: 0.7232\n",
            "Epoch 2552/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6690 - accuracy: 0.7242\n",
            "Epoch 2553/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7206\n",
            "Epoch 2554/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6640 - accuracy: 0.7216\n",
            "Epoch 2555/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7210\n",
            "Epoch 2556/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7189\n",
            "Epoch 2557/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7244\n",
            "Epoch 2558/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6791 - accuracy: 0.7196\n",
            "Epoch 2559/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6762 - accuracy: 0.7183\n",
            "Epoch 2560/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7195\n",
            "Epoch 2561/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7197\n",
            "Epoch 2562/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7205\n",
            "Epoch 2563/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7237\n",
            "Epoch 2564/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6668 - accuracy: 0.7246\n",
            "Epoch 2565/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6668 - accuracy: 0.7214\n",
            "Epoch 2566/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7226\n",
            "Epoch 2567/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6676 - accuracy: 0.7240\n",
            "Epoch 2568/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6745 - accuracy: 0.7213\n",
            "Epoch 2569/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6717 - accuracy: 0.7215\n",
            "Epoch 2570/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6671 - accuracy: 0.7211\n",
            "Epoch 2571/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7223\n",
            "Epoch 2572/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6721 - accuracy: 0.7191\n",
            "Epoch 2573/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7206\n",
            "Epoch 2574/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7196\n",
            "Epoch 2575/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7220\n",
            "Epoch 2576/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7222\n",
            "Epoch 2577/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6726 - accuracy: 0.7225\n",
            "Epoch 2578/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7234\n",
            "Epoch 2579/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7228\n",
            "Epoch 2580/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7189\n",
            "Epoch 2581/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6708 - accuracy: 0.7213\n",
            "Epoch 2582/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7219\n",
            "Epoch 2583/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7205\n",
            "Epoch 2584/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7205\n",
            "Epoch 2585/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7215\n",
            "Epoch 2586/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6704 - accuracy: 0.7217\n",
            "Epoch 2587/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7185\n",
            "Epoch 2588/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7200\n",
            "Epoch 2589/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7194\n",
            "Epoch 2590/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7220\n",
            "Epoch 2591/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6673 - accuracy: 0.7227\n",
            "Epoch 2592/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7197\n",
            "Epoch 2593/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6658 - accuracy: 0.7234\n",
            "Epoch 2594/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7192\n",
            "Epoch 2595/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7209\n",
            "Epoch 2596/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7178\n",
            "Epoch 2597/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7223\n",
            "Epoch 2598/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6774 - accuracy: 0.7194\n",
            "Epoch 2599/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6660 - accuracy: 0.7242\n",
            "Epoch 2600/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6727 - accuracy: 0.7208\n",
            "Epoch 2601/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7211\n",
            "Epoch 2602/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6669 - accuracy: 0.7239\n",
            "Epoch 2603/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7218\n",
            "Epoch 2604/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6764 - accuracy: 0.7200\n",
            "Epoch 2605/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7186\n",
            "Epoch 2606/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7217\n",
            "Epoch 2607/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7220\n",
            "Epoch 2608/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7223\n",
            "Epoch 2609/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6776 - accuracy: 0.7203\n",
            "Epoch 2610/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7223\n",
            "Epoch 2611/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7202\n",
            "Epoch 2612/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6659 - accuracy: 0.7261\n",
            "Epoch 2613/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6689 - accuracy: 0.7213\n",
            "Epoch 2614/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7189\n",
            "Epoch 2615/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7200\n",
            "Epoch 2616/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6632 - accuracy: 0.7252\n",
            "Epoch 2617/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6795 - accuracy: 0.7183\n",
            "Epoch 2618/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7223\n",
            "Epoch 2619/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7207\n",
            "Epoch 2620/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6661 - accuracy: 0.7232\n",
            "Epoch 2621/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7199\n",
            "Epoch 2622/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7219\n",
            "Epoch 2623/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7237\n",
            "Epoch 2624/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7165\n",
            "Epoch 2625/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6713 - accuracy: 0.7220\n",
            "Epoch 2626/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7187\n",
            "Epoch 2627/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6646 - accuracy: 0.7239\n",
            "Epoch 2628/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7220\n",
            "Epoch 2629/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7192\n",
            "Epoch 2630/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7237\n",
            "Epoch 2631/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6763 - accuracy: 0.7193\n",
            "Epoch 2632/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6744 - accuracy: 0.7205\n",
            "Epoch 2633/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7214\n",
            "Epoch 2634/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6701 - accuracy: 0.7235\n",
            "Epoch 2635/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6644 - accuracy: 0.7250\n",
            "Epoch 2636/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7185\n",
            "Epoch 2637/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6708 - accuracy: 0.7212\n",
            "Epoch 2638/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7191\n",
            "Epoch 2639/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7227\n",
            "Epoch 2640/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6765 - accuracy: 0.7213\n",
            "Epoch 2641/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7202\n",
            "Epoch 2642/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6695 - accuracy: 0.7236\n",
            "Epoch 2643/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7192\n",
            "Epoch 2644/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7191\n",
            "Epoch 2645/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7234\n",
            "Epoch 2646/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7207\n",
            "Epoch 2647/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6764 - accuracy: 0.7194\n",
            "Epoch 2648/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7173\n",
            "Epoch 2649/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7221\n",
            "Epoch 2650/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6695 - accuracy: 0.7199\n",
            "Epoch 2651/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7191\n",
            "Epoch 2652/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7230\n",
            "Epoch 2653/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7224\n",
            "Epoch 2654/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7195\n",
            "Epoch 2655/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6677 - accuracy: 0.7224\n",
            "Epoch 2656/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7202\n",
            "Epoch 2657/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7211\n",
            "Epoch 2658/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6673 - accuracy: 0.7227\n",
            "Epoch 2659/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7188\n",
            "Epoch 2660/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7229\n",
            "Epoch 2661/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7198\n",
            "Epoch 2662/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6662 - accuracy: 0.7237\n",
            "Epoch 2663/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7199\n",
            "Epoch 2664/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7213\n",
            "Epoch 2665/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7205\n",
            "Epoch 2666/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6705 - accuracy: 0.7198\n",
            "Epoch 2667/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7233\n",
            "Epoch 2668/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7225\n",
            "Epoch 2669/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6695 - accuracy: 0.7232\n",
            "Epoch 2670/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7180\n",
            "Epoch 2671/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7239\n",
            "Epoch 2672/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7193\n",
            "Epoch 2673/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6645 - accuracy: 0.7224\n",
            "Epoch 2674/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6789 - accuracy: 0.7207\n",
            "Epoch 2675/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7220\n",
            "Epoch 2676/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6750 - accuracy: 0.7196\n",
            "Epoch 2677/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7249\n",
            "Epoch 2678/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6653 - accuracy: 0.7219\n",
            "Epoch 2679/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7208\n",
            "Epoch 2680/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7208\n",
            "Epoch 2681/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6735 - accuracy: 0.7208\n",
            "Epoch 2682/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7197\n",
            "Epoch 2683/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7231\n",
            "Epoch 2684/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7193\n",
            "Epoch 2685/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7212\n",
            "Epoch 2686/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6719 - accuracy: 0.7244\n",
            "Epoch 2687/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7204\n",
            "Epoch 2688/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6831 - accuracy: 0.7181\n",
            "Epoch 2689/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7236\n",
            "Epoch 2690/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7226\n",
            "Epoch 2691/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6670 - accuracy: 0.7241\n",
            "Epoch 2692/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6713 - accuracy: 0.7209\n",
            "Epoch 2693/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6656 - accuracy: 0.7249\n",
            "Epoch 2694/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6771 - accuracy: 0.7189\n",
            "Epoch 2695/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7209\n",
            "Epoch 2696/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6747 - accuracy: 0.7168\n",
            "Epoch 2697/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7213\n",
            "Epoch 2698/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6666 - accuracy: 0.7219\n",
            "Epoch 2699/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7236\n",
            "Epoch 2700/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6586 - accuracy: 0.7275\n",
            "Epoch 2701/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7202\n",
            "Epoch 2702/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7197\n",
            "Epoch 2703/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6643 - accuracy: 0.7226\n",
            "Epoch 2704/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6804 - accuracy: 0.7188\n",
            "Epoch 2705/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7238\n",
            "Epoch 2706/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7190\n",
            "Epoch 2707/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7202\n",
            "Epoch 2708/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7217\n",
            "Epoch 2709/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7235\n",
            "Epoch 2710/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7208\n",
            "Epoch 2711/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6687 - accuracy: 0.7252\n",
            "Epoch 2712/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6676 - accuracy: 0.7217\n",
            "Epoch 2713/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6663 - accuracy: 0.7243\n",
            "Epoch 2714/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7247\n",
            "Epoch 2715/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6663 - accuracy: 0.7232\n",
            "Epoch 2716/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7231\n",
            "Epoch 2717/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7244\n",
            "Epoch 2718/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6671 - accuracy: 0.7252\n",
            "Epoch 2719/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6681 - accuracy: 0.7250\n",
            "Epoch 2720/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6731 - accuracy: 0.7203\n",
            "Epoch 2721/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6680 - accuracy: 0.7210\n",
            "Epoch 2722/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7216\n",
            "Epoch 2723/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6640 - accuracy: 0.7244\n",
            "Epoch 2724/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7217\n",
            "Epoch 2725/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7207\n",
            "Epoch 2726/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7194\n",
            "Epoch 2727/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7172\n",
            "Epoch 2728/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6658 - accuracy: 0.7222\n",
            "Epoch 2729/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6662 - accuracy: 0.7217\n",
            "Epoch 2730/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6659 - accuracy: 0.7210\n",
            "Epoch 2731/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6756 - accuracy: 0.7205\n",
            "Epoch 2732/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6768 - accuracy: 0.7192\n",
            "Epoch 2733/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6738 - accuracy: 0.7205\n",
            "Epoch 2734/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6690 - accuracy: 0.7217\n",
            "Epoch 2735/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7204\n",
            "Epoch 2736/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6718 - accuracy: 0.7202\n",
            "Epoch 2737/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6755 - accuracy: 0.7195\n",
            "Epoch 2738/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6705 - accuracy: 0.7224\n",
            "Epoch 2739/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7211\n",
            "Epoch 2740/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6676 - accuracy: 0.7222\n",
            "Epoch 2741/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6692 - accuracy: 0.7221\n",
            "Epoch 2742/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6806 - accuracy: 0.7156\n",
            "Epoch 2743/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7227\n",
            "Epoch 2744/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6655 - accuracy: 0.7224\n",
            "Epoch 2745/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6784 - accuracy: 0.7199\n",
            "Epoch 2746/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7224\n",
            "Epoch 2747/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7202\n",
            "Epoch 2748/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7238\n",
            "Epoch 2749/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7193\n",
            "Epoch 2750/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6770 - accuracy: 0.7203\n",
            "Epoch 2751/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7206\n",
            "Epoch 2752/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7189\n",
            "Epoch 2753/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6686 - accuracy: 0.7220\n",
            "Epoch 2754/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6649 - accuracy: 0.7233\n",
            "Epoch 2755/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6757 - accuracy: 0.7177\n",
            "Epoch 2756/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6754 - accuracy: 0.7207\n",
            "Epoch 2757/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6729 - accuracy: 0.7206\n",
            "Epoch 2758/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6721 - accuracy: 0.7220\n",
            "Epoch 2759/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7200\n",
            "Epoch 2760/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7204\n",
            "Epoch 2761/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7201\n",
            "Epoch 2762/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6769 - accuracy: 0.7181\n",
            "Epoch 2763/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6722 - accuracy: 0.7229\n",
            "Epoch 2764/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6666 - accuracy: 0.7276\n",
            "Epoch 2765/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6681 - accuracy: 0.7237\n",
            "Epoch 2766/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6689 - accuracy: 0.7222\n",
            "Epoch 2767/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7229\n",
            "Epoch 2768/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7215\n",
            "Epoch 2769/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7241\n",
            "Epoch 2770/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6708 - accuracy: 0.7192\n",
            "Epoch 2771/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7194\n",
            "Epoch 2772/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7243\n",
            "Epoch 2773/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7202\n",
            "Epoch 2774/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7225\n",
            "Epoch 2775/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6666 - accuracy: 0.7230\n",
            "Epoch 2776/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7213\n",
            "Epoch 2777/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7226\n",
            "Epoch 2778/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7211\n",
            "Epoch 2779/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6626 - accuracy: 0.7247\n",
            "Epoch 2780/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7218\n",
            "Epoch 2781/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6656 - accuracy: 0.7225\n",
            "Epoch 2782/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7231\n",
            "Epoch 2783/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7205\n",
            "Epoch 2784/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6723 - accuracy: 0.7219\n",
            "Epoch 2785/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6704 - accuracy: 0.7188\n",
            "Epoch 2786/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7238\n",
            "Epoch 2787/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6706 - accuracy: 0.7214\n",
            "Epoch 2788/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6715 - accuracy: 0.7219\n",
            "Epoch 2789/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6716 - accuracy: 0.7220\n",
            "Epoch 2790/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6662 - accuracy: 0.7226\n",
            "Epoch 2791/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6659 - accuracy: 0.7226\n",
            "Epoch 2792/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6656 - accuracy: 0.7226\n",
            "Epoch 2793/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7201\n",
            "Epoch 2794/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6677 - accuracy: 0.7228\n",
            "Epoch 2795/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7222\n",
            "Epoch 2796/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6687 - accuracy: 0.7221\n",
            "Epoch 2797/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7236\n",
            "Epoch 2798/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7190\n",
            "Epoch 2799/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6766 - accuracy: 0.7193\n",
            "Epoch 2800/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6690 - accuracy: 0.7238\n",
            "Epoch 2801/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6670 - accuracy: 0.7229\n",
            "Epoch 2802/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7190\n",
            "Epoch 2803/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6775 - accuracy: 0.7182\n",
            "Epoch 2804/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7195\n",
            "Epoch 2805/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6687 - accuracy: 0.7226\n",
            "Epoch 2806/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6666 - accuracy: 0.7248\n",
            "Epoch 2807/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7223\n",
            "Epoch 2808/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7209\n",
            "Epoch 2809/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7216\n",
            "Epoch 2810/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6651 - accuracy: 0.7218\n",
            "Epoch 2811/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7199\n",
            "Epoch 2812/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6673 - accuracy: 0.7231\n",
            "Epoch 2813/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7237\n",
            "Epoch 2814/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7221\n",
            "Epoch 2815/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7246\n",
            "Epoch 2816/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6687 - accuracy: 0.7206\n",
            "Epoch 2817/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6659 - accuracy: 0.7225\n",
            "Epoch 2818/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6704 - accuracy: 0.7227\n",
            "Epoch 2819/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6724 - accuracy: 0.7206\n",
            "Epoch 2820/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7209\n",
            "Epoch 2821/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7193\n",
            "Epoch 2822/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6662 - accuracy: 0.7228\n",
            "Epoch 2823/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7232\n",
            "Epoch 2824/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7203\n",
            "Epoch 2825/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6691 - accuracy: 0.7227\n",
            "Epoch 2826/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7222\n",
            "Epoch 2827/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7200\n",
            "Epoch 2828/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7220\n",
            "Epoch 2829/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7234\n",
            "Epoch 2830/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6778 - accuracy: 0.7208\n",
            "Epoch 2831/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6659 - accuracy: 0.7224\n",
            "Epoch 2832/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6751 - accuracy: 0.7194\n",
            "Epoch 2833/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6661 - accuracy: 0.7234\n",
            "Epoch 2834/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7191\n",
            "Epoch 2835/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6752 - accuracy: 0.7223\n",
            "Epoch 2836/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7216\n",
            "Epoch 2837/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7240\n",
            "Epoch 2838/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7209\n",
            "Epoch 2839/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6640 - accuracy: 0.7239\n",
            "Epoch 2840/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6642 - accuracy: 0.7254\n",
            "Epoch 2841/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6731 - accuracy: 0.7201\n",
            "Epoch 2842/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7217\n",
            "Epoch 2843/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6743 - accuracy: 0.7202\n",
            "Epoch 2844/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6645 - accuracy: 0.7247\n",
            "Epoch 2845/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6653 - accuracy: 0.7210\n",
            "Epoch 2846/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7203\n",
            "Epoch 2847/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7222\n",
            "Epoch 2848/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6788 - accuracy: 0.7166\n",
            "Epoch 2849/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6657 - accuracy: 0.7238\n",
            "Epoch 2850/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6673 - accuracy: 0.7251\n",
            "Epoch 2851/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6745 - accuracy: 0.7208\n",
            "Epoch 2852/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6711 - accuracy: 0.7209\n",
            "Epoch 2853/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6631 - accuracy: 0.7233\n",
            "Epoch 2854/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7186\n",
            "Epoch 2855/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6642 - accuracy: 0.7250\n",
            "Epoch 2856/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7240\n",
            "Epoch 2857/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7243\n",
            "Epoch 2858/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6686 - accuracy: 0.7209\n",
            "Epoch 2859/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7215\n",
            "Epoch 2860/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7211\n",
            "Epoch 2861/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7205\n",
            "Epoch 2862/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7216\n",
            "Epoch 2863/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6660 - accuracy: 0.7220\n",
            "Epoch 2864/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6671 - accuracy: 0.7219\n",
            "Epoch 2865/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6730 - accuracy: 0.7210\n",
            "Epoch 2866/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7235\n",
            "Epoch 2867/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6772 - accuracy: 0.7173\n",
            "Epoch 2868/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7214\n",
            "Epoch 2869/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6648 - accuracy: 0.7210\n",
            "Epoch 2870/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6668 - accuracy: 0.7221\n",
            "Epoch 2871/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7236\n",
            "Epoch 2872/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6753 - accuracy: 0.7197\n",
            "Epoch 2873/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7234\n",
            "Epoch 2874/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6748 - accuracy: 0.7183\n",
            "Epoch 2875/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6665 - accuracy: 0.7242\n",
            "Epoch 2876/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7229\n",
            "Epoch 2877/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7212\n",
            "Epoch 2878/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6716 - accuracy: 0.7220\n",
            "Epoch 2879/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6637 - accuracy: 0.7220\n",
            "Epoch 2880/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6682 - accuracy: 0.7231\n",
            "Epoch 2881/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7221\n",
            "Epoch 2882/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6675 - accuracy: 0.7245\n",
            "Epoch 2883/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6779 - accuracy: 0.7197\n",
            "Epoch 2884/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6674 - accuracy: 0.7230\n",
            "Epoch 2885/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7224\n",
            "Epoch 2886/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7221\n",
            "Epoch 2887/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6667 - accuracy: 0.7217\n",
            "Epoch 2888/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6623 - accuracy: 0.7251\n",
            "Epoch 2889/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7229\n",
            "Epoch 2890/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6712 - accuracy: 0.7185\n",
            "Epoch 2891/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7214\n",
            "Epoch 2892/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6728 - accuracy: 0.7226\n",
            "Epoch 2893/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6693 - accuracy: 0.7238\n",
            "Epoch 2894/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7220\n",
            "Epoch 2895/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7201\n",
            "Epoch 2896/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6623 - accuracy: 0.7248\n",
            "Epoch 2897/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7192\n",
            "Epoch 2898/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6620 - accuracy: 0.7235\n",
            "Epoch 2899/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6689 - accuracy: 0.7235\n",
            "Epoch 2900/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6646 - accuracy: 0.7273\n",
            "Epoch 2901/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6648 - accuracy: 0.7222\n",
            "Epoch 2902/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6660 - accuracy: 0.7235\n",
            "Epoch 2903/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6709 - accuracy: 0.7234\n",
            "Epoch 2904/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6572 - accuracy: 0.7275\n",
            "Epoch 2905/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7216\n",
            "Epoch 2906/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7230\n",
            "Epoch 2907/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6638 - accuracy: 0.7245\n",
            "Epoch 2908/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6670 - accuracy: 0.7231\n",
            "Epoch 2909/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6702 - accuracy: 0.7216\n",
            "Epoch 2910/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6667 - accuracy: 0.7220\n",
            "Epoch 2911/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6717 - accuracy: 0.7222\n",
            "Epoch 2912/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7202\n",
            "Epoch 2913/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6679 - accuracy: 0.7226\n",
            "Epoch 2914/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6746 - accuracy: 0.7197\n",
            "Epoch 2915/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6720 - accuracy: 0.7228\n",
            "Epoch 2916/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6676 - accuracy: 0.7232\n",
            "Epoch 2917/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6694 - accuracy: 0.7223\n",
            "Epoch 2918/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6689 - accuracy: 0.7207\n",
            "Epoch 2919/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6691 - accuracy: 0.7241\n",
            "Epoch 2920/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6741 - accuracy: 0.7198\n",
            "Epoch 2921/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7223\n",
            "Epoch 2922/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6740 - accuracy: 0.7212\n",
            "Epoch 2923/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6716 - accuracy: 0.7197\n",
            "Epoch 2924/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6663 - accuracy: 0.7227\n",
            "Epoch 2925/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7216\n",
            "Epoch 2926/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6681 - accuracy: 0.7226\n",
            "Epoch 2927/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6610 - accuracy: 0.7245\n",
            "Epoch 2928/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6667 - accuracy: 0.7246\n",
            "Epoch 2929/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6719 - accuracy: 0.7217\n",
            "Epoch 2930/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6649 - accuracy: 0.7243\n",
            "Epoch 2931/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7212\n",
            "Epoch 2932/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6732 - accuracy: 0.7206\n",
            "Epoch 2933/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6648 - accuracy: 0.7229\n",
            "Epoch 2934/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6706 - accuracy: 0.7212\n",
            "Epoch 2935/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6646 - accuracy: 0.7239\n",
            "Epoch 2936/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7243\n",
            "Epoch 2937/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6672 - accuracy: 0.7233\n",
            "Epoch 2938/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6749 - accuracy: 0.7227\n",
            "Epoch 2939/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6680 - accuracy: 0.7213\n",
            "Epoch 2940/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6663 - accuracy: 0.7250\n",
            "Epoch 2941/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6685 - accuracy: 0.7207\n",
            "Epoch 2942/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7204\n",
            "Epoch 2943/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6678 - accuracy: 0.7251\n",
            "Epoch 2944/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6758 - accuracy: 0.7188\n",
            "Epoch 2945/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6699 - accuracy: 0.7217\n",
            "Epoch 2946/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6652 - accuracy: 0.7222\n",
            "Epoch 2947/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6689 - accuracy: 0.7212\n",
            "Epoch 2948/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6684 - accuracy: 0.7217\n",
            "Epoch 2949/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6715 - accuracy: 0.7186\n",
            "Epoch 2950/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7206\n",
            "Epoch 2951/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6700 - accuracy: 0.7220\n",
            "Epoch 2952/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6739 - accuracy: 0.7216\n",
            "Epoch 2953/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6628 - accuracy: 0.7254\n",
            "Epoch 2954/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6668 - accuracy: 0.7245\n",
            "Epoch 2955/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6714 - accuracy: 0.7212\n",
            "Epoch 2956/3000\n",
            "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6697 - accuracy: 0.7221\n",
            "Epoch 2957/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7234\n",
            "Epoch 2958/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6646 - accuracy: 0.7251\n",
            "Epoch 2959/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7222\n",
            "Epoch 2960/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7204\n",
            "Epoch 2961/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6650 - accuracy: 0.7229\n",
            "Epoch 2962/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6681 - accuracy: 0.7227\n",
            "Epoch 2963/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6731 - accuracy: 0.7211\n",
            "Epoch 2964/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7207\n",
            "Epoch 2965/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6653 - accuracy: 0.7239\n",
            "Epoch 2966/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6698 - accuracy: 0.7207\n",
            "Epoch 2967/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6669 - accuracy: 0.7220\n",
            "Epoch 2968/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6737 - accuracy: 0.7205\n",
            "Epoch 2969/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6701 - accuracy: 0.7210\n",
            "Epoch 2970/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6660 - accuracy: 0.7230\n",
            "Epoch 2971/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6760 - accuracy: 0.7209\n",
            "Epoch 2972/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6685 - accuracy: 0.7207\n",
            "Epoch 2973/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6733 - accuracy: 0.7196\n",
            "Epoch 2974/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6680 - accuracy: 0.7206\n",
            "Epoch 2975/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6710 - accuracy: 0.7221\n",
            "Epoch 2976/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6690 - accuracy: 0.7216\n",
            "Epoch 2977/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6708 - accuracy: 0.7238\n",
            "Epoch 2978/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6669 - accuracy: 0.7233\n",
            "Epoch 2979/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6703 - accuracy: 0.7205\n",
            "Epoch 2980/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6679 - accuracy: 0.7223\n",
            "Epoch 2981/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6721 - accuracy: 0.7197\n",
            "Epoch 2982/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6742 - accuracy: 0.7225\n",
            "Epoch 2983/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6653 - accuracy: 0.7202\n",
            "Epoch 2984/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6668 - accuracy: 0.7214\n",
            "Epoch 2985/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6635 - accuracy: 0.7265\n",
            "Epoch 2986/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6696 - accuracy: 0.7206\n",
            "Epoch 2987/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6671 - accuracy: 0.7239\n",
            "Epoch 2988/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6707 - accuracy: 0.7216\n",
            "Epoch 2989/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6624 - accuracy: 0.7253\n",
            "Epoch 2990/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6647 - accuracy: 0.7228\n",
            "Epoch 2991/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6692 - accuracy: 0.7226\n",
            "Epoch 2992/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6623 - accuracy: 0.7264\n",
            "Epoch 2993/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7228\n",
            "Epoch 2994/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6628 - accuracy: 0.7251\n",
            "Epoch 2995/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6685 - accuracy: 0.7224\n",
            "Epoch 2996/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6736 - accuracy: 0.7201\n",
            "Epoch 2997/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6734 - accuracy: 0.7215\n",
            "Epoch 2998/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6725 - accuracy: 0.7195\n",
            "Epoch 2999/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6662 - accuracy: 0.7232\n",
            "Epoch 3000/3000\n",
            "1000/1000 [==============================] - 6s 6ms/step - loss: 0.6683 - accuracy: 0.7232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'])\n",
        "plt.title('accuracy');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "C8N1xP_G0CDX",
        "outputId": "885f6e7c-ef8e-4ca6-e3bf-f3162825c9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mRkFw950Rng",
        "outputId": "e5721ebb-6b36-4fde-9d0f-3afa6f726690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 1.2599 - accuracy: 0.6768 - 950ms/epoch - 3ms/step\n",
            "accuracy: 67.68%\n",
            "CPU times: user 1.23 s, sys: 190 ms, total: 1.42 s\n",
            "Wall time: 1.61 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
        "predictions = cnn_model.predict(x_test)\n",
        "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
        "print(cm); print()\n",
        "\n",
        "print('Classification accuracy for each class:'); print()\n",
        "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jsWhGrx0XrT",
        "outputId": "2a200f1f-fd42-4257-9467-c8c35ef74d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (rows: true classes; columns: predicted classes):\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[768  21  62  18  24   4   6  11  70  16]\n",
            " [ 31 829  11   8   2   2   7   7  32  71]\n",
            " [ 87   6 566  75 109  42  77  25   8   5]\n",
            " [ 27  10  89 473  84 156  94  37  15  15]\n",
            " [ 27   3  76  59 634  32  54 103  12   0]\n",
            " [ 10   4  62 225  51 537  34  62   9   6]\n",
            " [ 11  11  52  46  61  28 778   6   4   3]\n",
            " [ 10   2  67  42  88  56   4 717   2  12]\n",
            " [161  30  12  17   6   8   7   4 733  22]\n",
            " [ 31 127   9  17   9   8   8  13  45 733]]\n",
            "\n",
            "Classification accuracy for each class:\n",
            "\n",
            "0: 0.7680\n",
            "1: 0.8290\n",
            "2: 0.5660\n",
            "3: 0.4730\n",
            "4: 0.6340\n",
            "5: 0.5370\n",
            "6: 0.7780\n",
            "7: 0.7170\n",
            "8: 0.7330\n",
            "9: 0.7330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now trying with the \"More Verbose Training\":"
      ],
      "metadata": {
        "id": "kWgc1wnE5t5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(y_true, y_pred):\n",
        "    # if labels are integers, use sparse categorical crossentropy\n",
        "    # network's final layer is softmax, so from_logtis=False\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    # if labels are one-hot encoded, use standard crossentropy\n",
        "\n",
        "    return scce(y_true, y_pred)  "
      ],
      "metadata": {
        "id": "RPIqJdi051NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(model, batch_data, y_true):\n",
        "    y_pred = model(batch_data)\n",
        "    loss = compute_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Py939n1m57Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a function that will manage the training loop for us:\n",
        "\n",
        "def train_loop(batch_size, n_training_epochs, model, opt):\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_iteration(data, y_true, model, opt):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = forward_pass(model, data, y_true)\n",
        "\n",
        "        trainable_vars = model.trainable_variables\n",
        "\n",
        "        # Apply the update to the network (one at a time):\n",
        "        grads = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        opt.apply_gradients(zip(grads, trainable_vars))\n",
        "        return loss\n",
        "\n",
        "    for i_epoch in range(n_training_epochs):\n",
        "        print(\"beginning epoch %d\" % i_epoch)\n",
        "        start = time.time()\n",
        "\n",
        "        epoch_steps = int(50000/batch_size)\n",
        "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
        "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "        \n",
        "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
        "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
        "            loss = train_iteration(batch_data, y_true, model, opt)\n",
        "            \n",
        "        end = time.time()\n",
        "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
      ],
      "metadata": {
        "id": "28Yqjr0l6FLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    mnist_model = CIFAR10Classifier()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(_lr)\n",
        "\n",
        "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)\n",
        "    #the compile step is probably off...I'm just not sure what to do to generate the history...\n",
        "    mnist_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "    history = mnist_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ],
      "metadata": {
        "id": "GNk1lPvL6Lo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset.shuffle(50000)\n",
        "\n",
        "batch_size = 50\n",
        "epochs = 1000\n",
        "lr = .1\n",
        "history, new_cnn = train_network(batch_size, epochs, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXPGtBF56NUS",
        "outputId": "13c119f9-b125-42be-ec19-31cc8a8ae51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beginning epoch 0\n",
            "took 4.5 seconds for epoch #0\n",
            "beginning epoch 1\n",
            "took 4.1 seconds for epoch #1\n",
            "beginning epoch 2\n",
            "took 4.0 seconds for epoch #2\n",
            "beginning epoch 3\n",
            "took 4.0 seconds for epoch #3\n",
            "beginning epoch 4\n",
            "took 4.2 seconds for epoch #4\n",
            "beginning epoch 5\n",
            "took 5.4 seconds for epoch #5\n",
            "beginning epoch 6\n",
            "took 5.5 seconds for epoch #6\n",
            "beginning epoch 7\n",
            "took 5.1 seconds for epoch #7\n",
            "beginning epoch 8\n",
            "took 5.1 seconds for epoch #8\n",
            "beginning epoch 9\n",
            "took 4.4 seconds for epoch #9\n",
            "beginning epoch 10\n",
            "took 4.1 seconds for epoch #10\n",
            "beginning epoch 11\n",
            "took 4.1 seconds for epoch #11\n",
            "beginning epoch 12\n",
            "took 4.0 seconds for epoch #12\n",
            "beginning epoch 13\n",
            "took 4.0 seconds for epoch #13\n",
            "beginning epoch 14\n",
            "took 4.0 seconds for epoch #14\n",
            "beginning epoch 15\n",
            "took 4.0 seconds for epoch #15\n",
            "beginning epoch 16\n",
            "took 4.0 seconds for epoch #16\n",
            "beginning epoch 17\n",
            "took 4.0 seconds for epoch #17\n",
            "beginning epoch 18\n",
            "took 4.0 seconds for epoch #18\n",
            "beginning epoch 19\n",
            "took 4.0 seconds for epoch #19\n",
            "beginning epoch 20\n",
            "took 4.0 seconds for epoch #20\n",
            "beginning epoch 21\n",
            "took 4.0 seconds for epoch #21\n",
            "beginning epoch 22\n",
            "took 4.3 seconds for epoch #22\n",
            "beginning epoch 23\n",
            "took 4.0 seconds for epoch #23\n",
            "beginning epoch 24\n",
            "took 4.6 seconds for epoch #24\n",
            "beginning epoch 25\n",
            "took 4.0 seconds for epoch #25\n",
            "beginning epoch 26\n",
            "took 4.1 seconds for epoch #26\n",
            "beginning epoch 27\n",
            "took 4.3 seconds for epoch #27\n",
            "beginning epoch 28\n",
            "took 4.1 seconds for epoch #28\n",
            "beginning epoch 29\n",
            "took 4.7 seconds for epoch #29\n",
            "beginning epoch 30\n",
            "took 4.7 seconds for epoch #30\n",
            "beginning epoch 31\n",
            "took 4.0 seconds for epoch #31\n",
            "beginning epoch 32\n",
            "took 4.0 seconds for epoch #32\n",
            "beginning epoch 33\n",
            "took 4.0 seconds for epoch #33\n",
            "beginning epoch 34\n",
            "took 4.0 seconds for epoch #34\n",
            "beginning epoch 35\n",
            "took 4.0 seconds for epoch #35\n",
            "beginning epoch 36\n",
            "took 4.0 seconds for epoch #36\n",
            "beginning epoch 37\n",
            "took 4.0 seconds for epoch #37\n",
            "beginning epoch 38\n",
            "took 3.9 seconds for epoch #38\n",
            "beginning epoch 39\n",
            "took 4.0 seconds for epoch #39\n",
            "beginning epoch 40\n",
            "took 3.9 seconds for epoch #40\n",
            "beginning epoch 41\n",
            "took 4.0 seconds for epoch #41\n",
            "beginning epoch 42\n",
            "took 4.0 seconds for epoch #42\n",
            "beginning epoch 43\n",
            "took 4.0 seconds for epoch #43\n",
            "beginning epoch 44\n",
            "took 4.0 seconds for epoch #44\n",
            "beginning epoch 45\n",
            "took 4.0 seconds for epoch #45\n",
            "beginning epoch 46\n",
            "took 4.0 seconds for epoch #46\n",
            "beginning epoch 47\n",
            "took 4.0 seconds for epoch #47\n",
            "beginning epoch 48\n",
            "took 4.0 seconds for epoch #48\n",
            "beginning epoch 49\n",
            "took 4.0 seconds for epoch #49\n",
            "beginning epoch 50\n",
            "took 4.0 seconds for epoch #50\n",
            "beginning epoch 51\n",
            "took 4.0 seconds for epoch #51\n",
            "beginning epoch 52\n",
            "took 4.1 seconds for epoch #52\n",
            "beginning epoch 53\n",
            "took 4.0 seconds for epoch #53\n",
            "beginning epoch 54\n",
            "took 5.4 seconds for epoch #54\n",
            "beginning epoch 55\n",
            "took 4.0 seconds for epoch #55\n",
            "beginning epoch 56\n",
            "took 4.0 seconds for epoch #56\n",
            "beginning epoch 57\n",
            "took 4.0 seconds for epoch #57\n",
            "beginning epoch 58\n",
            "took 4.0 seconds for epoch #58\n",
            "beginning epoch 59\n",
            "took 4.0 seconds for epoch #59\n",
            "beginning epoch 60\n",
            "took 4.0 seconds for epoch #60\n",
            "beginning epoch 61\n",
            "took 4.0 seconds for epoch #61\n",
            "beginning epoch 62\n",
            "took 4.0 seconds for epoch #62\n",
            "beginning epoch 63\n",
            "took 4.0 seconds for epoch #63\n",
            "beginning epoch 64\n",
            "took 4.0 seconds for epoch #64\n",
            "beginning epoch 65\n",
            "took 4.0 seconds for epoch #65\n",
            "beginning epoch 66\n",
            "took 3.9 seconds for epoch #66\n",
            "beginning epoch 67\n",
            "took 4.0 seconds for epoch #67\n",
            "beginning epoch 68\n",
            "took 4.0 seconds for epoch #68\n",
            "beginning epoch 69\n",
            "took 4.0 seconds for epoch #69\n",
            "beginning epoch 70\n",
            "took 3.9 seconds for epoch #70\n",
            "beginning epoch 71\n",
            "took 4.0 seconds for epoch #71\n",
            "beginning epoch 72\n",
            "took 4.0 seconds for epoch #72\n",
            "beginning epoch 73\n",
            "took 4.0 seconds for epoch #73\n",
            "beginning epoch 74\n",
            "took 4.0 seconds for epoch #74\n",
            "beginning epoch 75\n",
            "took 4.0 seconds for epoch #75\n",
            "beginning epoch 76\n",
            "took 4.0 seconds for epoch #76\n",
            "beginning epoch 77\n",
            "took 4.0 seconds for epoch #77\n",
            "beginning epoch 78\n",
            "took 5.4 seconds for epoch #78\n",
            "beginning epoch 79\n",
            "took 4.0 seconds for epoch #79\n",
            "beginning epoch 80\n",
            "took 4.0 seconds for epoch #80\n",
            "beginning epoch 81\n",
            "took 4.0 seconds for epoch #81\n",
            "beginning epoch 82\n",
            "took 4.0 seconds for epoch #82\n",
            "beginning epoch 83\n",
            "took 4.4 seconds for epoch #83\n",
            "beginning epoch 84\n",
            "took 3.9 seconds for epoch #84\n",
            "beginning epoch 85\n",
            "took 4.0 seconds for epoch #85\n",
            "beginning epoch 86\n",
            "took 3.9 seconds for epoch #86\n",
            "beginning epoch 87\n",
            "took 4.0 seconds for epoch #87\n",
            "beginning epoch 88\n",
            "took 3.9 seconds for epoch #88\n",
            "beginning epoch 89\n",
            "took 4.0 seconds for epoch #89\n",
            "beginning epoch 90\n",
            "took 4.0 seconds for epoch #90\n",
            "beginning epoch 91\n",
            "took 4.0 seconds for epoch #91\n",
            "beginning epoch 92\n",
            "took 4.0 seconds for epoch #92\n",
            "beginning epoch 93\n",
            "took 4.0 seconds for epoch #93\n",
            "beginning epoch 94\n",
            "took 4.0 seconds for epoch #94\n",
            "beginning epoch 95\n",
            "took 4.0 seconds for epoch #95\n",
            "beginning epoch 96\n",
            "took 4.0 seconds for epoch #96\n",
            "beginning epoch 97\n",
            "took 4.0 seconds for epoch #97\n",
            "beginning epoch 98\n",
            "took 4.0 seconds for epoch #98\n",
            "beginning epoch 99\n",
            "took 4.0 seconds for epoch #99\n",
            "beginning epoch 100\n",
            "took 4.0 seconds for epoch #100\n",
            "beginning epoch 101\n",
            "took 3.9 seconds for epoch #101\n",
            "beginning epoch 102\n",
            "took 4.0 seconds for epoch #102\n",
            "beginning epoch 103\n",
            "took 4.0 seconds for epoch #103\n",
            "beginning epoch 104\n",
            "took 4.2 seconds for epoch #104\n",
            "beginning epoch 105\n",
            "took 4.5 seconds for epoch #105\n",
            "beginning epoch 106\n",
            "took 4.5 seconds for epoch #106\n",
            "beginning epoch 107\n",
            "took 4.5 seconds for epoch #107\n",
            "beginning epoch 108\n",
            "took 4.5 seconds for epoch #108\n",
            "beginning epoch 109\n",
            "took 4.5 seconds for epoch #109\n",
            "beginning epoch 110\n",
            "took 4.6 seconds for epoch #110\n",
            "beginning epoch 111\n",
            "took 4.6 seconds for epoch #111\n",
            "beginning epoch 112\n",
            "took 4.5 seconds for epoch #112\n",
            "beginning epoch 113\n",
            "took 4.4 seconds for epoch #113\n",
            "beginning epoch 114\n",
            "took 4.4 seconds for epoch #114\n",
            "beginning epoch 115\n",
            "took 4.4 seconds for epoch #115\n",
            "beginning epoch 116\n",
            "took 4.4 seconds for epoch #116\n",
            "beginning epoch 117\n",
            "took 4.4 seconds for epoch #117\n",
            "beginning epoch 118\n",
            "took 4.4 seconds for epoch #118\n",
            "beginning epoch 119\n",
            "took 4.4 seconds for epoch #119\n",
            "beginning epoch 120\n",
            "took 4.7 seconds for epoch #120\n",
            "beginning epoch 121\n",
            "took 4.7 seconds for epoch #121\n",
            "beginning epoch 122\n",
            "took 4.7 seconds for epoch #122\n",
            "beginning epoch 123\n",
            "took 4.8 seconds for epoch #123\n",
            "beginning epoch 124\n",
            "took 4.6 seconds for epoch #124\n",
            "beginning epoch 125\n",
            "took 4.7 seconds for epoch #125\n",
            "beginning epoch 126\n",
            "took 4.7 seconds for epoch #126\n",
            "beginning epoch 127\n",
            "took 4.7 seconds for epoch #127\n",
            "beginning epoch 128\n",
            "took 4.7 seconds for epoch #128\n",
            "beginning epoch 129\n",
            "took 4.7 seconds for epoch #129\n",
            "beginning epoch 130\n",
            "took 5.4 seconds for epoch #130\n",
            "beginning epoch 131\n",
            "took 4.6 seconds for epoch #131\n",
            "beginning epoch 132\n",
            "took 4.7 seconds for epoch #132\n",
            "beginning epoch 133\n",
            "took 4.6 seconds for epoch #133\n",
            "beginning epoch 134\n",
            "took 5.3 seconds for epoch #134\n",
            "beginning epoch 135\n",
            "took 4.6 seconds for epoch #135\n",
            "beginning epoch 136\n",
            "took 4.5 seconds for epoch #136\n",
            "beginning epoch 137\n",
            "took 4.4 seconds for epoch #137\n",
            "beginning epoch 138\n",
            "took 4.4 seconds for epoch #138\n",
            "beginning epoch 139\n",
            "took 4.5 seconds for epoch #139\n",
            "beginning epoch 140\n",
            "took 4.5 seconds for epoch #140\n",
            "beginning epoch 141\n",
            "took 4.4 seconds for epoch #141\n",
            "beginning epoch 142\n",
            "took 4.4 seconds for epoch #142\n",
            "beginning epoch 143\n",
            "took 4.5 seconds for epoch #143\n",
            "beginning epoch 144\n",
            "took 4.4 seconds for epoch #144\n",
            "beginning epoch 145\n",
            "took 4.5 seconds for epoch #145\n",
            "beginning epoch 146\n",
            "took 4.4 seconds for epoch #146\n",
            "beginning epoch 147\n",
            "took 4.5 seconds for epoch #147\n",
            "beginning epoch 148\n",
            "took 4.5 seconds for epoch #148\n",
            "beginning epoch 149\n",
            "took 4.4 seconds for epoch #149\n",
            "beginning epoch 150\n",
            "took 4.4 seconds for epoch #150\n",
            "beginning epoch 151\n",
            "took 4.5 seconds for epoch #151\n",
            "beginning epoch 152\n",
            "took 4.5 seconds for epoch #152\n",
            "beginning epoch 153\n",
            "took 4.5 seconds for epoch #153\n",
            "beginning epoch 154\n",
            "took 4.4 seconds for epoch #154\n",
            "beginning epoch 155\n",
            "took 4.4 seconds for epoch #155\n",
            "beginning epoch 156\n",
            "took 4.4 seconds for epoch #156\n",
            "beginning epoch 157\n",
            "took 4.5 seconds for epoch #157\n",
            "beginning epoch 158\n",
            "took 4.4 seconds for epoch #158\n",
            "beginning epoch 159\n",
            "took 4.5 seconds for epoch #159\n",
            "beginning epoch 160\n",
            "took 4.4 seconds for epoch #160\n",
            "beginning epoch 161\n",
            "took 4.5 seconds for epoch #161\n",
            "beginning epoch 162\n",
            "took 4.5 seconds for epoch #162\n",
            "beginning epoch 163\n",
            "took 4.4 seconds for epoch #163\n",
            "beginning epoch 164\n",
            "took 4.5 seconds for epoch #164\n",
            "beginning epoch 165\n",
            "took 4.4 seconds for epoch #165\n",
            "beginning epoch 166\n",
            "took 4.4 seconds for epoch #166\n",
            "beginning epoch 167\n",
            "took 4.5 seconds for epoch #167\n",
            "beginning epoch 168\n",
            "took 4.5 seconds for epoch #168\n",
            "beginning epoch 169\n",
            "took 4.5 seconds for epoch #169\n",
            "beginning epoch 170\n",
            "took 4.6 seconds for epoch #170\n",
            "beginning epoch 171\n",
            "took 4.5 seconds for epoch #171\n",
            "beginning epoch 172\n",
            "took 5.4 seconds for epoch #172\n",
            "beginning epoch 173\n",
            "took 4.5 seconds for epoch #173\n",
            "beginning epoch 174\n",
            "took 4.5 seconds for epoch #174\n",
            "beginning epoch 175\n",
            "took 4.4 seconds for epoch #175\n",
            "beginning epoch 176\n",
            "took 4.4 seconds for epoch #176\n",
            "beginning epoch 177\n",
            "took 4.5 seconds for epoch #177\n",
            "beginning epoch 178\n",
            "took 4.5 seconds for epoch #178\n",
            "beginning epoch 179\n",
            "took 5.4 seconds for epoch #179\n",
            "beginning epoch 180\n",
            "took 4.5 seconds for epoch #180\n",
            "beginning epoch 181\n",
            "took 4.4 seconds for epoch #181\n",
            "beginning epoch 182\n",
            "took 4.4 seconds for epoch #182\n",
            "beginning epoch 183\n",
            "took 5.0 seconds for epoch #183\n",
            "beginning epoch 184\n",
            "took 4.4 seconds for epoch #184\n",
            "beginning epoch 185\n",
            "took 4.5 seconds for epoch #185\n",
            "beginning epoch 186\n",
            "took 4.4 seconds for epoch #186\n",
            "beginning epoch 187\n",
            "took 4.4 seconds for epoch #187\n",
            "beginning epoch 188\n",
            "took 4.4 seconds for epoch #188\n",
            "beginning epoch 189\n",
            "took 4.5 seconds for epoch #189\n",
            "beginning epoch 190\n",
            "took 4.4 seconds for epoch #190\n",
            "beginning epoch 191\n",
            "took 4.5 seconds for epoch #191\n",
            "beginning epoch 192\n",
            "took 4.5 seconds for epoch #192\n",
            "beginning epoch 193\n",
            "took 5.4 seconds for epoch #193\n",
            "beginning epoch 194\n",
            "took 4.4 seconds for epoch #194\n",
            "beginning epoch 195\n",
            "took 4.6 seconds for epoch #195\n",
            "beginning epoch 196\n",
            "took 4.6 seconds for epoch #196\n",
            "beginning epoch 197\n",
            "took 4.6 seconds for epoch #197\n",
            "beginning epoch 198\n",
            "took 4.6 seconds for epoch #198\n",
            "beginning epoch 199\n",
            "took 4.6 seconds for epoch #199\n",
            "beginning epoch 200\n",
            "took 4.6 seconds for epoch #200\n",
            "beginning epoch 201\n",
            "took 4.6 seconds for epoch #201\n",
            "beginning epoch 202\n",
            "took 4.6 seconds for epoch #202\n",
            "beginning epoch 203\n",
            "took 4.6 seconds for epoch #203\n",
            "beginning epoch 204\n",
            "took 4.7 seconds for epoch #204\n",
            "beginning epoch 205\n",
            "took 4.7 seconds for epoch #205\n",
            "beginning epoch 206\n",
            "took 4.7 seconds for epoch #206\n",
            "beginning epoch 207\n",
            "took 4.7 seconds for epoch #207\n",
            "beginning epoch 208\n",
            "took 4.7 seconds for epoch #208\n",
            "beginning epoch 209\n",
            "took 4.7 seconds for epoch #209\n",
            "beginning epoch 210\n",
            "took 4.6 seconds for epoch #210\n",
            "beginning epoch 211\n",
            "took 4.7 seconds for epoch #211\n",
            "beginning epoch 212\n",
            "took 4.7 seconds for epoch #212\n",
            "beginning epoch 213\n",
            "took 4.7 seconds for epoch #213\n",
            "beginning epoch 214\n",
            "took 4.7 seconds for epoch #214\n",
            "beginning epoch 215\n",
            "took 4.6 seconds for epoch #215\n",
            "beginning epoch 216\n",
            "took 4.6 seconds for epoch #216\n",
            "beginning epoch 217\n",
            "took 4.7 seconds for epoch #217\n",
            "beginning epoch 218\n",
            "took 4.7 seconds for epoch #218\n",
            "beginning epoch 219\n",
            "took 4.7 seconds for epoch #219\n",
            "beginning epoch 220\n",
            "took 4.7 seconds for epoch #220\n",
            "beginning epoch 221\n",
            "took 4.8 seconds for epoch #221\n",
            "beginning epoch 222\n",
            "took 4.7 seconds for epoch #222\n",
            "beginning epoch 223\n",
            "took 4.7 seconds for epoch #223\n",
            "beginning epoch 224\n",
            "took 4.8 seconds for epoch #224\n",
            "beginning epoch 225\n",
            "took 4.8 seconds for epoch #225\n",
            "beginning epoch 226\n",
            "took 4.8 seconds for epoch #226\n",
            "beginning epoch 227\n",
            "took 5.4 seconds for epoch #227\n",
            "beginning epoch 228\n",
            "took 5.0 seconds for epoch #228\n",
            "beginning epoch 229\n",
            "took 4.8 seconds for epoch #229\n",
            "beginning epoch 230\n",
            "took 5.5 seconds for epoch #230\n",
            "beginning epoch 231\n",
            "took 4.7 seconds for epoch #231\n",
            "beginning epoch 232\n",
            "took 4.7 seconds for epoch #232\n",
            "beginning epoch 233\n",
            "took 4.7 seconds for epoch #233\n",
            "beginning epoch 234\n",
            "took 4.7 seconds for epoch #234\n",
            "beginning epoch 235\n",
            "took 4.7 seconds for epoch #235\n",
            "beginning epoch 236\n",
            "took 4.8 seconds for epoch #236\n",
            "beginning epoch 237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to figure out how to look at accuracy, plots etc."
      ],
      "metadata": {
        "id": "DE8AWIP37Mml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'])\n",
        "plt.title('accuracy');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "17494e3a-5940-48d7-eb36-493f568ab161",
        "id": "1fkt8kqNNUWm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d7bb5a-dd74-4689-ea6b-145da0f89869",
        "id": "A1Wqc0e7NbE7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 1.2599 - accuracy: 0.6768 - 853ms/epoch - 3ms/step\n",
            "accuracy: 67.68%\n",
            "CPU times: user 1.14 s, sys: 109 ms, total: 1.25 s\n",
            "Wall time: 1.45 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
        "predictions = cnn_model.predict(x_test)\n",
        "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
        "print(cm); print()\n",
        "\n",
        "print('Classification accuracy for each class:'); print()\n",
        "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxGTKLiFNlO0",
        "outputId": "0d8fb274-b91c-4df4-a248-b0e70c03be87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (rows: true classes; columns: predicted classes):\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[[768  21  62  18  24   4   6  11  70  16]\n",
            " [ 31 829  11   8   2   2   7   7  32  71]\n",
            " [ 87   6 566  75 109  42  77  25   8   5]\n",
            " [ 27  10  89 473  84 156  94  37  15  15]\n",
            " [ 27   3  76  59 634  32  54 103  12   0]\n",
            " [ 10   4  62 225  51 537  34  62   9   6]\n",
            " [ 11  11  52  46  61  28 778   6   4   3]\n",
            " [ 10   2  67  42  88  56   4 717   2  12]\n",
            " [161  30  12  17   6   8   7   4 733  22]\n",
            " [ 31 127   9  17   9   8   8  13  45 733]]\n",
            "\n",
            "Classification accuracy for each class:\n",
            "\n",
            "0: 0.7680\n",
            "1: 0.8290\n",
            "2: 0.5660\n",
            "3: 0.4730\n",
            "4: 0.6340\n",
            "5: 0.5370\n",
            "6: 0.7780\n",
            "7: 0.7170\n",
            "8: 0.7330\n",
            "9: 0.7330\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}