{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXMy-G9R8oWh"
   },
   "source": [
    "# CIFAR-10 dataset classification with CNNs\n",
    "\n",
    "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
    "\n",
    "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1666401104022,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "TN4uDgPV8oWp"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZlv2PAd8oWu"
   },
   "source": [
    "## CIFAR-10 data set\n",
    "\n",
    "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7860,
     "status": "ok",
     "timestamp": 1666401182459,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "xb6lPPH28oWy",
    "outputId": "b10f7a25-f8b0-4073-b057-f7923a767918"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "y_train = y_train.astype(numpy.int32)\n",
    "y_test  = y_test.astype(numpy.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Zss2_bq8oW2"
   },
   "source": [
    "This time we won't flatten the images. \n",
    "\n",
    "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 28x28 pixels. \n",
    "\n",
    "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JFYNl5f8oW5"
   },
   "source": [
    "## Convolutional neural network (CNN)\n",
    "\n",
    "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
    "\n",
    "Let's use a small model that includes convolutional layers\n",
    "\n",
    "- The Conv2D layers operate on 2D matrices so we input the digit images directly to the model.\n",
    "    - The two Conv2D layers belows learn 32 and 64 filters respectively. \n",
    "    - They are learning filters for 3x3 windows.\n",
    "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
    "    - It downsamples by taking the maximum value in the window \n",
    "    - The pool size of (2, 2) below means the windows are 2x2. \n",
    "    - Helps in extracting important features and reduce computation\n",
    "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
    "\n",
    "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJQLGLCz8oW8"
   },
   "source": [
    "![conv layer](https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv_layer.png?raw=1)\n",
    "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0Ud-hG08oW-"
   },
   "source": [
    "![conv layer](https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv.png?raw=1)\n",
    "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xDbR1qK8oXB"
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/MaxpoolSample2.png?raw=1\" width=\"600\" hight=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsY0Oey18oXH"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, activation=tf.nn.tanh):\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
    "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
    "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.drop_6 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.dense_5(x)\n",
    "        x = self.drop_6(x)\n",
    "        x = self.dense_7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvnetdTs8oXJ"
   },
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSzgHibq8oXK"
   },
   "source": [
    "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4J-XiXJ8oXL"
   },
   "outputs": [],
   "source": [
    "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    cnn_model = CIFAR10Classifier()\n",
    "\n",
    "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
    "    return history, cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23426,
     "status": "ok",
     "timestamp": 1666145149314,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "YJG4sW3M8oXM",
    "outputId": "851bb01d-da36-4d83-8670-816c9cd31f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 11s 35ms/step - loss: 1.9292 - accuracy: 0.2876\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 3s 32ms/step - loss: 1.5865 - accuracy: 0.4223\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 1.4625 - accuracy: 0.4728\n"
     ]
    }
   ],
   "source": [
    "# This took 55 seconds per epoch on my laptop\n",
    "batch_size = 512\n",
    "epochs = 3\n",
    "lr = .01\n",
    "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr9bXKuu8oXN"
   },
   "source": [
    "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1666145150132,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "KxCLi9u28oXO",
    "outputId": "62403e2d-bb00-4a16-f7bf-d71be850eb10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'])\n",
    "plt.title('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgmKpw4J8oXO"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRrkYuXB8oXP"
   },
   "source": [
    "With enough training epochs, the test accuracy should exceed 99%.\n",
    "\n",
    "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1666145308212,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "Zwm50VSt8oXQ",
    "outputId": "c7f3bdfa-737a-48a2-d095-30bfa0f8d8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.2500 - accuracy: 0.5566 - 1s/epoch - 4ms/step\n",
      "accuracy: 55.66%\n",
      "CPU times: user 1.4 s, sys: 163 ms, total: 1.56 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
    "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfUDwucV8oXR"
   },
   "source": [
    "We can also again check the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1666145312980,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "r-IhFa4L8oXS",
    "outputId": "d92045b3-110c-42a4-c39f-29033b13c88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows: true classes; columns: predicted classes):\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "[[556  50  82  14  12  13  27  10 199  37]\n",
      " [ 20 755   3   9   3   4  26   7  64 109]\n",
      " [ 88  11 385  46 157 109 139  21  31  13]\n",
      " [ 11  19  99 276  70 228 221  30  21  25]\n",
      " [ 39  14 152  57 428  37 194  66  11   2]\n",
      " [ 12   6 113 133  63 494 103  53  18   5]\n",
      " [  4  13  46  36  56  16 802   7   7  13]\n",
      " [ 23   7  32  45  89 124  71 561   5  43]\n",
      " [104  76  22  10   2   7  20   4 713  42]\n",
      " [ 26 190   9  12   5   7  42  25  88 596]]\n",
      "\n",
      "Classification accuracy for each class:\n",
      "\n",
      "0: 0.5560\n",
      "1: 0.7550\n",
      "2: 0.3850\n",
      "3: 0.2760\n",
      "4: 0.4280\n",
      "5: 0.4940\n",
      "6: 0.8020\n",
      "7: 0.5610\n",
      "8: 0.7130\n",
      "9: 0.5960\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "predictions = cnn_model.predict(x_test)\n",
    "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
    "print(cm); print()\n",
    "\n",
    "print('Classification accuracy for each class:'); print()\n",
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dalYJKP18oXU"
   },
   "source": [
    "### More verbose training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0ddLOnM8oXV"
   },
   "source": [
    "This approach explicitly handles the looping over data. It will be helpful this afternoon for diving in and optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUV5D1dd8oXX"
   },
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    # if labels are integers, use sparse categorical crossentropy\n",
    "    # network's final layer is softmax, so from_logtis=False\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    # if labels are one-hot encoded, use standard crossentropy\n",
    "\n",
    "    return scce(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2P9ju8mY8oXZ"
   },
   "outputs": [],
   "source": [
    "def forward_pass(model, batch_data, y_true):\n",
    "    y_pred = model(batch_data)\n",
    "    loss = compute_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Z4EGxSE8oXb"
   },
   "outputs": [],
   "source": [
    "# Here is a function that will manage the training loop for us:\n",
    "\n",
    "def train_loop(batch_size, n_training_epochs, model, opt):\n",
    "    \n",
    "    @tf.function()\n",
    "    def train_iteration(data, y_true, model, opt):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model, data, y_true)\n",
    "\n",
    "        trainable_vars = model.trainable_variables\n",
    "\n",
    "        # Apply the update to the network (one at a time):\n",
    "        grads = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        opt.apply_gradients(zip(grads, trainable_vars))\n",
    "        return loss\n",
    "\n",
    "    for i_epoch in range(n_training_epochs):\n",
    "        print(\"beginning epoch %d\" % i_epoch)\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_steps = int(50000/batch_size)\n",
    "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
    "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "        \n",
    "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
    "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
    "            loss = train_iteration(batch_data, y_true, model, opt)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sh6Xr6Nv8oXd"
   },
   "outputs": [],
   "source": [
    "def train_network(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    mnist_model = CIFAR10Classifier()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(_lr)\n",
    "\n",
    "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10915,
     "status": "ok",
     "timestamp": 1666145340949,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "sDSN2osF8oXf",
    "outputId": "0706f166-5e19-49b3-b3b0-91ab08e636e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning epoch 0\n",
      "took 3.5 seconds for epoch #0\n",
      "beginning epoch 1\n",
      "took 2.8 seconds for epoch #1\n",
      "beginning epoch 2\n",
      "took 2.8 seconds for epoch #2\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset.shuffle(50000)\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 3\n",
    "lr = .01\n",
    "train_network(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GCfkxx38oXg"
   },
   "source": [
    "# Homework: improve the accuracy of this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtNuUVwa8oXj"
   },
   "source": [
    "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning weight, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GV00-Ul1mdA"
   },
   "source": [
    "Starting with modifying the Simple Version first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1666401190041,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "weA7gAva8oXo"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, activation='relu'): #consider changing activation function tf.nn.tanh; try nn.relu6, (nn.softsign)\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "        #tried activation=tf.keras.layers.LeakyReLU(alpha=0.2), but results weren't as good...\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu') #smaller kernels are supposed to be better\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu') #odd numbered filter size is best\n",
    "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(3, 3)) #just changed from 2x2 (haven't run yet)\n",
    "        self.conv_3_a = tf.keras.layers.Conv2D(64, [3, 3], activation='relu') #seeing if another conv layer helps; w/o got to 66.67\n",
    "        self.pool_3_b = tf.keras.layers.MaxPooling2D(pool_size=(3,3))\n",
    "        self.drop_4 = tf.keras.layers.Dropout(0.25) #tried .5 but made it worse\n",
    "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu') \n",
    "        #self.dense_5 = tf.keras.layers.Dense(10)\n",
    "        #self.dense_6 = tf.keras.layers.LeakyReLU()\n",
    "        self.drop_6 = tf.keras.layers.Dropout(0.5) #.25 not as good\n",
    "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.conv_3_a(x)\n",
    "        ##x = self.conv_3_b(x)\n",
    "        #x = self.pool_3_b(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.dense_5(x)\n",
    "        x = self.drop_6(x)\n",
    "        x = self.dense_7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1666401192771,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "_LnCK05Rz7En"
   },
   "outputs": [],
   "source": [
    "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    cnn_model = CIFAR10Classifier()\n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1) #just tried .2 -- too big; .1 was ok, .09 bad\n",
    "\n",
    "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy']) #prev optimizer = \"adam\"\n",
    "    \n",
    "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
    "    return history, cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gThFo0_2z8NW",
    "outputId": "30e2a5bb-d0aa-4b58-d26f-cbe0985312e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 4s 2ms/step - loss: 1.9307 - accuracy: 0.2927\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.4609 - accuracy: 0.4739\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.2850 - accuracy: 0.5405\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.1518 - accuracy: 0.5902\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 1.0564 - accuracy: 0.6274\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9909 - accuracy: 0.6527\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.9275 - accuracy: 0.6728\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8885 - accuracy: 0.6869\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8432 - accuracy: 0.7041\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8095 - accuracy: 0.7158\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7750 - accuracy: 0.7264\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7502 - accuracy: 0.7352\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7232 - accuracy: 0.7433\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7021 - accuracy: 0.7514\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.7590\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6645 - accuracy: 0.7645\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6471 - accuracy: 0.7695\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6339 - accuracy: 0.7725\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6170 - accuracy: 0.7802\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6044 - accuracy: 0.7842\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5898 - accuracy: 0.7896\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5912 - accuracy: 0.7896\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5716 - accuracy: 0.7979\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5573 - accuracy: 0.7990\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5567 - accuracy: 0.8015\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.8075\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.8079\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.8098\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5213 - accuracy: 0.8129\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5146 - accuracy: 0.8151\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5087 - accuracy: 0.8196\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5012 - accuracy: 0.8200\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4926 - accuracy: 0.8236\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.8207\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4823 - accuracy: 0.8281\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4846 - accuracy: 0.8269\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4802 - accuracy: 0.8291\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4661 - accuracy: 0.8329\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4687 - accuracy: 0.8320\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8332\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.8341\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.8382\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.8382\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4611 - accuracy: 0.8341\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8411\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4446 - accuracy: 0.8414\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4464 - accuracy: 0.8412\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8401\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4400 - accuracy: 0.8435\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8432\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4354 - accuracy: 0.8463\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4238 - accuracy: 0.8487\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4363 - accuracy: 0.8441\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4324 - accuracy: 0.8482\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4319 - accuracy: 0.8477\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.8498\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4212 - accuracy: 0.8516\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4233 - accuracy: 0.8499\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4127 - accuracy: 0.8537\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4205 - accuracy: 0.8530\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4174 - accuracy: 0.8529\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4186 - accuracy: 0.8524\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4150 - accuracy: 0.8547\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4076 - accuracy: 0.8559\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4179 - accuracy: 0.8529\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4141 - accuracy: 0.8547\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4125 - accuracy: 0.8549\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4118 - accuracy: 0.8551\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4113 - accuracy: 0.8559\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4081 - accuracy: 0.8569\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4118 - accuracy: 0.8572\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4056 - accuracy: 0.8592\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4095 - accuracy: 0.8560\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4055 - accuracy: 0.8579\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4039 - accuracy: 0.8594\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3934 - accuracy: 0.8609\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8629\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3930 - accuracy: 0.8642\n",
<<<<<<< HEAD
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 79/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3972 - accuracy: 0.8633\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3977 - accuracy: 0.8606\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3966 - accuracy: 0.8610\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4032 - accuracy: 0.8603\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8640\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8631\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3975 - accuracy: 0.8613\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8643\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8637\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3982 - accuracy: 0.8624\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8638\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3897 - accuracy: 0.8649\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8654\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8657\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3951 - accuracy: 0.8630\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8651\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3865 - accuracy: 0.8648\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3860 - accuracy: 0.8680\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3803 - accuracy: 0.8692\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8667\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3877 - accuracy: 0.8674\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3879 - accuracy: 0.8671\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3922 - accuracy: 0.8650\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8653\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8675\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8661\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8669\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3838 - accuracy: 0.8690\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8684\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8687\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3894 - accuracy: 0.8689\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8715\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3769 - accuracy: 0.8718\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8702\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8719\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8704\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8729\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8724\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3735 - accuracy: 0.8735\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8711\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8742\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8731\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8727\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3704 - accuracy: 0.8748\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8733\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3703 - accuracy: 0.8740\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3785 - accuracy: 0.8718\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3802 - accuracy: 0.8726\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3724 - accuracy: 0.8737\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3786 - accuracy: 0.8719\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8708\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8713\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8718\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3789 - accuracy: 0.8721\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8743\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8741\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8763\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8749\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8727\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8703\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8764\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3758 - accuracy: 0.8749\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3761 - accuracy: 0.8731\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8733\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3791 - accuracy: 0.8711\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8718\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8759\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8748\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3733 - accuracy: 0.8770\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8743\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3758 - accuracy: 0.8739\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8737\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3615 - accuracy: 0.8790\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8749\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3765 - accuracy: 0.8757\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8757\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3676 - accuracy: 0.8777\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8744\n",
<<<<<<< HEAD
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 157/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8773\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3857 - accuracy: 0.8718\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8734\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8747\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3755 - accuracy: 0.8755\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8744\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8771\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8774\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8778\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8765\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8757\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3888 - accuracy: 0.8726\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8739\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3753 - accuracy: 0.8760\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8783\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3645 - accuracy: 0.8781\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3677 - accuracy: 0.8782\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8748\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3773 - accuracy: 0.8751\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8750\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3706 - accuracy: 0.8771\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8770\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3760 - accuracy: 0.8765\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3714 - accuracy: 0.8771\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3784 - accuracy: 0.8748\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8748\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3842 - accuracy: 0.8750\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3944 - accuracy: 0.8721\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3691 - accuracy: 0.8786\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3678 - accuracy: 0.8781\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3760 - accuracy: 0.8776\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8759\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8754\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8780\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3818 - accuracy: 0.8758\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3713 - accuracy: 0.8773\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3875 - accuracy: 0.8740\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3741 - accuracy: 0.8781\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3841 - accuracy: 0.8741\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8777\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8743\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3778 - accuracy: 0.8769\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3762 - accuracy: 0.8797\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3833 - accuracy: 0.8756\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8790\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8766\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8789\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8786\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8759\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3786 - accuracy: 0.8765\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3720 - accuracy: 0.8797\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8766\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3753 - accuracy: 0.8794\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8775\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8752\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3749 - accuracy: 0.8788\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3747 - accuracy: 0.8790\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3756 - accuracy: 0.8783\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3710 - accuracy: 0.8806\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8768\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8755\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3841 - accuracy: 0.8753\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8745\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3780 - accuracy: 0.8780\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8766\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8773\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8802\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8785\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3748 - accuracy: 0.8796\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8812\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8779\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3743 - accuracy: 0.8777\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3793 - accuracy: 0.8792\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8774\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8774\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8770\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8797\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8744\n",
<<<<<<< HEAD
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 235/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3871 - accuracy: 0.8772\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8736\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4005 - accuracy: 0.8724\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8735\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3859 - accuracy: 0.8766\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8779\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8766\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3841 - accuracy: 0.8769\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8740\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8765\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8801\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3801 - accuracy: 0.8779\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8756\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3755 - accuracy: 0.8789\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3903 - accuracy: 0.8769\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8821\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3658 - accuracy: 0.8812\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3678 - accuracy: 0.8814\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8793\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3916 - accuracy: 0.8749\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3810 - accuracy: 0.8786\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - accuracy: 0.8784\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3937 - accuracy: 0.8755\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8731\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8797\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8798\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3937 - accuracy: 0.8758\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3784 - accuracy: 0.8796\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3844 - accuracy: 0.8774\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3839 - accuracy: 0.8789\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8802\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8788\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8761\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8758\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8769\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3862 - accuracy: 0.8776\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8764\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8802\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8797\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3897 - accuracy: 0.8774\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8808\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3688 - accuracy: 0.8817\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8766\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3982 - accuracy: 0.8769\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.8738\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4009 - accuracy: 0.8744\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3835 - accuracy: 0.8795\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3952 - accuracy: 0.8746\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3676 - accuracy: 0.8835\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8788\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8771\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8802\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8739\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3851 - accuracy: 0.8790\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8785\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3785 - accuracy: 0.8800\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8817\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3780 - accuracy: 0.8786\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3715 - accuracy: 0.8820\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8771\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.8750\n",
      "Epoch 296/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8772\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - accuracy: 0.8785\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8795\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8768\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3962 - accuracy: 0.8756\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3816 - accuracy: 0.8794\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3747 - accuracy: 0.8812\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8838\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3817 - accuracy: 0.8800\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4006 - accuracy: 0.8735\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3890 - accuracy: 0.8766\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8782\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3999 - accuracy: 0.8762\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8747\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8781\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3907 - accuracy: 0.8777\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8776\n",
<<<<<<< HEAD
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 313/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8799\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8823\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3860 - accuracy: 0.8787\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3899 - accuracy: 0.8770\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3943 - accuracy: 0.8758\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3851 - accuracy: 0.8800\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4038 - accuracy: 0.8748\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4080 - accuracy: 0.8745\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4002 - accuracy: 0.8769\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8780\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8824\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3847 - accuracy: 0.8782\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3888 - accuracy: 0.8799\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3778 - accuracy: 0.8808\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3906 - accuracy: 0.8797\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4059 - accuracy: 0.8748\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8803\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4071 - accuracy: 0.8747\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8785\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3987 - accuracy: 0.8763\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8786\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3899 - accuracy: 0.8787\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8792\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4075 - accuracy: 0.8767\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3975 - accuracy: 0.8763\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3887 - accuracy: 0.8789\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4079 - accuracy: 0.8748\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3961 - accuracy: 0.8764\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3917 - accuracy: 0.8772\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8769\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8771\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3982 - accuracy: 0.8768\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8755\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8769\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4160 - accuracy: 0.8742\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3793 - accuracy: 0.8804\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4159 - accuracy: 0.8717\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4073 - accuracy: 0.8732\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3683 - accuracy: 0.8843\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3895 - accuracy: 0.8789\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3851 - accuracy: 0.8790\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8777\n",
      "Epoch 355/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8783\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8803\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3903 - accuracy: 0.8782\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3940 - accuracy: 0.8777\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.8790\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3877 - accuracy: 0.8806\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3915 - accuracy: 0.8779\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8838\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8761\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8825\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8784\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.8771\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - accuracy: 0.8755\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3814 - accuracy: 0.8809\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4055 - accuracy: 0.8754\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8803\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3961 - accuracy: 0.8764\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8790\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3843 - accuracy: 0.8797\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3802 - accuracy: 0.8818\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3859 - accuracy: 0.8794\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4015 - accuracy: 0.8772\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3960 - accuracy: 0.8788\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.8779\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8791\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3973 - accuracy: 0.8780\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8773\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8817\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8815\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3999 - accuracy: 0.8778\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4025 - accuracy: 0.8749\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8821\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3847 - accuracy: 0.8812\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8788\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4015 - accuracy: 0.8748\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8787\n",
<<<<<<< HEAD
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 391/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4097 - accuracy: 0.8752\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3810 - accuracy: 0.8810\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3834 - accuracy: 0.8827\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3980 - accuracy: 0.8778\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8785\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4073 - accuracy: 0.8752\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3930 - accuracy: 0.8789\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8807\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4044 - accuracy: 0.8769\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4059 - accuracy: 0.8746\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4069 - accuracy: 0.8749\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8788\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3839 - accuracy: 0.8807\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3912 - accuracy: 0.8802\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8783\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8807\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4005 - accuracy: 0.8761\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3843 - accuracy: 0.8821\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3977 - accuracy: 0.8776\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4029 - accuracy: 0.8762\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4043 - accuracy: 0.8768\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3933 - accuracy: 0.8803\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4190 - accuracy: 0.8725\n",
      "Epoch 414/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3998 - accuracy: 0.8800\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4253 - accuracy: 0.8720\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3951 - accuracy: 0.8788\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3850 - accuracy: 0.8831\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4061 - accuracy: 0.8749\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3835 - accuracy: 0.8826\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4170 - accuracy: 0.8747\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3932 - accuracy: 0.8808\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3981 - accuracy: 0.8766\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8783\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3827 - accuracy: 0.8833\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8817\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3989 - accuracy: 0.8781\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4146 - accuracy: 0.8742\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4089 - accuracy: 0.8741\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4272 - accuracy: 0.8714\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4116 - accuracy: 0.8740\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8734\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3942 - accuracy: 0.8769\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.8748\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4236 - accuracy: 0.8729\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4158 - accuracy: 0.8740\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8815\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8821\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3988 - accuracy: 0.8783\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4055 - accuracy: 0.8769\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4186 - accuracy: 0.8739\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4142 - accuracy: 0.8755\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4179 - accuracy: 0.8734\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3957 - accuracy: 0.8781\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8785\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8769\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4035 - accuracy: 0.8782\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4049 - accuracy: 0.8750\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3954 - accuracy: 0.8789\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4229 - accuracy: 0.8724\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3896 - accuracy: 0.8795\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8824\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4003 - accuracy: 0.8767\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8787\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8780\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4051 - accuracy: 0.8776\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8777\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4032 - accuracy: 0.8804\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4061 - accuracy: 0.8770\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4235 - accuracy: 0.8744\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8764\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4013 - accuracy: 0.8776\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4011 - accuracy: 0.8765\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4338 - accuracy: 0.8709\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8797\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8759\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4083 - accuracy: 0.8763\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8779\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3984 - accuracy: 0.8799\n",
<<<<<<< HEAD
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Epoch 469/500\n",
>>>>>>> a03676eded8b844ab52614e7b0723e2c1923c6a6
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4059 - accuracy: 0.8775\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8772\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4161 - accuracy: 0.8737\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4276 - accuracy: 0.8713\n",
      "Epoch 473/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4159 - accuracy: 0.8736\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4341 - accuracy: 0.8685\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4087 - accuracy: 0.8766\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8776\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4024 - accuracy: 0.8791\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8767\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8733\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4218 - accuracy: 0.8744\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8810\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4105 - accuracy: 0.8762\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8774\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8734\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4067 - accuracy: 0.8787\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4326 - accuracy: 0.8725\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4271 - accuracy: 0.8716\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4005 - accuracy: 0.8781\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4160 - accuracy: 0.8729\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3920 - accuracy: 0.8817\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4113 - accuracy: 0.8772\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4024 - accuracy: 0.8784\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4221 - accuracy: 0.8726\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.8691\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4201 - accuracy: 0.8738\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8769\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4289 - accuracy: 0.8707\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4009 - accuracy: 0.8805\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4064 - accuracy: 0.8797\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4147 - accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 50 #don't do 25\n",
    "epochs = 500 #500 #no more 1000 until further notice #3000 not really worth the time; only got to 67.68% on the test set #1000 is decent\n",
    "#I need to be able to shuffle the data...\n",
    "lr = .1 #prev .2 with 57.79, .1 with 56.69, .3 with 56.81\n",
    "history, cnn_model = train_network_concise(batch_size, epochs, lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1666334452587,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "C8N1xP_G0CDX",
    "outputId": "311fc160-1ce7-46de-f993-4b6b5fa932de"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'])\n",
    "plt.title('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1666334462188,
     "user": {
      "displayName": "Katherine Casey",
      "userId": "14454718602231422844"
     },
     "user_tz": 420
    },
    "id": "4mRkFw950Rng",
    "outputId": "d835a15a-dbc9-4594-fe2b-163258ee78ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.2637 - accuracy: 0.7386 - 611ms/epoch - 2ms/step\n",
      "accuracy: 73.86%\n",
      "CPU times: user 950 ms, sys: 218 ms, total: 1.17 s\n",
      "Wall time: 826 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
    "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couldn't figure out how to use the more verbose training to look at loss, or accuracy on test set."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "https://github.com/ktkc/ai-science-training-series/blob/main/03_neural_networks_tensorflow/02_keras_cnn.ipynb",
     "timestamp": 1664934797873
    }
   ]
  },
  "kernelspec": {
   "display_name": "conda/2022-07-01",
   "language": "python",
   "name": "conda-2022-07-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
